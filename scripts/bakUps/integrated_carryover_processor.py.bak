#!/usr/bin/env python3
"""
integrated_carryover_processor.py - FIXED VERSION
Fixed Issues:
- Recursive search for mastersheet in extracted ZIP
- Header detection for mastersheet loading to handle merged titles and variable header positions
- Enhanced student matching
- Program detection and handling
- Removed skip for first semesters
- Better logging and error handling
- Removed 'Unnamed:' from possible_names in find_exam_number_column to avoid picking wrong column
- Added fallback to header=5 in load_excel_with_header_detection for ND mastersheet
- Changed logging to print for output to stdout, errors to stderr
- FIXED: Resit score processing - now always updates scores regardless of comparison
"""

import os
import sys
import re
import pandas as pd
import numpy as np
from datetime import datetime
import glob
import json
import traceback
import shutil
import zipfile
import tempfile
from openpyxl import load_workbook, Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter

def print_info(message):
    print(f"{datetime.now()} - INFO - {message}")

def print_warning(message):
    print(f"{datetime.now()} - WARNING - {message}", file=sys.stderr)

def print_error(message):
    print(f"{datetime.now()} - ERROR - {message}", file=sys.stderr)

def detect_program_from_set(set_name):
    """Detect program from set name with better logic."""
    set_upper = set_name.upper()
    
    # Check for explicit program indicators
    if any(x in set_upper for x in ['BN', 'NURSING', 'N-']):
        return "BN"
    elif any(x in set_upper for x in ['BM', 'MIDWIFE', 'MIDWIFERY', 'M-']):
        return "BM"
    elif any(x in set_upper for x in ['ND', 'DIPLOMA']):
        return "ND"
    
    # Fallback: Check SET number
    if set_upper.startswith("SET4"):
        return "BN"
    elif set_upper.startswith("SET") and any(c.isdigit() for c in set_upper):
        # Assume other SETs are BM unless proven otherwise
        return "BM"
    
    # Final fallback
    print_warning(f"‚ö†Ô∏è Could not determine program from set '{set_name}', defaulting to ND")
    return "ND"

def standardize_semester_key(semester_key, program=None):
    """Standardize semester key to canonical format for all programs - FIXED VERSION."""
    if not semester_key:
        return None
    
    key_upper = semester_key.upper()
    
    # Determine program from key content if not provided
    if not program:
        if key_upper.startswith(('N-', 'N_')):
            program = "BN"
        elif key_upper.startswith(('M-', 'M_')):
            program = "BM"
        else:
            program = "ND"  # Default
    
    # Set appropriate prefix
    if program == "BN":
        prefix = "N-"
    elif program == "BM":
        prefix = "M-"
    else:
        prefix = "ND-"
    
    # Define canonical mappings with proper prefixes
    canonical_mappings = {
        # First Year First Semester variants
        ("FIRST", "YEAR", "FIRST", "SEMESTER"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("1ST", "YEAR", "1ST", "SEMESTER"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("YEAR", "1", "SEMESTER", "1"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("FIRST", "SEMESTER"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("SEMESTER", "1"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        
        # First Year Second Semester variants
        ("FIRST", "YEAR", "SECOND", "SEMESTER"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("1ST", "YEAR", "2ND", "SEMESTER"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("YEAR", "1", "SEMESTER", "2"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("SECOND", "SEMESTER"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("SEMESTER", "2"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        
        # Second Year First Semester variants
        ("SECOND", "YEAR", "FIRST", "SEMESTER"): f"{prefix}SECOND-YEAR-FIRST-SEMESTER",
        ("2ND", "YEAR", "1ST", "SEMESTER"): f"{prefix}SECOND-YEAR-FIRST-SEMESTER",
        ("YEAR", "2", "SEMESTER", "1"): f"{prefix}SECOND-YEAR-FIRST-SEMESTER",
        
        # Second Year Second Semester variants
        ("SECOND", "YEAR", "SECOND", "SEMESTER"): f"{prefix}SECOND-YEAR-SECOND-SEMESTER",
        ("2ND", "YEAR", "2ND", "SEMESTER"): f"{prefix}SECOND-YEAR-SECOND-SEMESTER",
        ("YEAR", "2", "SEMESTER", "2"): f"{prefix}SECOND-YEAR-SECOND-SEMESTER",
        
        # Third Year variants (for BN/BM)
        ("THIRD", "YEAR", "FIRST", "SEMESTER"): f"{prefix}THIRD-YEAR-FIRST-SEMESTER",
        ("3RD", "YEAR", "1ST", "SEMESTER"): f"{prefix}THIRD-YEAR-FIRST-SEMESTER",
        ("YEAR", "3", "SEMESTER", "1"): f"{prefix}THIRD-YEAR-FIRST-SEMESTER",
        
        ("THIRD", "YEAR", "SECOND", "SEMESTER"): f"{prefix}THIRD-YEAR-SECOND-SEMESTER",
        ("3RD", "YEAR", "2ND", "SEMESTER"): f"{prefix}THIRD-YEAR-SECOND-SEMESTER",
        ("YEAR", "3", "SEMESTER", "2"): f"{prefix}THIRD-YEAR-SECOND-SEMESTER",
    }
    
    # Extract key components using regex for all programs
    patterns = [
        # Generic patterns that work for all programs
        r'(FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1)',
        r'(FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2)',
        r'(SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1)',
        r'(SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2)',
        r'(THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1)',
        r'(THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2)',
        
        # BN-specific patterns with N- prefix
        r'(N[-_]?(?:FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1))',
        r'(N[-_]?(?:FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2))',
        r'(N[-_]?(?:SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1))',
        r'(N[-_]?(?:SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2))',
        r'(N[-_]?(?:THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1))',
        r'(N[-_]?(?:THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2))',
        
        # BN patterns with BN prefix
        r'(BN[-_]?(?:FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BN[-_]?(?:FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2))',
        r'(BN[-_]?(?:SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BN[-_]?(?:SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2))',
        r'(BN[-_]?(?:THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BN[-_]?(?:THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2))',
        
        # BM-specific patterns with M- prefix
        r'(M[-_]?(?:FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1))',
        r'(M[-_]?(?:FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2))',
        r'(M[-_]?(?:SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1))',
        r'(M[-_]?(?:SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2))',
        r'(M[-_]?(?:THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1))',
        r'(M[-_]?(?:THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2))',
        
        # BM patterns with BM prefix
        r'(BM[-_]?(?:FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BM[-_]?(?:FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2))',
        r'(BM[-_]?(?:SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BM[-_]?(?:SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2))',
        r'(BM[-_]?(?:THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BM[-_]?(?:THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2))',
    ]
    
    for pattern_idx, pattern in enumerate(patterns):
        match = re.search(pattern, key_upper, re.IGNORECASE)
        if match:
            # Determine which pattern group matched
            matched_text = match.group(0)
            
            # Map pattern index to semester
            if pattern_idx in [0, 6, 12, 18, 24]:
                return f"{prefix}FIRST-YEAR-FIRST-SEMESTER"
            elif pattern_idx in [1, 7, 13, 19, 25]:
                return f"{prefix}FIRST-YEAR-SECOND-SEMESTER"
            elif pattern_idx in [2, 8, 14, 20, 26]:
                return f"{prefix}SECOND-YEAR-FIRST-SEMESTER"
            elif pattern_idx in [3, 9, 15, 21, 27]:
                return f"{prefix}SECOND-YEAR-SECOND-SEMESTER"
            elif pattern_idx in [4, 10, 16, 22, 28]:
                return f"{prefix}THIRD-YEAR-FIRST-SEMESTER"
            elif pattern_idx in [5, 11, 17, 23, 29]:
                return f"{prefix}THIRD-YEAR-SECOND-SEMESTER"
    
    # Check for direct matches in canonical mappings
    for key_components, canonical_key in canonical_mappings.items():
        if all(component in key_upper for component in key_components):
            return canonical_key
    
    # If no match but contains program prefix, return as-is
    if key_upper.startswith(("N-", "M-", "ND-")):
        return semester_key.upper()
    
    # If no match, try to construct from known patterns
    if "FIRST" in key_upper and "FIRST" in key_upper:
        return f"{prefix}FIRST-YEAR-FIRST-SEMESTER"
    elif "FIRST" in key_upper and "SECOND" in key_upper:
        return f"{prefix}FIRST-YEAR-SECOND-SEMESTER"
    elif "SECOND" in key_upper and "FIRST" in key_upper:
        return f"{prefix}SECOND-YEAR-FIRST-SEMESTER"
    elif "SECOND" in key_upper and "SECOND" in key_upper:
        return f"{prefix}SECOND-YEAR-SECOND-SEMESTER"
    elif "THIRD" in key_upper and "FIRST" in key_upper:
        return f"{prefix}THIRD-YEAR-FIRST-SEMESTER"
    elif "THIRD" in key_upper and "SECOND" in key_upper:
        return f"{prefix}THIRD-YEAR-SECOND-SEMESTER"
    
    # If no match, return original with proper prefix
    print_warning(f"‚ö†Ô∏è Could not standardize semester key: {semester_key}, using prefix: {prefix}")
    return f"{prefix}{semester_key.replace('-', ' ').upper().replace(' ', '-')}" 

def get_previous_semester(semester_key, program=None):
    """Get the previous semester key for carryover for all programs."""
    standardized = standardize_semester_key(semester_key, program)
    
    # Determine program from standardized key if not provided
    if not program:
        if standardized.startswith('N-'):
            program = "BN"
        elif standardized.startswith('M-'):
            program = "BM"
        else:
            program = "ND"
    
    # ND semesters
    if program == "ND":
        if standardized == "ND-FIRST-YEAR-SECOND-SEMESTER":
            return "ND-FIRST-YEAR-FIRST-SEMESTER"
        elif standardized == "ND-SECOND-YEAR-FIRST-SEMESTER":
            return "ND-FIRST-YEAR-SECOND-SEMESTER"
        elif standardized == "ND-SECOND-YEAR-SECOND-SEMESTER":
            return "ND-SECOND-YEAR-FIRST-SEMESTER"
    
    # BN semesters
    elif program == "BN":
        if standardized == "N-FIRST-YEAR-SECOND-SEMESTER":
            return "N-FIRST-YEAR-FIRST-SEMESTER"
        elif standardized == "N-SECOND-YEAR-FIRST-SEMESTER":
            return "N-FIRST-YEAR-SECOND-SEMESTER"
        elif standardized == "N-SECOND-YEAR-SECOND-SEMESTER":
            return "N-SECOND-YEAR-FIRST-SEMESTER"
        elif standardized == "N-THIRD-YEAR-FIRST-SEMESTER":
            return "N-SECOND-YEAR-SECOND-SEMESTER"
        elif standardized == "N-THIRD-YEAR-SECOND-SEMESTER":
            return "N-THIRD-YEAR-FIRST-SEMESTER"
    
    # BM semesters (same structure as BN)
    elif program == "BM":
        if standardized == "M-FIRST-YEAR-SECOND-SEMESTER":
            return "M-FIRST-YEAR-FIRST-SEMESTER"
        elif standardized == "M-SECOND-YEAR-FIRST-SEMESTER":
            return "M-FIRST-YEAR-SECOND-SEMESTER"
        elif standardized == "M-SECOND-YEAR-SECOND-SEMESTER":
            return "M-SECOND-YEAR-FIRST-SEMESTER"
        elif standardized == "M-THIRD-YEAR-FIRST-SEMESTER":
            return "M-SECOND-YEAR-SECOND-SEMESTER"
        elif standardized == "M-THIRD-YEAR-SECOND-SEMESTER":
            return "M-THIRD-YEAR-FIRST-SEMESTER"
    
    return None  # No previous for first semester

# ----------------------------
# Configuration
# ----------------------------
def get_base_directory():
    """Get base directory - ENHANCED VERSION."""
    # First try environment variable
    if os.getenv('BASE_DIR'):
        base_dir = os.getenv('BASE_DIR')
        if os.path.exists(base_dir):
            return base_dir
    
    # Try the user's home directory with student_result_cleaner
    home_dir = os.path.expanduser('~')
    default_dir = os.path.join(home_dir, 'student_result_cleaner')
    
    # Check if EXAMS_INTERNAL exists in the default directory
    if os.path.exists(os.path.join(default_dir, "EXAMS_INTERNAL")):
        return default_dir
    
    # If not, check if we're already in a directory that contains EXAMS_INTERNAL
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    if os.path.exists(os.path.join(current_script_dir, "EXAMS_INTERNAL")):
        return current_script_dir
    
    # Check parent directory
    parent_dir = os.path.dirname(current_script_dir)
    if os.path.exists(os.path.join(parent_dir, "EXAMS_INTERNAL")):
        return parent_dir
    
    # Final fallback
    return default_dir

BASE_DIR = get_base_directory()
TIMESTAMP_FMT = "%d-%m-%Y_%H%M%S"
DEFAULT_PASS_THRESHOLD = 50.0
DEFAULT_LOGO_PATH = os.path.join(os.path.dirname(__file__), "logo.png")

def sanitize_filename(filename):
    """Remove or replace characters that are not safe for filenames."""
    return re.sub(r'[^\w\-_.]', '_', filename)

def load_excel_with_header_detection(file_path, sheet_name):
    """Load Excel sheet and detect header row dynamically - FIXED WITH FALLBACK."""
    df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
    
    header_row = None
    for idx, row in df.iterrows():
        row_values = row.astype(str).str.upper().str.strip().tolist()
        if 'EXAM NUMBER' in row_values or 'EXAMS NUMBER' in row_values or 'REG NO' in row_values or 'REG. NO' in row_values:
            header_row = idx
            break
    
    if header_row is None:
        print_warning("‚ö†Ô∏è Header detection failed, falling back to header=5")
        return pd.read_excel(file_path, sheet_name=sheet_name, header=5)
    
    # Set columns
    headers = df.iloc[header_row].astype(str).str.strip()
    df = df.iloc[header_row + 1:].reset_index(drop=True)
    df.columns = headers
    
    return df

def find_exam_number_column(df):
    """Find the exam number column in a DataFrame - ENHANCED ROBUST VERSION."""
    # Comprehensive list of possible column names for exam numbers
    possible_names = [
        # Primary variations - FIXED: Added "EXAMS NUMBER" to handle the mismatch
        'EXAM NUMBER', 'EXAMS NUMBER', 'EXAM NO', 'EXAMS NO', 
        'EXAM', 'EXAMS', 'EXAMINATION NUMBER', 'EXAMINATION NO',
        
        # Registration variations
        'REG. NO', 'REG NO', 'REG NO.', 'REGISTRATION NUMBER', 
        'REGISTRATION NO', 'REGISTRATION', 'REG. NUMBER',
        
        # Student ID variations
        'MAT NO', 'MATRIC NO', 'MATRICULATION NUMBER', 'MATRIC',
        'STUDENT ID', 'STUDENT NO', 'STUDENT NUMBER', 'STUDENT',
        'ID', 'STUDENT ID NUMBER',
        
        # Common abbreviations
        'EXM NO', 'EXM NUMBER', 'EXAM NUM', 'EXAMS NUM',
        'REG NUM', 'REGISTRATION NUM',
        
        # With special characters and spaces
        'EXAM-NO', 'EXAM-NUMBER', 'EXAMS-NO', 'EXAMS-NUMBER',
        'REG-NO', 'REG-NUMBER', 'STUDENT-ID', 'STUDENT-NO',
        
        # Lowercase variations (we'll convert to upper for matching)
        'exam number', 'exams number', 'exam no', 'exams no',
        'reg no', 'registration number', 'student id',
    ]
    
    print_info(f"üîç Searching for exam number column among {len(df.columns)} columns: {list(df.columns)}")
    
    # First, check for exact matches (case-insensitive)
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if col_upper == possible_name.upper():
                print_info(f"‚úÖ Found exact exam column match: '{col}'")
                return col
    
    # Then check for partial matches (contains)
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if possible_name.upper() in col_upper:
                print_info(f"‚úÖ Found partial exam column match: '{col}' contains '{possible_name}'")
                return col
    
    # Then check for columns that might contain exam-like patterns with regex
    for col in df.columns:
        col_str = str(col).upper().strip()
        
        # Look for patterns using regular expressions
        exam_patterns = [
            r'.*EXAM.*NO.*', r'.*EXAM.*NUM.*', r'.*REG.*NO.*', 
            r'.*REG.*NUM.*', r'.*STUDENT.*ID.*', r'.*MAT.*NO.*',
            r'.*EXAMS.*NO.*', r'.*EXAMS.*NUM.*'
        ]
        
        for pattern in exam_patterns:
            if re.match(pattern, col_str, re.IGNORECASE):
                print_info(f"‚úÖ Found exam column by pattern '{pattern}': '{col}'")
                return col
    
    # Then check for columns that might contain exam-like patterns with keywords
    for col in df.columns:
        col_str = str(col).upper().strip()
        # Look for patterns like exam numbers (mix of letters and numbers)
        exam_keywords = ['EXAM', 'REG', 'MAT', 'STUDENT', 'ID', 'NO', 'NUMBER']
        keyword_matches = sum(1 for keyword in exam_keywords if keyword in col_str)
        
        if keyword_matches >= 2:  # At least 2 keywords match
            print_info(f"‚úÖ Found potential exam column by keywords ({keyword_matches} matches): '{col}'")
            return col
    
    # If still not found, try to find the first column that looks like it contains exam numbers
    print_info("üîÑ Trying value-based detection for exam number column...")
    for col in df.columns:
        # Skip columns that are clearly not exam numbers
        col_str = str(col).upper().strip()
        if any(skip_word in col_str for skip_word in ['NAME', 'SCORE', 'MARK', 'GRADE', 'TOTAL', 'GPA', 'REMARK']):
            continue
            
        # Sample a few values to see if they look like exam numbers
        sample_values = df[col].dropna().head(10)
        if len(sample_values) > 0:
            exam_like_count = 0
            total_checked = min(10, len(sample_values))
            
            for val in sample_values:
                val_str = str(val).strip()
                # Exam numbers are typically alphanumeric and not too long
                if (re.match(r'^[A-Za-z0-9/-]+$', val_str) and 
                    3 <= len(val_str) <= 20 and 
                    not val_str.isalpha() and 
                    not val_str.isdigit() and
                    not re.match(r'^\d+$', val_str)):  # Not pure numbers
                    exam_like_count += 1
            
            if exam_like_count >= total_checked * 0.6:  # At least 60% look like exam numbers
                print_info(f"üîÑ Using column '{col}' as exam column based on value pattern ({exam_like_count}/{total_checked} values look like exam numbers)")
                return col
    
    # Last resort: check if there's a column that's mostly unique values (common for IDs)
    print_info("üîÑ Trying uniqueness-based detection...")
    for col in df.columns:
        unique_ratio = df[col].nunique() / len(df) if len(df) > 0 else 0
        if unique_ratio > 0.8:  # Mostly unique values (like IDs)
            print_info(f"üîÑ Using column '{col}' as exam column based on uniqueness ({unique_ratio:.1%} unique)")
            return col
    
    print_error(f"‚ùå No exam number column found. Available columns: {list(df.columns)}")
    print_info("üí° Please check if your data has one of these columns:")
    for name in possible_names[:10]:  # Show first 10 possible names
        print_info(f"   - {name}")
    
    return None

def find_student_name_column(df):
    """Find the student name column in a DataFrame - ENHANCED VERSION."""
    possible_names = [
        'NAME', 'STUDENT NAME', 'FULL NAME', 'NAMES', 'STUDENT',
        'CANDIDATE NAME', 'CANDIDATE', 'STUDENTNAMES', 'STUDENT_NAME',
        'name', 'student name', 'full name'
    ]
    
    # First, check for exact matches
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if col_upper == possible_name.upper():
                print_info(f"‚úÖ Found exact name column match: '{col}'")
                return col
    
    # Then check for partial matches
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if possible_name.upper() in col_upper:
                print_info(f"‚úÖ Found partial name column match: '{col}' contains '{possible_name}'")
                return col
    
    # If not found, return the second column (often the name column)
    if len(df.columns) > 1:
        print_info(f"üîÑ Using second column as name column: '{df.columns[1]}'")
        return df.columns[1]
    
    print_error(f"‚ùå No student name column found. Available columns: {list(df.columns)}")
    return 'NAME'

# Course Data Loading for different programs
def load_course_data(program):
    """Load course data for the specified program."""
    if program == "BN":
        return load_bn_course_data()
    elif program == "BM":
        return load_bm_course_data()
    else:  # ND
        return load_nd_course_data()

def load_nd_course_data():
    """Load ND course data from course-code-creditUnit.xlsx."""
    possible_course_files = [
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "ND", "ND-COURSES", "course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "ND", "ND-COURSES", "course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "ND-COURSES", "course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "course-code-creditUnit.xlsx"),
    ]
    
    course_file = None
    for possible_file in possible_course_files:
        if os.path.exists(possible_file):
            course_file = possible_file
            print_info(f"‚úÖ Found ND course file: {course_file}")
            break
    
    if not course_file:
        print_error(f"‚ùå Main ND course file not found in standard locations")
        alternative_files = find_alternative_course_files("ND")
        if alternative_files:
            course_file = alternative_files[0]
            print_info(f"üîÑ Using alternative ND course file: {course_file}")
        else:
            print_error("‚ùå No ND course files found anywhere!")
            return {}, {}, {}, {}
    
    print_info(f"üìö Loading ND course data from: {course_file}")
    return _load_course_data_from_file(course_file)

def load_bn_course_data():
    """Load BN course data from N-course-code-creditUnit.xlsx."""
    possible_course_files = [
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BN", "BN-COURSES", "N-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "BN", "BN-COURSES", "N-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BN-COURSES", "N-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "N-course-code-creditUnit.xlsx"),
    ]
    
    course_file = None
    for possible_file in possible_course_files:
        if os.path.exists(possible_file):
            course_file = possible_file
            print_info(f"‚úÖ Found BN course file: {course_file}")
            break
    
    if not course_file:
        print_error(f"‚ùå Main BN course file not found in standard locations")
        alternative_files = find_alternative_course_files("BN")
        if alternative_files:
            course_file = alternative_files[0]
            print_info(f"üîÑ Using alternative BN course file: {course_file}")
        else:
            print_error("‚ùå No BN course files found anywhere!")
            return {}, {}, {}, {}
    
    print_info(f"üìö Loading BN course data from: {course_file}")
    return _load_course_data_from_file(course_file)

def load_bm_course_data():
    """Load BM course data from M-course-code-creditUnit.xlsx."""
    possible_course_files = [
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BM", "BM-COURSES", "M-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "BM", "BM-COURSES", "M-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BM-COURSES", "M-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "M-course-code-creditUnit.xlsx"),
    ]
    
    course_file = None
    for possible_file in possible_course_files:
        if os.path.exists(possible_file):
            course_file = possible_file
            print_info(f"‚úÖ Found BM course file: {course_file}")
            break
    
    if not course_file:
        print_error(f"‚ùå Main BM course file not found in standard locations")
        alternative_files = find_alternative_course_files("BM")
        if alternative_files:
            course_file = alternative_files[0]
            print_info(f"üîÑ Using alternative BM course file: {course_file}")
        else:
            print_error("‚ùå No BM course files found anywhere!")
            return {}, {}, {}, {}
    
    print_info(f"üìö Loading BM course data from: {course_file}")
    return _load_course_data_from_file(course_file)

def _load_course_data_from_file(course_file):
    """Generic function to load course data from Excel file - FIXED VERSION."""
    try:
        xl = pd.ExcelFile(course_file)
        semester_course_titles = {}
        semester_credit_units = {}
        course_code_to_title = {}
        course_code_to_unit = {}
        
        print_info(f"üìñ Available sheets: {xl.sheet_names}")
        
        for sheet in xl.sheet_names:
            sheet_standard = standardize_semester_key(sheet)
            print_info(f"üìñ Reading sheet: {sheet} (standardized: {sheet_standard})")
            try:
                df = pd.read_excel(course_file, sheet_name=sheet, engine='openpyxl', header=0)
                
                # Convert columns to string and clean
                df.columns = [str(c).strip().upper() for c in df.columns]
                
                # Look for course code, title, and credit unit columns with flexible matching
                code_col = None
                title_col = None
                unit_col = None
                
                for col in df.columns:
                    col_clean = str(col).upper()
                    if any(keyword in col_clean for keyword in ['COURSE CODE', 'CODE', 'COURSECODE']):
                        code_col = col
                    elif any(keyword in col_clean for keyword in ['COURSE TITLE', 'TITLE', 'COURSENAME']):
                        title_col = col
                    elif any(keyword in col_clean for keyword in ['CU', 'CREDIT', 'UNIT', 'CREDIT UNIT']):
                        unit_col = col
                
                print_info(f"üîç Detected columns - Code: {code_col}, Title: {title_col}, Unit: {unit_col}")
                
                if not all([code_col, title_col, unit_col]):
                    print_warning(f"‚ö†Ô∏è Sheet '{sheet}' missing required columns - found: code={code_col}, title={title_col}, unit={unit_col}")
                    # Try to use first three columns as fallback
                    if len(df.columns) >= 3:
                        code_col, title_col, unit_col = df.columns[0], df.columns[1], df.columns[2]
                        print_info(f"üîÑ Using fallback columns: {code_col}, {title_col}, {unit_col}")
                    else:
                        print_warning(f"‚ùå Sheet '{sheet}' doesn't have enough columns - skipped")
                        continue
                
                # Clean the data
                df_clean = df.dropna(subset=[code_col]).copy()
                if df_clean.empty:
                    print_warning(f"‚ö†Ô∏è Sheet '{sheet}' has no data after cleaning - skipped")
                    continue
                
                # Convert credit units to numeric, handling errors
                df_clean[unit_col] = pd.to_numeric(df_clean[unit_col], errors='coerce')
                df_clean = df_clean.dropna(subset=[unit_col])
                
                # FIXED: Remove rows with "TOTAL" in course code
                df_clean = df_clean[~df_clean[code_col].astype(str).str.contains('TOTAL', case=False, na=False)]
                
                if df_clean.empty:
                    print_warning(f"‚ö†Ô∏è Sheet '{sheet}' has no valid rows after cleaning - skipped")
                    continue
                
                codes = df_clean[code_col].astype(str).str.strip().tolist()
                titles = df_clean[title_col].astype(str).str.strip().tolist()
                units = df_clean[unit_col].astype(float).tolist()

                print_info(f"üìã Found {len(codes)} courses in {sheet}:")
                for i, (code, title, unit) in enumerate(zip(codes[:5], titles[:5], units[:5])):
                    print_info(f"   - '{code}': '{title}' (CU: {unit})")

                # Create mapping dictionaries with ENHANCED normalization strategies
                sheet_titles = {}
                sheet_units = {}
                
                for code, title, unit in zip(codes, titles, units):
                    if not code or code.upper() in ['NAN', 'NONE', '']:
                        continue
                    
                    # ENHANCED: Create comprehensive normalization variants for robust matching
                    variants = [
                        # Basic variants
                        code.upper().strip(),
                        code.strip(),
                        code.upper(),
                        code.lower(),
                        code.title(),
                        
                        # Space removal variants
                        code.upper().replace(' ', ''),
                        code.replace(' ', ''),
                        re.sub(r'\s+', '', code.upper()),
                        re.sub(r'\s+', '', code),
                        
                        # Special character removal (keep only alphanumeric)
                        re.sub(r'[^a-zA-Z0-9]', '', code.upper()),
                        re.sub(r'[^a-zA-Z0-9]', '', code),
                        
                        # Dash and underscore variants
                        code.upper().replace('-', ''),
                        code.upper().replace('_', ''),
                        code.replace('-', '').replace('_', ''),
                        code.upper().replace('-', '').replace('_', '').replace(' ', ''),
                        
                        # WITH common prefixes (for matching with prefix)
                        f"NUR{code.upper()}",
                        f"NUR{code.upper().replace(' ', '')}",
                        f"NUR{re.sub(r'[^a-zA-Z0-9]', '', code.upper())}",
                        f"NSC{code.upper()}",
                        f"NSC{code.upper().replace(' ', '')}",
                        f"NSC{re.sub(r'[^a-zA-Z0-9]', '', code.upper())}",
                        
                        # WITHOUT common prefixes (for matching without prefix)
                        code.upper().replace('NUR', '').strip(),
                        code.upper().replace('NSC', '').strip(),
                        re.sub(r'^(NUR|NSC)', '', code.upper()).strip(),
                        re.sub(r'^(NUR|NSC)', '', code.upper()).replace(' ', '').strip(),
                        
                        # Number-focused variants (for codes like "101", "201")
                        re.sub(r'[^0-9]', '', code),
                        
                        # Common variations with dots
                        code.upper().replace('.', ''),
                        code.replace('.', ''),
                    ]
                    
                    # Remove duplicates while preserving order
                    variants = list(dict.fromkeys([v for v in variants if v and v not in ['NAN', 'NONE', '']]))
                    
                    # Add all variants to mappings
                    for variant in variants:
                        sheet_titles[variant] = title
                        sheet_units[variant] = unit
                        course_code_to_title[variant] = title
                        course_code_to_unit[variant] = unit
                
                semester_course_titles[sheet_standard] = sheet_titles
                semester_credit_units[sheet_standard] = sheet_units
                
            except Exception as e:
                print_error(f"‚ùå Error processing sheet '{sheet}': {e}")
                traceback.print_exc(file=sys.stderr)
                continue
        
        print_info(f"‚úÖ Loaded course data for sheets: {list(semester_course_titles.keys())}")
        print_info(f"üìä Total course mappings: {len(course_code_to_title)}")
        
        # Debug: Show some course mappings
        print_info("üîç Sample course mappings:")
        sample_items = list(course_code_to_title.items())[:15]
        for code, title in sample_items:
            unit = course_code_to_unit.get(code, 0)
            print_info(f"   '{code}' -> '{title}' (CU: {unit})")
            
        return semester_course_titles, semester_credit_units, course_code_to_title, course_code_to_unit
        
    except Exception as e:
        print_error(f"‚ùå Error loading course data: {e}")
        traceback.print_exc(file=sys.stderr)
        return {}, {}, {}, {}

def find_alternative_course_files(program):
    """Look for alternative course files for the specified program."""
    if program == "BN":
        base_dirs = [
            os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BN", "BN-COURSES"),
            os.path.join(BASE_DIR, "BN", "BN-COURSES"),
            os.path.join(BASE_DIR, "COURSES"),
            os.path.join(BASE_DIR, "EXAMS_INTERNAL"),
        ]
    elif program == "BM":
        base_dirs = [
            os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BM", "BM-COURSES"),
            os.path.join(BASE_DIR, "BM", "BM-COURSES"),
            os.path.join(BASE_DIR, "COURSES"),
            os.path.join(BASE_DIR, "EXAMS_INTERNAL"),
        ]
    else:  # ND
        base_dirs = [
            os.path.join(BASE_DIR, "EXAMS_INTERNAL", "ND", "ND-COURSES"),
            os.path.join(BASE_DIR, "ND", "ND-COURSES"),
            os.path.join(BASE_DIR, "COURSES"),
            os.path.join(BASE_DIR, "EXAMS_INTERNAL"),
        ]
    
    course_files = []
    for base_dir in base_dirs:
        if os.path.exists(base_dir):
            for file in os.listdir(base_dir):
                if 'course' in file.lower() and file.endswith(('.xlsx', '.xls')):
                    full_path = os.path.join(base_dir, file)
                    course_files.append(full_path)
                    print_info(f"üìÅ Found {program} course file: {full_path}")
    
    return course_files

def debug_course_matching(resit_file_path, course_code_to_title, course_code_to_unit, program):
    """Debug function to check why course codes aren't matching - ENHANCED."""
    print_info(f"\nüîç DEBUGGING {program} COURSE MATCHING")
    print_info("=" * 50)
    
    # Read resit file to see what course codes we have
    resit_df = pd.read_excel(resit_file_path, header=0)
    resit_exam_col = find_exam_number_column(resit_df)
    
    # Get all course codes from resit file
    resit_courses = []
    for col in resit_df.columns:
        if col != resit_exam_col and col != 'NAME' and not 'Unnamed' in str(col):
            resit_courses.append(col)
    
    print_info(f"üìã {program} Course codes from resit file: {resit_courses}")
    print_info(f"üìä Total courses in {program} resit file: {len(resit_courses)}")
    
    # Check each resit course against course file
    for course in resit_courses:
        print_info(f"\nüîç Checking {program} course: '{course}'")
        original_code = str(course).strip()
        
        # Generate ENHANCED variants for matching
        variants = [
            original_code.upper().strip(),
            original_code.strip(),
            original_code.upper(),
            original_code,
            original_code.lower(),
            original_code.title(),
            original_code.upper().replace(' ', ''),
            original_code.replace(' ', ''),
            re.sub(r'\s+', '', original_code.upper()),
            re.sub(r'\s+', '', original_code),
            re.sub(r'[^a-zA-Z0-9]', '', original_code.upper()),
            re.sub(r'[^a-zA-Z0-9]', '', original_code),
            original_code.upper().replace('-', ''),
            original_code.upper().replace('_', ''),
            original_code.replace('-', '').replace('_', ''),
            original_code.upper().replace('-', '').replace('_', '').replace(' ', ''),
            f"NUR{original_code.upper()}",
            f"NUR{original_code.upper().replace(' ', '')}",
            f"NSC{original_code.upper()}",
            f"NSC{original_code.upper().replace(' ', '')}",
            original_code.upper().replace('NUR', '').strip(),
            original_code.upper().replace('NSC', '').strip(),
            re.sub(r'^(NUR|NSC)', '', original_code.upper()).strip(),
            re.sub(r'[^0-9]', '', original_code),
            original_code.upper().replace('.', ''),
            original_code.replace('.', ''),
        ]
        
        # Remove duplicates
        variants = list(dict.fromkeys([v for v in variants if v and v != 'NAN']))
        
        print_info(f"   Generated {len(variants)} variants to try")
        
        found = False
        for variant in variants:
            if variant in course_code_to_title:
                title = course_code_to_title[variant]
                unit = course_code_to_unit.get(variant, 0)
                print_info(f"   ‚úÖ FOUND: '{variant}' -> '{title}' (CU: {unit})")
                found = True
                break
        
        if not found:
            print_info(f"   ‚ùå NOT FOUND: No match for '{course}'")
            # Show some similar keys from course file
            similar_keys = []
            # Check for partial matches
            for key in list(course_code_to_title.keys())[:50]:  # Check first 50 keys
                if any(part in key.upper() for part in original_code.upper().split() if len(part) > 2):
                    similar_keys.append(key)
            
            if similar_keys:
                print_info(f"   üí° Similar keys found: {similar_keys[:5]}")
            else:
                print_info(f"   üí° Sample available keys: {list(course_code_to_title.keys())[:10]}")

def find_course_title(course_code, course_titles_dict, course_code_to_title):
    """Robust function to find course title with comprehensive matching strategies - ENHANCED."""
    if not course_code or str(course_code).upper() in ['NAN', 'NONE', '']:
        return str(course_code) if course_code else "Unknown Course"
    
    original_code = str(course_code).strip()
    
    # Generate ENHANCED comprehensive matching variants
    variants = [
        # Basic normalizations
        original_code.upper().strip(),
        original_code.strip(),
        original_code.upper(),
        original_code,
        original_code.lower(),
        original_code.title(),
        
        # Space handling variations
        original_code.upper().replace(' ', ''),
        original_code.replace(' ', ''),
        re.sub(r'\s+', '', original_code.upper()),
        re.sub(r'\s+', '', original_code),
        
        # Special character handling
        re.sub(r'[^a-zA-Z0-9]', '', original_code.upper()),
        re.sub(r'[^a-zA-Z0-9]', '', original_code),
        
        # Common formatting issues
        original_code.upper().replace('-', ''),
        original_code.upper().replace('_', ''),
        original_code.replace('-', '').replace('_', ''),
        original_code.upper().replace('-', '').replace('_', '').replace(' ', ''),
        
        # WITH common prefixes
        f"NUR{original_code.upper()}",
        f"NUR{original_code.upper().replace(' ', '')}",
        f"NUR{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        f"NSC{original_code.upper()}",
        f"NSC{original_code.upper().replace(' ', '')}",
        f"NSC{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        
        # WITHOUT common prefixes
        original_code.upper().replace('NUR', '').strip(),
        original_code.upper().replace('NSC', '').strip(),
        re.sub(r'^(NUR|NSC)', '', original_code.upper()).strip(),
        re.sub(r'^(NUR|NSC)', '', original_code.upper()).replace(' ', '').strip(),
        
        # Number-focused variants
        re.sub(r'[^0-9]', '', original_code),
        
        # Dot removal
        original_code.upper().replace('.', ''),
        original_code.replace('.', ''),
    ]
    
    # Remove duplicates
    variants = list(dict.fromkeys([v for v in variants if v and v != 'NAN']))
    
    # Try each strategy in order
    for variant in variants:
        # Try course_titles_dict first (semester-specific)
        if variant in course_titles_dict:
            title = course_titles_dict[variant]
            print_info(f"‚úÖ Found title for '{original_code}' using variant '{variant}': '{title}'")
            return title
        
        # Try global course_code_to_title
        if variant in course_code_to_title:
            title = course_code_to_title[variant]
            print_info(f"‚úÖ Found title for '{original_code}' using global variant '{variant}': '{title}'")
            return title
    
    # If no match found, log and return descriptive original code
    print_warning(f"‚ö†Ô∏è Could not find course title for: '{original_code}'")
    print_info(f"   Tried {len(variants)} variants without success")
    return f"{original_code} (Title Not Found)"

def find_credit_unit(course_code, credit_units_dict, course_code_to_unit):
    """Robust function to find credit unit with comprehensive matching strategies - ENHANCED."""
    if not course_code or str(course_code).upper() in ['NAN', 'NONE', '']:
        return 0
    
    original_code = str(course_code).strip()
    
    # Generate the same ENHANCED variants as title matching
    variants = [
        original_code.upper().strip(),
        original_code.strip(),
        original_code.upper(),
        original_code,
        original_code.lower(),
        original_code.title(),
        original_code.upper().replace(' ', ''),
        original_code.replace(' ', ''),
        re.sub(r'\s+', '', original_code.upper()),
        re.sub(r'\s+', '', original_code),
        re.sub(r'[^a-zA-Z0-9]', '', original_code.upper()),
        re.sub(r'[^a-zA-Z0-9]', '', original_code),
        original_code.upper().replace('-', ''),
        original_code.upper().replace('_', ''),
        original_code.replace('-', '').replace('_', ''),
        original_code.upper().replace('-', '').replace('_', '').replace(' ', ''),
        f"NUR{original_code.upper()}",
        f"NUR{original_code.upper().replace(' ', '')}",
        f"NUR{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        f"NSC{original_code.upper()}",
        f"NSC{original_code.upper().replace(' ', '')}",
        f"NSC{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        original_code.upper().replace('NUR', '').strip(),
        original_code.upper().replace('NSC', '').strip(),
        re.sub(r'^(NUR|NSC)', '', original_code.upper()).strip(),
        re.sub(r'^(NUR|NSC)', '', original_code.upper()).replace(' ', '').strip(),
        re.sub(r'[^0-9]', '', original_code),
        original_code.upper().replace('.', ''),
        original_code.replace('.', ''),
    ]
    
    # Remove duplicates
    variants = list(dict.fromkeys([v for v in variants if v and v != 'NAN']))
    
    # Try each strategy
    for variant in variants:
        if variant in credit_units_dict:
            unit = credit_units_dict[variant]
            return unit
        
        if variant in course_code_to_unit:
            unit = course_code_to_unit[variant]
            return unit
    
    print_warning(f"‚ö†Ô∏è Could not find credit unit for: '{original_code}', defaulting to 2")
    return 2  # Default credit unit

def get_semester_display_info(semester_key, program):
    """Get display information for a semester key based on program."""
    semester_lower = semester_key.lower()
    
    if program == "BN":
        if 'first-year-first-semester' in semester_lower:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "BN1", "Semester 1"
        elif 'first-year-second-semester' in semester_lower:
            return 1, 2, "YEAR ONE", "SECOND SEMESTER", "BN1", "Semester 2"
        elif 'second-year-first-semester' in semester_lower:
            return 2, 1, "YEAR TWO", "FIRST SEMESTER", "BN2", "Semester 3"
        elif 'second-year-second-semester' in semester_lower:
            return 2, 2, "YEAR TWO", "SECOND SEMESTER", "BN2", "Semester 4"
        elif 'third-year-first-semester' in semester_lower:
            return 3, 1, "YEAR THREE", "FIRST SEMESTER", "BN3", "Semester 5"
        elif 'third-year-second-semester' in semester_lower:
            return 3, 2, "YEAR THREE", "SECOND SEMESTER", "BN3", "Semester 6"
        else:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "BN1", "Semester 1"
    elif program == "BM":
        if 'first-year-first-semester' in semester_lower:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "BM1", "Semester 1"
        elif 'first-year-second-semester' in semester_lower:
            return 1, 2, "YEAR ONE", "SECOND SEMESTER", "BM1", "Semester 2"
        elif 'second-year-first-semester' in semester_lower:
            return 2, 1, "YEAR TWO", "FIRST SEMESTER", "BM2", "Semester 3"
        elif 'second-year-second-semester' in semester_lower:
            return 2, 2, "YEAR TWO", "SECOND SEMESTER", "BM2", "Semester 4"
        elif 'third-year-first-semester' in semester_lower:
            return 3, 1, "YEAR THREE", "FIRST SEMESTER", "BM3", "Semester 5"
        elif 'third-year-second-semester' in semester_lower:
            return 3, 2, "YEAR THREE", "SECOND SEMESTER", "BM3", "Semester 6"
        else:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "BM1", "Semester 1"
    else:  # ND
        if 'first-year-first-semester' in semester_lower:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "NDI", "Semester 1"
        elif 'first-year-second-semester' in semester_lower:
            return 1, 2, "YEAR ONE", "SECOND SEMESTER", "NDI", "Semester 2"
        elif 'second-year-first-semester' in semester_lower:
            return 2, 1, "YEAR TWO", "FIRST SEMESTER", "NDII", "Semester 3"
        elif 'second-year-second-semester' in semester_lower:
            return 2, 2, "YEAR TWO", "SECOND SEMESTER", "NDII", "Semester 4"
        else:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "NDI", "Semester 1"

def get_grade_point(score):
    """Determine grade point based on score - NIGERIAN 5.0 SCALE."""
    try:
        score = float(score)
        if score >= 70: return 5.0
        elif score >= 60: return 4.0
        elif score >= 50: return 3.0
        elif score >= 45: return 2.0
        elif score >= 40: return 1.0
        else: return 0.0
    except (ValueError, TypeError):
        return 0.0

def extract_mastersheet_from_zip(zip_path, semester_key):
    """Extract mastersheet from ZIP file and return temporary file path."""
    try:
        print_info(f"üì¶ Looking for mastersheet in ZIP: {zip_path}")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            all_files = zip_ref.namelist()
            print_info(f"üìÅ Files in ZIP: {all_files}")
            
            mastersheet_files = [f for f in all_files if 'mastersheet' in f.lower() and f.endswith('.xlsx')]
            
            if not mastersheet_files:
                print_error(f"‚ùå No mastersheet found in ZIP")
                return None, None
            
            mastersheet_name = mastersheet_files[0]
            print_info(f"‚úÖ Found mastersheet: {mastersheet_name}")
            
            temp_dir = tempfile.mkdtemp()
            temp_mastersheet_path = os.path.join(temp_dir, f"mastersheet_{semester_key}.xlsx")
            
            with open(temp_mastersheet_path, 'wb') as f:
                f.write(zip_ref.read(mastersheet_name))
            
            print_info(f"‚úÖ Extracted mastersheet to: {temp_mastersheet_path}")
            return temp_mastersheet_path, temp_dir
            
    except Exception as e:
        print_error(f"‚ùå Error extracting mastersheet from ZIP: {e}")
        traceback.print_exc(file=sys.stderr)
        return None, None

def find_latest_zip_file(clean_dir, program):
    """Find the latest ZIP file in clean results directory."""
    print_info(f"üîç Looking for {program} ZIP files in: {clean_dir}")
    
    if not os.path.exists(clean_dir):
        print_error(f"‚ùå {program} clean directory doesn't exist: {clean_dir}")
        return None
    
    all_files = os.listdir(clean_dir)
    
    zip_files = []
    for f in all_files:
        if f.lower().endswith('.zip'):
            if 'carryover' in f.lower():
                print_info(f"‚ö†Ô∏è Skipping {program} carryover ZIP: {f}")
                continue
            
            if any(pattern in f for pattern in ['_RESULT-', 'RESULT_', 'RESULT-']):
                zip_files.append(f)
                print_info(f"‚úÖ Found {program} regular results ZIP: {f}")
            else:
                print_info(f"‚ÑπÔ∏è Found other {program} ZIP (not a result file): {f}")
    
    if not zip_files:
        print_error(f"‚ùå No {program} regular results ZIP files found (excluding carryover files)")
        fallback_zips = [f for f in all_files if f.lower().endswith('.zip') and 'carryover' not in f.lower()]
        if fallback_zips:
            print_warning(f"‚ö†Ô∏è Using fallback {program} ZIP files: {fallback_zips}")
            zip_files = fallback_zips
        else:
            print_error(f"‚ùå No {program} ZIP files found at all in {clean_dir}")
            return None
    
    print_info(f"‚úÖ Final {program} ZIP files to consider: {zip_files}")
    
    zip_files_with_path = [os.path.join(clean_dir, f) for f in zip_files]
    latest_zip = sorted(zip_files_with_path, key=os.path.getmtime, reverse=True)[0]
    
    print_info(f"üéØ Using latest {program} ZIP: {latest_zip}")
    return latest_zip

def find_latest_result_folder(clean_dir, set_name, program):
    """Find the latest result folder in clean results directory."""
    print_info(f"üîç Looking for {program} result folders in: {clean_dir}")
    
    if not os.path.exists(clean_dir):
        print_error(f"‚ùå {program} clean directory doesn't exist: {clean_dir}")
        return None
    
    all_items = os.listdir(clean_dir)
    
    result_folders = [f for f in all_items if os.path.isdir(os.path.join(clean_dir, f)) and f.startswith(f"{set_name}_RESULT-")]
    
    if not result_folders:
        print_error(f"‚ùå No {program} result folders found")
        return None
    
    print_info(f"‚úÖ Found {program} result folders: {result_folders}")
    
    folders_with_path = [os.path.join(clean_dir, f) for f in result_folders]
    latest_folder = sorted(folders_with_path, key=os.path.getmtime, reverse=True)[0]
    
    print_info(f"üéØ Using latest {program} result folder: {latest_folder}")
    return latest_folder

def find_latest_mastersheet_source(clean_dir, set_name, program):
    """Find the latest source for mastersheet: prefer ZIP, fallback to folder."""
    print_info(f"üîç Looking for {program} mastersheet source in: {clean_dir}")
    
    if not os.path.exists(clean_dir):
        print_error(f"‚ùå {program} clean directory doesn't exist: {clean_dir}")
        return None, None
    
    zip_path = find_latest_zip_file(clean_dir, program)
    if zip_path:
        print_info(f"‚úÖ Using {program} ZIP source: {zip_path}")
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_files = zip_ref.namelist()
                mastersheet_files = [f for f in zip_files if 'mastersheet' in f.lower() and f.endswith('.xlsx')]
                if mastersheet_files:
                    print_info(f"‚úÖ {program} ZIP contains mastersheet files: {mastersheet_files}")
                    return zip_path, 'zip'
                else:
                    print_warning(f"‚ö†Ô∏è {program} ZIP found but no mastersheet inside: {zip_path}")
        except Exception as e:
            print_warning(f"‚ö†Ô∏è Error checking {program} ZIP contents: {e}")
    
    folder_path = find_latest_result_folder(clean_dir, set_name, program)
    if folder_path:
        print_info(f"‚úÖ Using {program} folder source: {folder_path}")
        return folder_path, 'folder'
    
    print_error(f"‚ùå No valid {program} ZIP files or result folders found in {clean_dir}")
    return None, None

def get_mastersheet_path(source_path, source_type, semester_key):
    """Get mastersheet path based on source type (zip or folder) - FIXED WITH RECURSIVE SEARCH."""
    temp_dir = None
    if source_type == 'zip':
        temp_mastersheet_path, temp_dir = extract_mastersheet_from_zip(source_path, semester_key)
        if not temp_mastersheet_path:
            print_error("‚ùå Failed to extract mastersheet from ZIP")
            return None, None
    elif source_type == 'folder':
        # Recursive search for mastersheet in folder
        mastersheet_files = glob.glob(os.path.join(source_path, '**', '*mastersheet*.xlsx'), recursive=True)
        if not mastersheet_files:
            mastersheet_files = glob.glob(os.path.join(source_path, '**', '*.xlsx'), recursive=True)
        
        if not mastersheet_files:
            print_error(f"‚ùå No mastersheet found in folder {source_path}")
            return None, None
        
        temp_mastersheet_path = mastersheet_files[0]
        print_info(f"‚úÖ Found mastersheet in folder: {temp_mastersheet_path}")
    else:
        return None, None
    
    return temp_mastersheet_path, temp_dir

def get_matching_sheet(xl, target_key):
    """Find matching sheet name with variants."""
    target_upper = target_key.upper().replace('-', ' ').replace('_', ' ').replace('.', ' ')
    target_upper = ' '.join(target_upper.split())
    
    possible_keys = [
        target_key,
        target_key.upper(),
        target_key.lower(),
        target_key.title(),
        target_key.replace('-', ' ').upper(),
        target_key.replace('-', ' ').lower(),
        target_key.replace('-', ' ').title(),
        target_key.replace('-', '_').upper(),
        target_key.replace('-', '_').lower(),
        target_key.replace('-', '_').title(),
        target_key.replace('First', '1st'),
        target_key.replace('Second', '2nd'),
        target_key.replace('Third', '3rd'),
        target_key.replace('YEAR', 'YR'),
        target_key.replace('SEMESTER', 'SEM'),
        target_upper,
        target_upper.replace('FIRST', '1ST'),
        target_upper.replace('SECOND', '2ND'),
        target_upper.replace('THIRD', '3RD'),
        target_upper.replace('YEAR', 'YR'),
        target_upper.replace('SEMESTER', 'SEM'),
    ]
    
    possible_keys = list(set([k for k in possible_keys if k]))
    
    print_info(f"üîç Trying sheet variants for '{target_key}': {possible_keys}")
    
    for sheet in xl.sheet_names:
        sheet_normalized = sheet.upper().replace('-', ' ').replace('_', ' ').replace('.', ' ')
        sheet_normalized = ' '.join(sheet_normalized.split())
        
        if any(p == sheet or p in sheet or p == sheet_normalized or p in sheet_normalized for p in possible_keys):
            print_info(f"‚úÖ Found matching sheet: '{sheet}' for '{target_key}'")
            return sheet
    
    print_error(f"‚ùå No matching sheet found for '{target_key}'")
    print_info(f"üìñ Available sheets: {xl.sheet_names}")
    return None

def load_previous_gpas(mastersheet_path, current_semester_key, program):
    """Load previous GPA data from mastersheet for CGPA calculation."""
    all_student_data = {}
    current_standard = standardize_semester_key(current_semester_key, program)
    
    if program == "BN":
        all_semesters = {
            "N-FIRST-YEAR-FIRST-SEMESTER": [],
            "N-FIRST-YEAR-SECOND-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER"],
            "N-SECOND-YEAR-FIRST-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER"],
            "N-SECOND-YEAR-SECOND-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER"],
            "N-THIRD-YEAR-FIRST-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER", "N-SECOND-YEAR-SECOND-SEMESTER"],
            "N-THIRD-YEAR-SECOND-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER", "N-SECOND-YEAR-SECOND-SEMESTER", "N-THIRD-YEAR-FIRST-SEMESTER"]
        }
    elif program == "BM":
        all_semesters = {
            "M-FIRST-YEAR-FIRST-SEMESTER": [],
            "M-FIRST-YEAR-SECOND-SEMESTER": ["M-FIRST-YEAR-FIRST-SEMESTER"],
            "M-SECOND-YEAR-FIRST-SEMESTER": ["M-FIRST-YEAR-FIRST-SEMESTER", "M-FIRST-YEAR-SECOND-SEMESTER"],
            "M-SECOND-YEAR-SECOND-SEMESTER": ["M-FIRST-YEAR-FIRST-SEMESTER", "M-FIRST-YEAR-SECOND-SEMESTER", "M-SECOND-YEAR-FIRST-SEMESTER"],
            "M-THIRD-YEAR-FIRST-SEMESTER": ["M-FIRST-YEAR-FIRST-SEMESTER", "M-FIRST-YEAR-SECOND-SEMESTER", "M-SECOND-YEAR-FIRST-SEMESTER", "M-SECOND-YEAR-SECOND-SEMESTER"],
            "M-THIRD-YEAR-SECOND-SEMESTER": ["M-FIRST-YEAR-FIRST-SEMESTER", "M-FIRST-YEAR-SECOND-SEMESTER", "M-SECOND-YEAR-FIRST-SEMESTER", "M-SECOND-YEAR-SECOND-SEMESTER", "M-THIRD-YEAR-FIRST-SEMESTER"]
        }
    else:
        all_semesters = {
            "ND-FIRST-YEAR-FIRST-SEMESTER": [],
            "ND-FIRST-YEAR-SECOND-SEMESTER": ["ND-FIRST-YEAR-FIRST-SEMESTER"],
            "ND-SECOND-YEAR-FIRST-SEMESTER": ["ND-FIRST-YEAR-FIRST-SEMESTER", "ND-FIRST-YEAR-SECOND-SEMESTER"],
            "ND-SECOND-YEAR-SECOND-SEMESTER": ["ND-FIRST-YEAR-FIRST-SEMESTER", "ND-FIRST-YEAR-SECOND-SEMESTER", "ND-SECOND-YEAR-FIRST-SEMESTER"]
        }
    
    semesters_to_load = all_semesters.get(current_standard, [])
    print_info(f"üìä Loading previous {program} GPAs for {current_standard}: {semesters_to_load}")

    if not os.path.exists(mastersheet_path):
        print_error(f"‚ùå {program} Mastersheet not found: {mastersheet_path}")
        return {}

    try:
        xl = pd.ExcelFile(mastersheet_path)
        print_info(f"üìñ Available sheets in {program} mastersheet: {xl.sheet_names}")
    except Exception as e:
        print_error(f"‚ùå Error opening {program} mastersheet: {e}")
        return {}

    for semester in semesters_to_load:
        try:
            sheet_name = get_matching_sheet(xl, semester)
            if not sheet_name:
                print_warning(f"‚ö†Ô∏è Skipping {program} semester {semester} - no matching sheet found")
                continue
            
            print_info(f"üìñ Reading {program} sheet '{sheet_name}' for semester {semester}")
            df = load_excel_with_header_detection(mastersheet_path, sheet_name)
            
            if df is None:
                print_warning(f"‚ö†Ô∏è Skipping {program} semester {semester} - could not load with header detection")
                continue
            
            exam_col = find_exam_number_column(df)
            gpa_col = None
            credit_col = None
            
            for col in df.columns:
                col_str = str(col).upper()
                if 'GPA' in col_str and 'CGPA' not in col_str:
                    gpa_col = col
                if 'CU PASSED' in col_str or 'CREDIT' in col_str or 'UNIT' in col_str:
                    credit_col = col
            
            print_info(f"üîç Columns found - Exam: {exam_col}, GPA: {gpa_col}, Credits: {credit_col}")
            
            if exam_col and gpa_col:
                for idx, row in df.iterrows():
                    try:
                        exam_no = str(row[exam_col]).strip()
                        if pd.isna(exam_no) or exam_no in ['', 'NAN', 'NONE']:
                            continue
                            
                        gpa_value = row[gpa_col]
                        if pd.isna(gpa_value):
                            continue
                            
                        credits = 30
                        if credit_col and credit_col in row and pd.notna(row[credit_col]):
                            try:
                                credits = int(float(row[credit_col]))
                            except (ValueError, TypeError):
                                credits = 30
                        
                        if exam_no not in all_student_data:
                            all_student_data[exam_no] = {'gpas': [], 'credits': [], 'semesters': []}
                        
                        all_student_data[exam_no]['gpas'].append(float(gpa_value))
                        all_student_data[exam_no]['credits'].append(credits)
                        all_student_data[exam_no]['semesters'].append(semester)
                        
                        if idx < 3:
                            print_info(f"üìä Loaded {program} GPA for {exam_no}: {gpa_value} with {credits} credits from {semester}")
                            
                    except (ValueError, TypeError) as e:
                        print_warning(f"‚ö†Ô∏è Error processing row {idx} for {program} {semester}: {e}")
                        continue
            else:
                print_warning(f"‚ö†Ô∏è Missing required columns in {program} {sheet_name}: exam_col={exam_col}, gpa_col={gpa_col}")
                
        except Exception as e:
            print_warning(f"‚ö†Ô∏è Could not load data from {program} {semester}: {e}")
            traceback.print_exc(file=sys.stderr)
    
    print_info(f"üìä Loaded cumulative {program} data for {len(all_student_data)} students")
    return all_student_data

def calculate_cgpa(student_data, current_gpa, current_credits, program):
    """Calculate Cumulative GPA for all programs."""
    if not student_data or not student_data.get('gpas'):
        print_warning(f"‚ö†Ô∏è No previous {program} GPA data, using current GPA: {current_gpa}")
        return current_gpa

    total_grade_points = 0.0
    total_credits = 0

    print_info(f"üî¢ Calculating {program} CGPA from {len(student_data['gpas'])} previous semesters")
    
    for prev_gpa, prev_credits in zip(student_data['gpas'], student_data['credits']):
        total_grade_points += prev_gpa * prev_credits
        total_credits += prev_credits
        print_info(f"   - GPA: {prev_gpa}, Credits: {prev_credits}, Running Total: {total_grade_points}/{total_credits}")

    total_grade_points += current_gpa * current_credits
    total_credits += current_credits

    print_info(f"üìä Final {program} calculation: {total_grade_points} / {total_credits}")

    if total_credits > 0:
        cgpa = round(total_grade_points / total_credits, 2)
        print_info(f"‚úÖ Calculated {program} CGPA: {cgpa}")
        return cgpa
    else:
        print_warning(f"‚ö†Ô∏è No {program} credits, returning current GPA: {current_gpa}")
        return current_gpa

def get_previous_semesters_for_display(current_semester_key, program):
    """Get list of previous semesters for GPA display in mastersheet."""
    current_standard = standardize_semester_key(current_semester_key, program)
    
    if program == "BN":
        semester_mapping = {
            "N-FIRST-YEAR-FIRST-SEMESTER": [],
            "N-FIRST-YEAR-SECOND-SEMESTER": ["Semester 1"],
            "N-SECOND-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2"], 
            "N-SECOND-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3"],
            "N-THIRD-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2", "Semester 3", "Semester 4"],
            "N-THIRD-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3", "Semester 4", "Semester 5"]
        }
    elif program == "BM":
        semester_mapping = {
            "M-FIRST-YEAR-FIRST-SEMESTER": [],
            "M-FIRST-YEAR-SECOND-SEMESTER": ["Semester 1"],
            "M-SECOND-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2"], 
            "M-SECOND-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3"],
            "M-THIRD-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2", "Semester 3", "Semester 4"],
            "M-THIRD-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3", "Semester 4", "Semester 5"]
        }
    else:
        semester_mapping = {
            "ND-FIRST-YEAR-FIRST-SEMESTER": [],
            "ND-FIRST-YEAR-SECOND-SEMESTER": ["Semester 1"],
            "ND-SECOND-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2"], 
            "ND-SECOND-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3"]
        }
    
    return semester_mapping.get(current_standard, [])

def extract_semester_from_filename(filename):
    """Extract semester from filename using comprehensive pattern matching - FIXED with BM support."""
    filename_upper = filename.upper()
    
    # First try to extract any semester-like pattern from filename
    semester_pattern = r'((?:N|M|ND)[-_]?(?:FIRST|SECOND|THIRD|1ST|2ND|3RD)[-_]?YEAR[-_]?(?:FIRST|SECOND|1ST|2ND)[-_]?SEMESTER)'
    match = re.search(semester_pattern, filename_upper)
    
    if match:
        extracted = match.group(1)
        # Determine program from prefix
        if extracted.startswith(('N-', 'N_')):
            program = "BN"
        elif extracted.startswith(('M-', 'M_')):
            program = "BM"
        else:
            program = "ND"
        
        # Standardize the extracted pattern with program context
        standardized = standardize_semester_key(extracted, program)
        print_info(f"‚úÖ Extracted and standardized: '{filename}' ‚Üí '{standardized}'")
        return standardized
    
    # Fallback to comprehensive pattern mapping
    semester_patterns = {
        # BN patterns
        "N-FIRST-YEAR-FIRST-SEMESTER": [
            "N.FIRST YEAR.FIRST SEMESTER", "N-FIRST-YEAR-FIRST-SEMESTER", "N_FIRST_YEAR_FIRST_SEMESTER",
            "FIRST YEAR.FIRST SEMESTER", "FIRST-YEAR-FIRST-SEMESTER", "FIRST_YEAR_FIRST_SEMESTER",
            "1ST YEAR.1ST SEMESTER", "1ST-YEAR-1ST-SEMESTER", "1ST_YEAR_1ST_SEMESTER",
            "YEAR1.SEMESTER1", "YEAR-1-SEMESTER-1", "YEAR_1_SEMESTER_1"
        ],
        "N-FIRST-YEAR-SECOND-SEMESTER": [
            "N.FIRST YEAR.SECOND SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N_FIRST_YEAR_SECOND_SEMESTER",
            "FIRST YEAR.SECOND SEMESTER", "FIRST-YEAR-SECOND-SEMESTER", "FIRST_YEAR_SECOND_SEMESTER",
            "1ST YEAR.2ND SEMESTER", "1ST-YEAR-2ND-SEMESTER", "1ST_YEAR_2ND_SEMESTER",
            "YEAR1.SEMESTER2", "YEAR-1-SEMESTER-2", "YEAR_1_SEMESTER_2"
        ],
        "N-SECOND-YEAR-FIRST-SEMESTER": [
            "N.SECOND YEAR.FIRST SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER", "N_SECOND_YEAR_FIRST_SEMESTER",
            "SECOND YEAR.FIRST SEMESTER", "SECOND-YEAR-FIRST-SEMESTER", "SECOND_YEAR_FIRST_SEMESTER",
            "2ND YEAR.1ST SEMESTER", "2ND-YEAR-1ST-SEMESTER", "2ND_YEAR_1ST_SEMESTER",
            "YEAR2.SEMESTER1", "YEAR-2-SEMESTER-1", "YEAR_2_SEMESTER_1"
        ],
        "N-SECOND-YEAR-SECOND-SEMESTER": [
            "N.SECOND YEAR.SECOND SEMESTER", "N-SECOND-YEAR-SECOND-SEMESTER", "N_SECOND_YEAR_SECOND_SEMESTER",
            "SECOND YEAR.SECOND SEMESTER", "SECOND-YEAR-SECOND-SEMESTER", "SECOND_YEAR_SECOND_SEMESTER",
            "2ND YEAR.2ND SEMESTER", "2ND-YEAR-2ND-SEMESTER", "2ND_YEAR_2ND_SEMESTER",
            "YEAR2.SEMESTER2", "YEAR-2-SEMESTER-2", "YEAR_2_SEMESTER_2"
        ],
        "N-THIRD-YEAR-FIRST-SEMESTER": [
            "N.THIRD YEAR.FIRST SEMESTER", "N-THIRD-YEAR-FIRST-SEMESTER", "N_THIRD_YEAR_FIRST_SEMESTER",
            "THIRD YEAR.FIRST SEMESTER", "THIRD-YEAR-FIRST-SEMESTER", "THIRD_YEAR_FIRST_SEMESTER",
            "3RD YEAR.1ST SEMESTER", "3RD-YEAR-1ST-SEMESTER", "3RD_YEAR_1ST_SEMESTER",
            "YEAR3.SEMESTER1", "YEAR-3-SEMESTER-1", "YEAR_3_SEMESTER_1"
        ],
        "N-THIRD-YEAR-SECOND-SEMESTER": [
            "N.THIRD YEAR.SECOND SEMESTER", "N-THIRD-YEAR-SECOND-SEMESTER", "N_THIRD_YEAR_SECOND_SEMESTER",
            "THIRD YEAR.SECOND SEMESTER", "THIRD-YEAR-SECOND-SEMESTER", "THIRD_YEAR_SECOND_SEMESTER",
            "3RD YEAR.2ND SEMESTER", "3RD-YEAR-2ND-SEMESTER", "3RD_YEAR_2ND_SEMESTER",
            "YEAR3.SEMESTER2", "YEAR-3-SEMESTER-2", "YEAR_3_SEMESTER_2"
        ],
        
        # BM patterns (added M- variants)
        "M-FIRST-YEAR-FIRST-SEMESTER": [
            "M.FIRST YEAR.FIRST SEMESTER", "M-FIRST-YEAR-FIRST-SEMESTER", "M_FIRST_YEAR_FIRST_SEMESTER",
            "M.FIRST YEAR.1ST SEMESTER", "M-FIRST-YEAR-1ST-SEMESTER", "M_FIRST_YEAR_1ST_SEMESTER",
            "M YEAR1.SEMESTER1", "M-YEAR-1-SEMESTER-1", "M_YEAR_1_SEMESTER_1"
        ],
        "M-FIRST-YEAR-SECOND-SEMESTER": [
            "M.FIRST YEAR.SECOND SEMESTER", "M-FIRST-YEAR-SECOND-SEMESTER", "M_FIRST_YEAR_SECOND_SEMESTER",
            "M.FIRST YEAR.2ND SEMESTER", "M-FIRST-YEAR-2ND-SEMESTER", "M_FIRST_YEAR_2ND_SEMESTER",
            "M YEAR1.SEMESTER2", "M-YEAR-1-SEMESTER-2", "M_YEAR_1_SEMESTER_2"
        ],
        "M-SECOND-YEAR-FIRST-SEMESTER": [
            "M.SECOND YEAR.FIRST SEMESTER", "M-SECOND-YEAR-FIRST-SEMESTER", "M_SECOND_YEAR_FIRST_SEMESTER",
            "M.SECOND YEAR.1ST SEMESTER", "M-SECOND-YEAR-1ST-SEMESTER", "M_SECOND_YEAR_1ST_SEMESTER",
            "M YEAR2.SEMESTER1", "M-YEAR-2-SEMESTER-1", "M_YEAR_2_SEMESTER_1"
        ],
        "M-SECOND-YEAR-SECOND-SEMESTER": [
            "M.SECOND YEAR.SECOND SEMESTER", "M-SECOND-YEAR-SECOND-SEMESTER", "M_SECOND_YEAR_SECOND_SEMESTER",
            "M.SECOND YEAR.2ND SEMESTER", "M-SECOND-YEAR-2ND-SEMESTER", "M_SECOND_YEAR_2ND_SEMESTER",
            "M YEAR2.SEMESTER2", "M-YEAR-2-SEMESTER-2", "M_YEAR_2_SEMESTER_2"
        ],
        "M-THIRD-YEAR-FIRST-SEMESTER": [
            "M.THIRD YEAR.FIRST SEMESTER", "M-THIRD-YEAR-FIRST-SEMESTER", "M_THIRD_YEAR_FIRST_SEMESTER",
            "M.THIRD YEAR.1ST SEMESTER", "M-THIRD-YEAR-1ST-SEMESTER", "M_THIRD_YEAR_1ST_SEMESTER",
            "M YEAR3.SEMESTER1", "M-YEAR-3-SEMESTER-1", "M_YEAR_3_SEMESTER_1"
        ],
        "M-THIRD-YEAR-SECOND-SEMESTER": [
            "M.THIRD YEAR.SECOND SEMESTER", "M-THIRD-YEAR-SECOND-SEMESTER", "M_THIRD_YEAR_SECOND_SEMESTER",
            "M.THIRD YEAR.2ND SEMESTER", "M-THIRD-YEAR-2ND-SEMESTER", "M_THIRD_YEAR_2ND_SEMESTER",
            "M YEAR3.SEMESTER2", "M-YEAR-3-SEMESTER-2", "M_YEAR_3_SEMESTER_2"
        ]
    }
    
    for semester_key, patterns in semester_patterns.items():
        for pattern in patterns:
            flexible_pattern = pattern.replace('.', '[ ._ -]?')
            if re.search(flexible_pattern, filename_upper, re.IGNORECASE):
                print_info(f"‚úÖ Matched semester '{semester_key}' for filename: {filename}")
                return semester_key
    
    print_error(f"‚ùå Could not determine semester for filename: {filename}")
    return "UNKNOWN_SEMESTER"

def load_carryover_json_files(carryover_dir, semester_key=None, program=None):
    """Load carryover JSON files from directory."""
    carryover_files = []
    
    if semester_key:
        semester_key = standardize_semester_key(semester_key, program)
    
    previous_semester = get_previous_semester(semester_key, program)
    print_info(f"üîë Target {program} semester: {semester_key}")
    print_info(f"üîë Previous {program} semester for carryover: {previous_semester}")
    
    for file in os.listdir(carryover_dir):
        if file.startswith("co_student_") and file.endswith(".json"):
            file_semester = extract_semester_from_filename(file)
            file_semester_standardized = standardize_semester_key(file_semester, program)
            
            print_info(f"üìÑ Found {program} carryover file: {file}")
            print_info(f"   Original semester: {file_semester}")
            print_info(f"   Standardized: {file_semester_standardized}")
            print_info(f"   Target previous: {previous_semester}")
            
            if previous_semester and file_semester_standardized != previous_semester:
                print_info(f"   ‚è≠Ô∏è Skipping (doesn't match previous {program} semester)")
                continue
            
            file_path = os.path.join(carryover_dir, file)
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                    carryover_files.append({
                        'filename': file,
                        'semester': file_semester_standardized,
                        'data': data,
                        'count': len(data),
                        'file_path': file_path
                    })
                    print_info(f"   ‚úÖ Loaded: {len(data)} {program} records")
            except Exception as e:
                print_error(f"Error loading {program} {file}: {e}")
    
    print_info(f"üìä Total {program} carryover files loaded: {len(carryover_files)}")
    return carryover_files

def get_carryover_records_from_zip(zip_path, set_name, semester_key, program):
    """Get carryover records from ZIP file."""
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            temp_dir = tempfile.mkdtemp()
            carryover_dir = os.path.join(temp_dir, "CARRYOVER_RECORDS")
            os.makedirs(carryover_dir, exist_ok=True)
            for member in zip_ref.namelist():
                if member.startswith("CARRYOVER_RECORDS/"):
                    zip_ref.extract(member, temp_dir)
            records = load_carryover_json_files(carryover_dir, semester_key, program)
            shutil.rmtree(temp_dir)
            print_info(f"‚úÖ Loaded {len(records)} {program} carryover records from ZIP")
            return records
    except Exception as e:
        print_error(f"‚ùå Error loading from {program} ZIP: {e}")
        return []

def get_carryover_records(program, set_name, semester_key=None):
    """Get carryover records for a specific program, set, and semester."""
    try:
        if semester_key:
            semester_key = standardize_semester_key(semester_key, program)
            print_info(f"üîë Using standardized {program} semester key: {semester_key}")
        
        clean_dir = os.path.join(BASE_DIR, program, set_name, "CLEAN_RESULTS")
        if not os.path.exists(clean_dir):
            print_error(f"‚ùå {program} clean directory not found: {clean_dir}")
            return []
        
        timestamp_items = []
        
        for item in os.listdir(clean_dir):
            item_path = os.path.join(clean_dir, item)
            
            if item.startswith(f"{set_name}_RESULT-") and "CARRYOVER" not in item.upper():
                if os.path.isdir(item_path) or item.endswith('.zip'):
                    timestamp_items.append(item)
                    print_info(f"Found {program} regular result: {item}")
        
        if not timestamp_items:
            print_error(f"‚ùå No {program} regular result files found in: {clean_dir}")
            return []
        
        latest_item = sorted(timestamp_items)[-1]
        latest_path = os.path.join(clean_dir, latest_item)
        print_info(f"‚úÖ Using latest {program} result: {latest_item}")
        
        if latest_item.endswith('.zip'):
            return get_carryover_records_from_zip(latest_path, set_name, semester_key, program)
        else:
            carryover_dir = os.path.join(latest_path, "CARRYOVER_RECORDS")
            if not os.path.exists(carryover_dir):
                print_error(f"‚ùå No {program} CARRYOVER_RECORDS folder in: {latest_path}")
                return []
            return load_carryover_json_files(carryover_dir, semester_key, program)
            
    except Exception as e:
        print_error(f"Error getting {program} carryover records: {e}")
        return []

def normalize_exam_number(exam_no):
    """Normalize exam numbers for better matching - NEW FUNCTION"""
    if not exam_no or pd.isna(exam_no):
        return None
    
    exam_str = str(exam_no).strip().upper()
    
    # Remove extra spaces and special characters
    exam_str = re.sub(r'\s+', ' ', exam_str)
    exam_str = re.sub(r'[^\w\s/-]', '', exam_str)
    
    return exam_str

def enhanced_student_matching(resit_df, mastersheet_df, carryover_students, program):
    """Enhanced student matching with multiple strategies"""
    resit_exam_col = find_exam_number_column(resit_df)
    mastersheet_exam_col = find_exam_number_column(mastersheet_df)
    
    if not resit_exam_col or not mastersheet_exam_col:
        print_error(f"‚ùå Could not find exam number columns in {program} data")
        return []
    
    matched_students = []
    
    for _, resit_row in resit_df.iterrows():
        resit_exam_no = str(resit_row[resit_exam_col]).strip()
        if not resit_exam_no or resit_exam_no in ['', 'nan', 'NaN', 'None']:
            continue
            
        # Strategy 1: Direct exact match
        student_found = False
        
        # Check in mastersheet first
        for _, mastersheet_row in mastersheet_df.iterrows():
            mastersheet_exam_no = str(mastersheet_row[mastersheet_exam_col]).strip()
            
            if not mastersheet_exam_no or mastersheet_exam_no in ['', 'nan', 'NaN', 'None']:
                continue
                
            # Multiple matching strategies
            match_strategies = [
                # Exact match
                resit_exam_no == mastersheet_exam_no,
                # Case-insensitive match
                resit_exam_no.upper() == mastersheet_exam_no.upper(),
                # Remove spaces and compare
                resit_exam_no.replace(' ', '') == mastersheet_exam_no.replace(' ', ''),
                # Handle FCTCONS/ prefix variations
                resit_exam_no.replace('FCTCONS/', '') == mastersheet_exam_no,
                mastersheet_exam_no.replace('FCTCONS/', '') == resit_exam_no,
                # Partial matching for ND students
                any(part in mastersheet_exam_no for part in resit_exam_no.split('/') if len(part) > 3),
                any(part in resit_exam_no for part in mastersheet_exam_no.split('/') if len(part) > 3),
            ]
            
            if any(match_strategies):
                matched_students.append({
                    'resit_exam_no': resit_exam_no,
                    'mastersheet_exam_no': mastersheet_exam_no,
                    'resit_row': resit_row,
                    'mastersheet_idx': mastersheet_row.name,
                    'match_type': 'mastersheet'
                })
                student_found = True
                print_info(f"‚úÖ Matched {program} student: {resit_exam_no} -> {mastersheet_exam_no}")
                break
        
        if not student_found:
            print_warning(f"‚ö†Ô∏è {program} Student {resit_exam_no} not found in mastersheet")
    
    print_info(f"üìä {program} Matching results: {len(matched_students)}/{len(resit_df)} students matched")
    return matched_students

def load_bn_carryover_data(base_result_path, semester_key):
    """Load BN carryover data with proper path handling"""
    try:
        print_info(f"üìÇ Loading BN carryover data from: {base_result_path}")
        
        if base_result_path.endswith('.zip'):
            # Handle ZIP file
            with zipfile.ZipFile(base_result_path, 'r') as zip_ref:
                temp_dir = tempfile.mkdtemp()
                zip_ref.extractall(temp_dir)
                
                # Look for BN carryover folders
                carryover_data = []
                for root, dirs, files in os.walk(temp_dir):
                    for dir_name in dirs:
                        if 'CARRYOVER_SET47' in dir_name and semester_key in dir_name:
                            carryover_dir = os.path.join(root, dir_name)
                            for file in os.listdir(carryover_dir):
                                if file.endswith('.json') and 'co_student' in file:
                                    file_path = os.path.join(carryover_dir, file)
                                    with open(file_path, 'r') as f:
                                        data = json.load(f)
                                        carryover_data.extend(data if isinstance(data, list) else [data])
                                    print_info(f"‚úÖ Loaded BN carryover from: {file}")
                
                # Cleanup
                shutil.rmtree(temp_dir)
                return carryover_data
        else:
            # Handle directory
            carryover_data = []
            for item in os.listdir(base_result_path):
                if 'CARRYOVER_SET47' in item and os.path.isdir(os.path.join(base_result_path, item)):
                    carryover_dir = os.path.join(base_result_path, item)
                    for file in os.listdir(carryover_dir):
                        if file.endswith('.json') and 'co_student' in file and semester_key in file:
                            file_path = os.path.join(carryover_dir, file)
                            with open(file_path, 'r') as f:
                                data = json.load(f)
                                carryover_data.extend(data if isinstance(data, list) else [data])
                            print_info(f"‚úÖ Loaded BN carryover from: {file}")
            
            return carryover_data
            
    except Exception as e:
        print_error(f"‚ùå Error loading BN carryover data: {e}")
        return []

def load_mastersheet_with_fallback(base_result_path, semester_key, program):
    """Load mastersheet with multiple fallback strategies"""
    try:
        mastersheet_path = None
        temp_dir = None
        
        if base_result_path.endswith('.zip'):
            # Extract from ZIP
            temp_dir = tempfile.mkdtemp()
            with zipfile.ZipFile(base_result_path, 'r') as zip_ref:
                zip_ref.extractall(temp_dir)
                base_result_path = temp_dir
        
        # Look for mastersheet with multiple patterns - recursive
        mastersheet_patterns = [
            '**/*mastersheet*_{semester_key}*.xlsx',
            '**/*mastersheet*.xlsx',
            '**/*master*{semester_key}*.xlsx', 
            '**/*master*.xlsx',
            '**/*{semester_key}*.xlsx'
        ]
        
        for pattern in mastersheet_patterns:
            for file in glob.glob(os.path.join(base_result_path, pattern), recursive=True):
                if file.endswith('.xlsx'):
                    mastersheet_path = file
                    print_info(f"‚úÖ Found {program} mastersheet: {mastersheet_path}")
                    break
            if mastersheet_path:
                break
        
        if not mastersheet_path:
            print_error(f"‚ùå Could not find {program} mastersheet in: {base_result_path}")
            # List available files for debugging
            all_files = []
            for root, dirs, files in os.walk(base_result_path):
                for file in files:
                    if file.endswith('.xlsx'):
                        all_files.append(os.path.join(root, file))
            print_info(f"üìÅ Available Excel files: {all_files}")
            return None
        
        # Load mastersheet and find correct sheet
        xl = pd.ExcelFile(mastersheet_path)
        target_sheet = None
        
        # Try multiple sheet matching strategies
        sheet_variants = [
            semester_key,
            semester_key.replace('-', ' '),
            semester_key.replace('-', '_'),
            semester_key.split('-')[-1],  # Just the semester part
            'Sheet1',
            'Master',
            'Result'
        ]
        
        for sheet in xl.sheet_names:
            for variant in sheet_variants:
                if variant.lower() in sheet.lower():
                    target_sheet = sheet
                    print_info(f"‚úÖ Using {program} sheet: {target_sheet}")
                    break
            if target_sheet:
                break
        
        if not target_sheet:
            target_sheet = xl.sheet_names[0]  # Use first sheet as fallback
            print_warning(f"‚ö†Ô∏è Using first sheet as fallback: {target_sheet}")
        
        # Load the data with header detection
        mastersheet_df = load_excel_with_header_detection(mastersheet_path, target_sheet)
        if mastersheet_df is None:
            return None
        
        print_info(f"üìä {program} Mastersheet loaded: {len(mastersheet_df)} rows, {len(mastersheet_df.columns)} columns")
        
        # Cleanup
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            
        return mastersheet_df
        
    except Exception as e:
        print_error(f"‚ùå Error loading {program} mastersheet: {e}")
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        return None

def save_updated_mastersheet(mastersheet_df, base_result_path, semester_key, program):
    """Save the updated mastersheet"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"updated_mastersheet_{program}_{semester_key}_{timestamp}.xlsx"
        output_path = os.path.join(os.path.dirname(base_result_path), output_filename)
        
        mastersheet_df.to_excel(output_path, index=False)
        return output_path
    except Exception as e:
        print_error(f"‚ùå Error saving updated {program} mastersheet: {e}")
        return None

def process_resit_scores_enhanced(program, set_name, semester_key, resit_file_path, base_result_path):
    """Enhanced resit processing with better error handling and matching - FIXED VERSION"""
    try:
        print_info(f"üéØ PROCESSING {program} RESIT SCORES FOR {semester_key}...")
        
        # Load resit file
        resit_df = pd.read_excel(resit_file_path)
        print_info(f"üìä {program} Resit file has {len(resit_df)} students")
        
        # Load mastersheet with enhanced method
        mastersheet_df = load_mastersheet_with_fallback(base_result_path, semester_key, program)
        if mastersheet_df is None:
            print_error(f"‚ùå Could not load {program} mastersheet data")
            return False, "Could not load mastersheet data"
        
        # Enhanced student matching
        matched_students = enhanced_student_matching(resit_df, mastersheet_df, [], program)
        
        if not matched_students:
            print_error(f"‚ùå No {program} students matched between resit file and mastersheet")
            
            # Debug: Show sample exam numbers from both sources
            resit_exam_col = find_exam_number_column(resit_df)
            mastersheet_exam_col = find_exam_number_column(mastersheet_df)
            
            print_info(f"üîç Sample resit exam numbers: {resit_df[resit_exam_col].head(10).tolist()}")
            print_info(f"üîç Sample mastersheet exam numbers: {mastersheet_df[mastersheet_exam_col].head(10).tolist()}")
            
            return False, "No students matched between resit file and mastersheet"
        
        print_info(f"‚úÖ Matched {len(matched_students)} {program} students for processing")
        
        # DEBUG: Show what we're working with
        resit_exam_col = find_exam_number_column(resit_df)
        if matched_students:
            sample_courses = [col for col in matched_students[0]['resit_row'].index 
                             if col != resit_exam_col and col != 'NAME' 
                             and not str(col).startswith('Unnamed')
                             and pd.notna(matched_students[0]['resit_row'][col])]
            print_info(f"üîç Sample courses from resit file: {sample_courses[:5]}")
            print_info(f"üîç Mastersheet columns: {list(mastersheet_df.columns)[:15]}")
        
        # Apply score updates - FIXED LOGIC
        updates_applied = 0
        
        for matched_student in matched_students:
            student_idx = matched_student['mastersheet_idx']
            resit_row = matched_student['resit_row']
            student_exam_no = matched_student['resit_exam_no']
            
            # Update each course score
            for course_col in resit_row.index:
                if (course_col != resit_exam_col and 
                    course_col != 'NAME' and 
                    not str(course_col).startswith('Unnamed') and
                    pd.notna(resit_row[course_col])):
                    
                    # Try to find matching column in mastersheet with flexible matching
                    matched_col = None
                    if course_col in mastersheet_df.columns:
                        matched_col = course_col
                    else:
                        # Try case-insensitive match
                        course_upper = str(course_col).upper().strip()
                        for ms_col in mastersheet_df.columns:
                            if str(ms_col).upper().strip() == course_upper:
                                matched_col = ms_col
                                break
                        
                        # Try removing spaces
                        if not matched_col:
                            course_no_space = course_upper.replace(' ', '')
                            for ms_col in mastersheet_df.columns:
                                if str(ms_col).upper().replace(' ', '') == course_no_space:
                                    matched_col = ms_col
                                    break
                    
                    if matched_col:
                        try:
                            new_score = resit_row[course_col]
                            
                            # Validate new score - FIXED: Remove the comparison with old score
                            if pd.notna(new_score) and str(new_score).strip() != '':
                                new_score_val = float(new_score)
                                
                                # Get old score for logging only
                                old_score = mastersheet_df.at[student_idx, matched_col]
                                old_score_val = 0.0
                                if pd.notna(old_score) and str(old_score).strip() != '':
                                    try:
                                        old_score_val = float(old_score)
                                    except (ValueError, TypeError):
                                        old_score_val = 0.0
                                
                                # ALWAYS UPDATE - remove the equality check that was causing the issue
                                mastersheet_df.at[student_idx, matched_col] = new_score_val
                                updates_applied += 1
                                print_info(f"üìù Updated {program} {student_exam_no} {matched_col}: {old_score_val} ‚Üí {new_score_val}")
                                
                        except (ValueError, TypeError) as e:
                            print_warning(f"‚ö†Ô∏è Score conversion error for {student_exam_no} {course_col}: {e}")
                            continue
                    else:
                        print_warning(f"‚ö†Ô∏è Course '{course_col}' not found in mastersheet for {student_exam_no}")
        
        if updates_applied > 0:
            print_info(f"‚úÖ Successfully updated {updates_applied} {program} scores")
            
            # Save updated mastersheet
            output_path = save_updated_mastersheet(mastersheet_df, base_result_path, semester_key, program)
            if output_path:
                print_info(f"üíæ Saved updated {program} mastersheet to: {output_path}")
            
            return True, f"Updated {updates_applied} scores for {len(matched_students)} {program} students"
        else:
            print_warning(f"‚ö†Ô∏è No {program} scores updated - possible column mismatch")
            print_info(f"üîç Resit columns: {[c for c in resit_df.columns if c not in [resit_exam_col, 'NAME']]}")
            print_info(f"üîç Mastersheet columns: {list(mastersheet_df.columns)}")
            return False, "No scores updated - check column names match between files"
            
    except Exception as e:
        print_error(f"‚ùå {program} Resit processing failed: {str(e)}")
        traceback.print_exc(file=sys.stderr)
        return False, f"Processing error: {str(e)}"

def process_resit_scores(program, set_name, semester_key, resit_file_path, base_result_path):
    """QUICK FIX VERSION - Process resit scores with enhanced matching"""
    
    # Add immediate debug printing
    print_info(f"üöÄ STARTING RESIT PROCESSING FOR {program}/{set_name}/{semester_key}")
    print_info(f"üìÅ Resit file: {resit_file_path}")
    print_info(f"üìÅ Base path: {base_result_path}")
    
    try:
        # Use the enhanced processing function
        return process_resit_scores_enhanced(program, set_name, semester_key, resit_file_path, base_result_path)
    except Exception as e:
        print_error(f"üí• CRITICAL ERROR in {program} processing: {e}")
        return False, f"Critical error: {str(e)}"

def process_carryover_results(resit_file_path, source_path, source_type, semester_key, set_name, pass_threshold, output_dir, program):
    """
    Process carryover results and generate CARRYOVER_mastersheet for all programs.
    """
    print_info(f"\nüîÑ PROCESSING {program} CARRYOVER RESULTS FOR {semester_key}")
    print_info("=" * 60)
    
    # Standardize semester key with program context
    semester_key = standardize_semester_key(semester_key, program)
    print_info(f"üîë Processing {program} semester: {semester_key}")
    
    # Get previous semester for carryover
    previous_semester = get_previous_semester(semester_key, program)
    print_info(f"üîë Previous {program} semester for carryover: {previous_semester}")
    
    semester_course_titles, semester_credit_units, course_code_to_title, course_code_to_unit = load_course_data(program)
    
    debug_course_matching(resit_file_path, course_code_to_title, course_code_to_unit, program)
    
    year, sem_num, level, sem_display, set_code, sem_name = get_semester_display_info(semester_key, program)
    
    possible_sheet_keys = []
    if program == "BN":
        possible_sheet_keys = [
            f"{set_code} {sem_display}",
            f"{set_code.replace('BN2', 'BN 2').replace('BN1', 'BN 1').replace('BN3', 'BN 3')} {sem_display}",
            semester_key,
            semester_key.replace('-', ' ').upper(),
            f"{set_code} {sem_name}",
            f"{level} {sem_display}",
        ]
    elif program == "BM":
        possible_sheet_keys = [
            f"{set_code} {sem_display}",
            f"{set_code.replace('BM2', 'BM 2').replace('BM1', 'BM 1').replace('BM3', 'BM 3')} {sem_display}",
            semester_key,
            semester_key.replace('-', ' ').upper(),
            f"{set_code} {sem_name}",
            f"{level} {sem_display}",
        ]
    else:
        possible_sheet_keys = [
            f"{set_code} {sem_display}",
            f"{set_code.replace('NDII', 'ND II').replace('NDI', 'ND I')} {sem_display}",
            semester_key,
            semester_key.replace('-', ' ').upper(),
            f"{set_code} {sem_name}",
            f"{level} {sem_display}",
        ]
    
    course_titles_dict = {}
    credit_units_dict = {}
    
    for sheet_key in possible_sheet_keys:
        sheet_standard = standardize_semester_key(sheet_key, program)
        if sheet_standard in semester_course_titles:
            course_titles_dict = semester_course_titles[sheet_standard]
            credit_units_dict = semester_credit_units[sheet_standard]
            print_info(f"‚úÖ Using {program} sheet key: '{sheet_key}' with {len(course_titles_dict)} courses")
            break
        else:
            print_info(f"‚ùå {program} sheet key not found: '{sheet_key}'")
    
    if not course_titles_dict:
        print_warning(f"‚ö†Ô∏è No {program} semester-specific course data found, using global course mappings")
        course_titles_dict = course_code_to_title
        credit_units_dict = course_code_to_unit
    
    print_info(f"üìä Final {program} course mappings: {len(course_titles_dict)} titles, {len(credit_units_dict)} units")
    
    timestamp = datetime.now().strftime(TIMESTAMP_FMT)
    carryover_output_dir = os.path.join(output_dir, f"CARRYOVER_{set_name}_{semester_key}_{timestamp}")
    os.makedirs(carryover_output_dir, exist_ok=True)
    
    if not os.path.exists(resit_file_path):
        print_error(f"‚ùå {program} resit file not found: {resit_file_path}")
        return False
    
    temp_mastersheet_path = None
    temp_dir = None
    
    try:
        temp_mastersheet_path, temp_dir = get_mastersheet_path(source_path, source_type, semester_key)
        
        if not temp_mastersheet_path:
            print_error(f"‚ùå Failed to get {program} mastersheet")
            return False
        
        print_info(f"üìñ Reading {program} files...")
        resit_df = pd.read_excel(resit_file_path, header=0)
        
        xl = pd.ExcelFile(temp_mastersheet_path)
        sheet_name = get_matching_sheet(xl, semester_key)
        if not sheet_name:
            print_error(f"‚ùå No matching {program} sheet found for {semester_key}")
            return False
        
        print_info(f"üìñ Using {program} sheet '{sheet_name}' for current semester {semester_key}")
        
        # Use enhanced header detection for mastersheet
        mastersheet_df = load_excel_with_header_detection(temp_mastersheet_path, sheet_name)
        if mastersheet_df is None:
            print_error(f"‚ùå Could not load {program} mastersheet with header detection")
            return False
        
        print_info(f"‚úÖ {program} files loaded - Resit: {len(resit_df)} rows, Mastersheet: {len(mastersheet_df)} students")
        
        resit_exam_col = find_exam_number_column(resit_df)
        mastersheet_exam_col = find_exam_number_column(mastersheet_df)
        
        if not resit_exam_col:
            print_error(f"‚ùå Cannot find exam number column in {program} resit file")
            print_info(f"üìä Resit file columns: {list(resit_df.columns)}")
            return False
        
        if not mastersheet_exam_col:
            print_error(f"‚ùå Cannot find exam number column in {program} mastersheet")
            print_info(f"üìä Mastersheet columns: {list(mastersheet_df.columns)}")
            return False
        
        print_info(f"üìù {program} Exam columns - Resit: {resit_exam_col}, Mastersheet: {mastersheet_exam_col}")
        
        cgpa_data = load_previous_gpas(temp_mastersheet_path, semester_key, program)
        
        carryover_data = []
        updated_students = set()
        
        print_info(f"\nüéØ PROCESSING {program} RESIT SCORES...")
        
        for idx, resit_row in resit_df.iterrows():
            exam_no = str(resit_row[resit_exam_col]).strip().upper()
            if not exam_no or exam_no in ['NAN', 'NONE', '']:
                continue
            
            # Find student in mastersheet with enhanced matching
            student_mask = mastersheet_df[mastersheet_exam_col].astype(str).str.strip().str.upper() == exam_no
            if not student_mask.any():
                print_info(f"‚ö†Ô∏è {program} Student {exam_no} not found in mastersheet - skipping")
                continue
            
            student_data = mastersheet_df[student_mask].iloc[0]
            student_name_col = find_student_name_column(mastersheet_df)
            student_name = student_data.get(student_name_col, 'Unknown')
            
            # Find current credits
            current_credits = 0
            for col in mastersheet_df.columns:
                if 'CU PASSED' in str(col).upper() or 'CREDIT' in str(col).upper():
                    current_credits = student_data.get(col, 0)
                    break
            
            # Find current GPA
            current_gpa = 0
            for col in mastersheet_df.columns:
                if 'GPA' in str(col).upper() and 'CGPA' not in str(col).upper():
                    current_gpa = student_data.get(col, 0)
                    break
            
            student_record = {
                'EXAM NUMBER': exam_no,
                'NAME': student_name,
                'RESIT_COURSES': {},
                'CURRENT_GPA': current_gpa,
                'CURRENT_CREDITS': current_credits
            }
            
            if exam_no in cgpa_data:
                student_record['CURRENT_CGPA'] = calculate_cgpa(
                    cgpa_data[exam_no], 
                    student_record['CURRENT_GPA'], 
                    current_credits,
                    program
                )
            else:
                student_record['CURRENT_CGPA'] = student_record['CURRENT_GPA']
            
            if exam_no in cgpa_data:
                student_gpa_data = cgpa_data[exam_no]
                for i, prev_semester in enumerate(student_gpa_data['semesters']):
                    sem_display_name = get_semester_display_info(prev_semester, program)[5]
                    student_record[f'GPA_{sem_display_name}'] = student_gpa_data['gpas'][i]
                    print_info(f"üìä Stored {program} GPA for {exam_no}: {sem_display_name} = {student_gpa_data['gpas'][i]}")
            
            for col in resit_df.columns:
                if col == resit_exam_col or col == 'NAME' or 'Unnamed' in str(col):
                    continue
                    
                resit_score = resit_row.get(col)
                if pd.isna(resit_score) or resit_score == '':
                    continue
                
                try:
                    resit_score_val = float(resit_score)
                except (ValueError, TypeError):
                    continue
                
                if col in mastersheet_df.columns:
                    original_score = student_data.get(col)
                    if pd.isna(original_score):
                        continue
                    
                    try:
                        original_score_val = float(original_score) if not pd.isna(original_score) else 0.0
                    except (ValueError, TypeError):
                        original_score_val = 0.0
                    
                    if original_score_val < pass_threshold:
                        course_title = find_course_title(col, course_titles_dict, course_code_to_title)
                        credit_unit = find_credit_unit(col, credit_units_dict, course_code_to_unit)
                        
                        student_record['RESIT_COURSES'][col] = {
                            'original_score': original_score_val,
                            'resit_score': resit_score_val,
                            'updated': resit_score_val >= pass_threshold,
                            'course_title': course_title,
                            'credit_unit': credit_unit
                        }
            
            if student_record['RESIT_COURSES']:
                carryover_data.append(student_record)
                updated_students.add(exam_no)
                print_info(f"‚úÖ {program} {exam_no}: {len(student_record['RESIT_COURSES'])} resit courses, CGPA: {student_record['CURRENT_CGPA']}")
        
        if carryover_data:
            print_info(f"\nüìä GENERATING {program} CARRYOVER MASTERSHEET...")
            carryover_mastersheet_path = generate_carryover_mastersheet(
                carryover_data, carryover_output_dir, semester_key, set_name, timestamp, 
                cgpa_data, course_titles_dict, credit_units_dict, course_code_to_title, course_code_to_unit, program
            )
            
            print_info(f"\nüìÑ GENERATING {program} INDIVIDUAL STUDENT REPORTS...")
            generate_individual_reports(
                carryover_data, carryover_output_dir, semester_key, set_name, timestamp, cgpa_data, program
            )
            
            zip_path = os.path.join(output_dir, f"CARRYOVER_{set_name}_{semester_key}_{timestamp}.zip")
            if create_carryover_zip(carryover_output_dir, zip_path, program):
                print_info(f"‚úÖ Final {program} carryover ZIP created: {zip_path}")
            
            print_info(f"\nüéâ {program} CARRYOVER PROCESSING COMPLETED!")
            print_info(f"üìÅ Output directory: {carryover_output_dir}")
            print_info(f"üì¶ ZIP file: {zip_path}")
            print_info(f"üë®‚Äçüéì {program} Students processed: {len(carryover_data)}")
            
            return True
        else:
            print_error(f"‚ùå No {program} carryover data found to process")
            return False
            
    except Exception as e:
        print_error(f"‚ùå Error processing {program} carryover results: {e}")
        traceback.print_exc(file=sys.stderr)
        return False
    finally:
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            print_info(f"‚úÖ Cleaned up {program} temporary files")

def generate_remarks(resit_courses, program):
    """Generate remarks based on resit performance."""
    passed_count = sum(1 for course_data in resit_courses.values() 
                      if course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD)
    total_count = len(resit_courses)
    
    if passed_count == total_count:
        return f"All {program} courses passed in resit"
    elif passed_count > 0:
        return f"{passed_count}/{total_count} {program} courses passed in resit"
    else:
        return f"No improvement in {program} resit"

def generate_carryover_mastersheet(carryover_data, output_dir, semester_key, set_name, timestamp, cgpa_data, course_titles, course_units, course_code_to_title, course_code_to_unit, program):
    """Generate the CARRYOVER_mastersheet with enhanced GPA tracking for all programs."""
    
    wb = Workbook()
    ws = wb.active
    
    if program == "BN":
        ws.title = "BN_CARRYOVER_RESULTS"
        program_name = "BASIC NURSING"
        program_abbr = "BN"
    elif program == "BM":
        ws.title = "BM_CARRYOVER_RESULTS"
        program_name = "BASIC MIDWIFERY"
        program_abbr = "BM"
    else:
        ws.title = "CARRYOVER_RESULTS"
        program_name = "NATIONAL DIPLOMA"
        program_abbr = "ND"
    
    if os.path.exists(DEFAULT_LOGO_PATH):
        try:
            from openpyxl.drawing.image import Image
            img = Image(DEFAULT_LOGO_PATH)
            img.width = 80
            img.height = 80
            ws.add_image(img, 'A1')
        except Exception as e:
            print_warning(f"‚ö†Ô∏è Could not add logo: {e}")
    
    current_year = 2025
    next_year = 2026
    year, sem_num, level, sem_display, set_code, current_semester_name = get_semester_display_info(semester_key, program)
    
    all_courses = set()
    for student in carryover_data:
        all_courses.update(student['RESIT_COURSES'].keys())
    
    previous_semesters = get_previous_semesters_for_display(semester_key, program)
    
    headers = ['S/N', 'EXAM NUMBER', 'NAME']
    
    for prev_sem in previous_semesters:
        headers.append(f'GPA {prev_sem}')
    
    course_headers = []
    for course in sorted(all_courses):
        course_headers.extend([f'{course}', f'{course}_RESIT'])
    
    headers.extend(course_headers)
    headers.extend([f'GPA {current_semester_name}', 'CGPA', 'REMARKS'])
    
    total_columns = len(headers)
    last_column = get_column_letter(total_columns)
    
    ws.merge_cells(f'A3:{last_column}3')
    title_cell = ws['A3']
    title_cell.value = "FCT COLLEGE OF NURSING SCIENCES, GWAGWALADA-ABUJA"
    title_cell.font = Font(bold=True, size=14)
    title_cell.alignment = Alignment(horizontal='center', vertical='center')
    
    ws.merge_cells(f'A4:{last_column}4')
    subtitle_cell = ws['A4']
    
    if program == "BN":
        subtitle_cell.value = f"{program_name} RESIT - {current_year}/{next_year} SESSION {level} {sem_display} EXAMINATIONS RESULT ‚Äî {datetime.now().strftime('%B %d, %Y')}"
    elif program == "BM":
        subtitle_cell.value = f"{program_name} RESIT - {current_year}/{next_year} SESSION {level} {sem_display} EXAMINATIONS RESULT ‚Äî {datetime.now().strftime('%B %d, %Y')}"
    else:
        subtitle_cell.value = f"RESIT - {current_year}/{next_year} SESSION {program_name} {level} {sem_display} EXAMINATIONS RESULT ‚Äî {datetime.now().strftime('%B %d, %Y')}"
    
    subtitle_cell.font = Font(bold=True, size=12)
    subtitle_cell.alignment = Alignment(horizontal='center', vertical='center')
    
    print_info(f"üîç {program} Courses found in resit data: {sorted(all_courses)}")
    print_info(f"üìä {program} GPA columns for {semester_key}: Previous={previous_semesters}, Current={current_semester_name}")
    
    headers = ['S/N', 'EXAM NUMBER', 'NAME']
    
    for prev_sem in previous_semesters:
        headers.append(f'GPA {prev_sem}')
    
    course_headers = []
    course_title_mapping = {}
    course_unit_mapping = {}
    
    for course in sorted(all_courses):
        course_title = find_course_title(course, course_titles, course_code_to_title)
        course_title_mapping[course] = course_title
        
        credit_unit = find_credit_unit(course, course_units, course_code_to_unit)
        course_unit_mapping[course] = credit_unit
        
        if len(course_title) > 30:
            course_title = course_title[:27] + "..."
        course_headers.extend([f'{course}', f'{course}_RESIT'])
    
    headers.extend(course_headers)
    headers.extend([f'GPA {current_semester_name}', 'CGPA', 'REMARKS'])
    
    title_row = [''] * 3
    
    for prev_sem in previous_semesters:
        title_row.extend([''])
    
    for course in sorted(all_courses):
        course_title = course_title_mapping[course]
        if len(course_title) > 30:
            course_title = course_title[:27] + "..."
        title_row.extend([course_title, course_title])
    
    title_row.extend(['', '', ''])
    
    ws.append(title_row)
    
    credit_row = [''] * 3
    
    for prev_sem in previous_semesters:
        credit_row.extend([''])
    
    for course in sorted(all_courses):
        credit_unit = course_unit_mapping[course]
        credit_row.extend([f'CU: {credit_unit}', f'CU: {credit_unit}'])
    
    credit_row.extend(['', '', ''])
    
    ws.append(credit_row)
    
    code_row = ['S/N', 'EXAM NUMBER', 'NAME']
    
    for prev_sem in previous_semesters:
        code_row.append(f'GPA {prev_sem}')
    
    for course in sorted(all_courses):
        code_row.extend([f'{course}', f'{course}_RESIT'])
    
    code_row.extend([f'GPA {current_semester_name}', 'CGPA', 'REMARKS'])
    
    ws.append(code_row)
    
    course_colors = [
        "E6F3FF", "FFF0E6", "E6FFE6", "FFF6E6", "F0E6FF",
        "E6FFFF", "FFE6F2", "F5F5DC", "E6F7FF", "FFF5E6",
    ]
    
    start_col = 4
    if previous_semesters:
        start_col += len(previous_semesters)
    
    color_index = 0
    for course in sorted(all_courses):
        for row in [5, 6, 7]:
            for offset in [0, 1]:
                cell = ws.cell(row=row, column=start_col + offset)
                cell.fill = PatternFill(start_color=course_colors[color_index % len(course_colors)], 
                                      end_color=course_colors[color_index % len(course_colors)], 
                                      fill_type="solid")
                cell.font = Font(bold=True)
                cell.alignment = Alignment(horizontal='center', vertical='center')
                cell.border = Border(
                    left=Side(style='thin'), right=Side(style='thin'),
                    top=Side(style='thin'), bottom=Side(style='thin')
                )
        
        for offset in [0, 1]:
            cell = ws.cell(row=5, column=start_col + offset)
            cell.alignment = Alignment(text_rotation=90, horizontal='center', vertical='center')
            cell.font = Font(bold=True, size=9)
        
        color_index += 1
        start_col += 2
    
    for row in [5, 6, 7]:
        for col in range(1, 4):
            cell = ws.cell(row=row, column=col)
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = Border(
                left=Side(style='thin'), right=Side(style='thin'),
                top=Side(style='thin'), bottom=Side(style='thin')
            )
        
        gpa_col = 4
        for prev_sem in previous_semesters:
            cell = ws.cell(row=row, column=gpa_col)
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = Border(
                left=Side(style='thin'), right=Side(style='thin'),
                top=Side(style='thin'), bottom=Side(style='thin')
            )
            gpa_col += 1
        
        for col in range(len(headers)-2, len(headers)+1):
            cell = ws.cell(row=row, column=col)
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = Border(
                left=Side(style='thin'), right=Side(style='thin'),
                top=Side(style='thin'), bottom=Side(style='thin')
            )
    
    row_idx = 8
    failed_counts = {course: 0 for course in all_courses}
    
    start_col = 4
    if previous_semesters:
        start_col += len(previous_semesters)
    
    for student in carryover_data:
        exam_no = student['EXAM NUMBER']
        
        ws.cell(row=row_idx, column=1, value=row_idx-7)
        ws.cell(row=row_idx, column=2, value=student['EXAM NUMBER'])
        ws.cell(row=row_idx, column=3, value=student['NAME'])
        
        gpa_col = 4
        for prev_sem in previous_semesters:
            gpa_value = student.get(f'GPA_{prev_sem}', '')
            ws.cell(row=row_idx, column=gpa_col, value=gpa_value)
            gpa_col += 1
        
        course_col = gpa_col
        color_index = 0
        for course in sorted(all_courses):
            for offset in [0, 1]:
                cell = ws.cell(row=row_idx, column=course_col + offset)
                cell.fill = PatternFill(start_color=course_colors[color_index % len(course_colors)], 
                                      end_color=course_colors[color_index % len(course_colors)], 
                                      fill_type="solid")
            
            if course in student['RESIT_COURSES']:
                course_data = student['RESIT_COURSES'][course]
                
                orig_cell = ws.cell(row=row_idx, column=course_col, value=course_data['original_score'])
                if course_data['original_score'] < DEFAULT_PASS_THRESHOLD:
                    orig_cell.fill = PatternFill(start_color="FFB6C1", end_color="FFB6C1", fill_type="solid")
                
                resit_cell = ws.cell(row=row_idx, column=course_col+1, value=course_data['resit_score'])
                if course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD:
                    resit_cell.fill = PatternFill(start_color="90EE90", end_color="90EE90", fill_type="solid")
                else:
                    resit_cell.fill = PatternFill(start_color="FFB6C1", end_color="FFB6C1", fill_type="solid")
                    failed_counts[course] += 1
            else:
                ws.cell(row=row_idx, column=course_col, value='')
                ws.cell(row=row_idx, column=course_col+1, value='')
            
            color_index += 1
            course_col += 2
        
        ws.cell(row=row_idx, column=course_col, value=student['CURRENT_GPA'])
        ws.cell(row=row_idx, column=course_col+1, value=student['CURRENT_CGPA'])
        
        remarks = generate_remarks(student['RESIT_COURSES'], program)
        ws.cell(row=row_idx, column=course_col+2, value=remarks)
        
        row_idx += 1
    
    failed_row_idx = row_idx
    ws.cell(row=failed_row_idx, column=1, value=f"{program} FAILED COUNT BY COURSE:").font = Font(bold=True)
    
    for col in range(1, len(headers) + 1):
        cell = ws.cell(row=failed_row_idx, column=col)
        cell.fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")
    
    course_col = gpa_col
    for course in sorted(all_courses):
        count_cell = ws.cell(row=failed_row_idx, column=course_col+1, value=failed_counts[course])
        count_cell.font = Font(bold=True)
        count_cell.fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")
        course_col += 2
    
    summary_start_row = failed_row_idx + 2
    
    total_students = len(carryover_data)
    passed_all = sum(1 for student in carryover_data 
                    if all(course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD 
                          for course_data in student['RESIT_COURSES'].values()))
    
    carryover_count = total_students - passed_all
    total_failed_attempts = sum(failed_counts.values())
    
    summary_data = [
        [f"{program} CARRYOVER SUMMARY"],
        [f"A total of {total_students} {program} students registered and sat for the Carryover Examination"],
        [f"A total of {passed_all} {program} students passed all carryover courses"],
        [f"A total of {carryover_count} {program} students failed one or more carryover courses and must repeat them"],
        [f"Total failed {program} resit attempts: {total_failed_attempts} across all courses"],
        [f"{program} Carryover processing completed on {datetime.now().strftime('%B %d, %Y at %H:%M:%S')}"],
        [""],
        [""],
        ["", ""],
        ["________________________", "________________________"],
        ["Mrs. Abini Hauwa", "Mrs. Olukemi Ogunleye"],
        ["Head of Exams", f"Chairman, {program} Program C'tee"]
    ]
    
    for i, row_data in enumerate(summary_data):
        row_num = summary_start_row + i
        if len(row_data) == 1:
            if row_data[0]:
                ws.merge_cells(start_row=row_num, start_column=1, end_row=row_num, end_column=10)
                cell = ws.cell(row=row_num, column=1, value=row_data[0])
                if i == 0:
                    cell.font = Font(bold=True, size=12, underline='single')
                else:
                    cell.font = Font(bold=False, size=11)
                cell.alignment = Alignment(horizontal='left', vertical='center')
        elif len(row_data) == 2:
            left_cell = ws.cell(row=row_num, column=1, value=row_data[0])
            right_cell = ws.cell(row=row_num, column=4, value=row_data[1])
            
            if i >= len(summary_data) - 3:
                left_cell.alignment = Alignment(horizontal='left')
                right_cell.alignment = Alignment(horizontal='left')
                left_cell.font = Font(bold=True, size=11)
                right_cell.font = Font(bold=True, size=11)
    
    thin_border = Border(
        left=Side(style='thin'), right=Side(style='thin'),
        top=Side(style='thin'), bottom=Side(style='thin')
    )
    
    for row in ws.iter_rows(min_row=7, max_row=row_idx-1, min_col=1, max_col=len(headers)):
        for cell in row:
            cell.border = thin_border
    
    ws.freeze_panes = 'D8'
    
    for row in ws.iter_rows():
        for cell in row:
            if cell.font is None or not cell.font.bold:
                cell.font = Font(name='Calibri', size=11)
    
    for col_idx, column in enumerate(ws.columns, 1):
        max_length = 0
        column_letter = get_column_letter(col_idx)
        
        for cell in column:
            try:
                if cell.value is not None:
                    cell_value = str(cell.value)
                    cell_length = len(cell_value)
                    
                    if cell.row == 5 and cell.alignment.text_rotation == 90:
                        cell_length = max(cell_length, 10)
                    
                    if isinstance(cell.value, (int, float)) and not isinstance(cell.value, bool):
                        cell_length = max(cell_length, 8)
                    
                    if cell_length > max_length:
                        max_length = cell_length
            except:
                pass
        
        adjusted_width = min(max_length + 2, 50)
        
        if col_idx == 1:
            adjusted_width = 8
        elif col_idx == 2:
            adjusted_width = 18
        elif col_idx == 3:
            adjusted_width = 35
        elif col_idx >= 4 and col_idx <= (4 + len(previous_semesters) - 1):
            adjusted_width = 15
        elif col_idx >= len(headers) - 2:
            adjusted_width = 15
        else:
            adjusted_width = min(max(adjusted_width, 12), 25)
        
        ws.column_dimensions[column_letter].width = adjusted_width
    
    for row_idx in range(8, row_idx):
        if row_idx % 2 == 0:
            for cell in ws[row_idx]:
                if (cell.fill.start_color.index == '00000000' or 
                    cell.fill.start_color.index == '00FFFFFF'):
                    cell.fill = PatternFill(start_color="F8F8F8", end_color="F8F8F8", fill_type="solid")
    
    gpa_fill = PatternFill(start_color="E6E6FA", end_color="E6E6FA", fill_type="solid")
    if previous_semesters:
        for row in range(8, row_idx):
            for col in range(4, 4 + len(previous_semesters)):
                cell = ws.cell(row=row, column=col)
                if cell.fill.start_color.index == '00000000':
                    cell.fill = gpa_fill
    
    final_gpa_fill = PatternFill(start_color="E0FFFF", end_color="E0FFFF", fill_type="solid")
    for row in range(8, row_idx):
        for col in range(len(headers)-2, len(headers)+1):
            cell = ws.cell(row=row, column=col)
            if cell.fill.start_color.index == '00000000':
                cell.fill = final_gpa_fill
    
    if program == "BN":
        filename = f"BN_CARRYOVER_mastersheet_{timestamp}.xlsx"
    elif program == "BM":
        filename = f"BM_CARRYOVER_mastersheet_{timestamp}.xlsx"
    else:
        filename = f"CARRYOVER_mastersheet_{timestamp}.xlsx"
        
    filepath = os.path.join(output_dir, filename)
    wb.save(filepath)
    
    print_info(f"‚úÖ {program} CARRYOVER mastersheet generated: {filepath}")
    return filepath

def generate_individual_reports(carryover_data, output_dir, semester_key, set_name, timestamp, cgpa_data, program):
    """Generate individual student reports in CSV format."""
    if program == "BN":
        reports_dir = os.path.join(output_dir, "BN_INDIVIDUAL_REPORTS")
    elif program == "BM":
        reports_dir = os.path.join(output_dir, "BM_INDIVIDUAL_REPORTS")
    else:
        reports_dir = os.path.join(output_dir, "INDIVIDUAL_REPORTS")
        
    os.makedirs(reports_dir, exist_ok=True)
    
    for student in carryover_data:
        exam_no = student['EXAM NUMBER']
        safe_exam_no = sanitize_filename(exam_no)
        
        if program == "BN":
            filename = f"bn_carryover_report_{safe_exam_no}_{timestamp}.csv"
        elif program == "BM":
            filename = f"bm_carryover_report_{safe_exam_no}_{timestamp}.csv"
        else:
            filename = f"carryover_report_{safe_exam_no}_{timestamp}.csv"
            
        filepath = os.path.join(reports_dir, filename)
        
        report_data = []
        report_data.append([f"{program} CARRYOVER RESULT REPORT"])
        report_data.append(["FCT COLLEGE OF NURSING SCIENCES"])
        report_data.append([f"{program} Set: {set_name}"])
        report_data.append([f"{program} Semester: {semester_key}"])
        report_data.append([])
        report_data.append([f"{program} STUDENT INFORMATION"])
        report_data.append(["Exam Number:", student['EXAM NUMBER']])
        report_data.append(["Name:", student['NAME']])
        report_data.append([])
        
        report_data.append([f"{program} PREVIOUS GPAs"])
        for key in sorted([k for k in student.keys() if k.startswith('GPA_')]):
            semester = key.replace('GPA_', '')
            report_data.append([f"{semester}:", student[key]])
        report_data.append([])
        
        report_data.append([f"{program} CURRENT ACADEMIC RECORD"])
        report_data.append(["Current GPA:", student['CURRENT_GPA']])
        report_data.append(["Current CGPA:", student['CURRENT_CGPA']])
        report_data.append([])
        
        report_data.append([f"{program} RESIT COURSES"])
        report_data.append(["Course Code", "Course Title", "Credit Unit", "Original Score", "Resit Score", "Status"])
        
        for course_code, course_data in student['RESIT_COURSES'].items():
            status = "PASSED" if course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD else "FAILED"
            course_title = course_data.get('course_title', course_code)
            credit_unit = course_data.get('credit_unit', 0)
            report_data.append([
                course_code, 
                course_title,
                credit_unit,
                course_data['original_score'], 
                course_data['resit_score'], 
                status
            ])
        
        try:
            df = pd.DataFrame(report_data)
            df.to_csv(filepath, index=False, header=False)
            print_info(f"‚úÖ Generated {program} report for: {exam_no}")
        except Exception as e:
            print_error(f"‚ùå Error generating {program} report for {exam_no}: {e}")
    
    print_info(f"‚úÖ Generated {len(carryover_data)} {program} individual student reports in {reports_dir}")

def create_carryover_zip(source_dir, zip_path, program):
    """Create ZIP file of carryover results."""
    try:
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(source_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, source_dir)
                    zipf.write(file_path, arcname)
        print_info(f"‚úÖ {program} ZIP file created: {zip_path}")
        return True
    except Exception as e:
        print_error(f"‚ùå Error creating {program} ZIP: {e}")
        return False

def main():
    """Main function for carryover processing - FIXED VERSION"""
    try:
        print_info("üöÄ STARTING INTEGRATED CARRYOVER PROCESSOR...")
        
        # Get environment variables
        base_dir = os.getenv('BASE_DIR')
        selected_set = os.getenv('SELECTED_SET')
        selected_semesters = os.getenv('SELECTED_SEMESTERS', '').split(',')
        resit_file_path = os.getenv('RESIT_FILE_PATH')
        process_resit_flag = os.getenv('PROCESS_RESIT', 'false').lower() == 'true'
        base_result_path = os.getenv('BASE_RESULT_PATH')
        
        print_info(f"üìù Configuration:")
        print_info(f"   BASE_DIR: {base_dir}")
        print_info(f"   SELECTED_SET: {selected_set}")
        print_info(f"   SELECTED_SEMESTERS: {selected_semesters}")
        print_info(f"   RESIT_FILE_PATH: {resit_file_path}")
        print_info(f"   PROCESS_RESIT: {process_resit_flag}")
        print_info(f"   BASE_RESULT_PATH: {base_result_path}")
        
        # Determine program from set name
        program = detect_program_from_set(selected_set)
        
        if not program:
            print_error("‚ùå Could not determine program from set name")
            return False
        
        print_info(f"üéØ Detected program: {program}")
        
        # Process resit if requested
        if process_resit_flag and resit_file_path and base_result_path:
            if not os.path.exists(resit_file_path):
                print_error(f"‚ùå Resit file not found: {resit_file_path}")
                return False
            
            if not os.path.exists(base_result_path):
                print_error(f"‚ùå Base result path not found: {base_result_path}")
                return False
            
            overall_success = True
            for semester in selected_semesters:
                if semester and semester != 'all':
                    print_info(f"üîß Processing resit for {program}/{selected_set}/{semester}")
                    s, message = process_resit_scores(program, selected_set, semester, resit_file_path, base_result_path)
                    if s:
                        print_info(f"‚úÖ Resit processing successful for {semester}: {message}")
                    else:
                        print_error(f"‚ùå Resit processing failed for {semester}: {message}")
                        overall_success = False
            
            if overall_success:
                print_info("‚úÖ All carryover processing completed successfully")
                return True
            else:
                print_error("‚ùå Some carryover processing failed!")
                return False
        else:
            print_info("‚ÑπÔ∏è No resit processing requested")
            return True
            
    except Exception as e:
        print_error(f"‚ùå Fatal error in carryover processor: {e}")
        traceback.print_exc(file=sys.stderr)
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)