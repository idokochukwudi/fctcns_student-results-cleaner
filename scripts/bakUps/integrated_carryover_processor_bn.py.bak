#!/usr/bin/env python3
"""
integrated_carryover_processor.py - ENHANCED VERSION
Enhanced Features:
1. More robust column detection with comprehensive pattern matching
2. Added support for "EXAMS NUMBER", "EXAM NO", "REG NO", and many variations
3. Improved error handling and fallback strategies
4. Better logging and debugging for column detection
"""

import os
import sys
import re
import pandas as pd
import numpy as np
from datetime import datetime
import glob
import json
import traceback
import shutil
import zipfile
import tempfile
from openpyxl import load_workbook, Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter

def standardize_semester_key(semester_key, program=None):
    """Standardize semester key to canonical format for all programs - FIXED VERSION."""
    if not semester_key:
        return None
    
    key_upper = semester_key.upper()
    
    # Determine program from key content if not provided
    if not program:
        if key_upper.startswith(('N-', 'NURSING', 'BN')):
            program = "BN"
        elif key_upper.startswith(('M-', 'MIDWIFERY', 'BM')):
            program = "BM"
        else:
            program = "ND"  # Default
    
    # Set appropriate prefix
    if program == "BN":
        prefix = "N-"
    elif program == "BM":
        prefix = "M-"
    else:
        prefix = "ND-"
    
    # Define canonical mappings with proper prefixes
    canonical_mappings = {
        # First Year First Semester variants
        ("FIRST", "YEAR", "FIRST", "SEMESTER"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("1ST", "YEAR", "1ST", "SEMESTER"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("YEAR", "1", "SEMESTER", "1"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("FIRST", "SEMESTER"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        ("SEMESTER", "1"): f"{prefix}FIRST-YEAR-FIRST-SEMESTER",
        
        # First Year Second Semester variants
        ("FIRST", "YEAR", "SECOND", "SEMESTER"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("1ST", "YEAR", "2ND", "SEMESTER"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("YEAR", "1", "SEMESTER", "2"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("SECOND", "SEMESTER"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        ("SEMESTER", "2"): f"{prefix}FIRST-YEAR-SECOND-SEMESTER",
        
        # Second Year First Semester variants
        ("SECOND", "YEAR", "FIRST", "SEMESTER"): f"{prefix}SECOND-YEAR-FIRST-SEMESTER",
        ("2ND", "YEAR", "1ST", "SEMESTER"): f"{prefix}SECOND-YEAR-FIRST-SEMESTER",
        ("YEAR", "2", "SEMESTER", "1"): f"{prefix}SECOND-YEAR-FIRST-SEMESTER",
        
        # Second Year Second Semester variants
        ("SECOND", "YEAR", "SECOND", "SEMESTER"): f"{prefix}SECOND-YEAR-SECOND-SEMESTER",
        ("2ND", "YEAR", "2ND", "SEMESTER"): f"{prefix}SECOND-YEAR-SECOND-SEMESTER",
        ("YEAR", "2", "SEMESTER", "2"): f"{prefix}SECOND-YEAR-SECOND-SEMESTER",
        
        # Third Year variants (for BN/BM)
        ("THIRD", "YEAR", "FIRST", "SEMESTER"): f"{prefix}THIRD-YEAR-FIRST-SEMESTER",
        ("3RD", "YEAR", "1ST", "SEMESTER"): f"{prefix}THIRD-YEAR-FIRST-SEMESTER",
        ("YEAR", "3", "SEMESTER", "1"): f"{prefix}THIRD-YEAR-FIRST-SEMESTER",
        
        ("THIRD", "YEAR", "SECOND", "SEMESTER"): f"{prefix}THIRD-YEAR-SECOND-SEMESTER",
        ("3RD", "YEAR", "2ND", "SEMESTER"): f"{prefix}THIRD-YEAR-SECOND-SEMESTER",
        ("YEAR", "3", "SEMESTER", "2"): f"{prefix}THIRD-YEAR-SECOND-SEMESTER",
    }
    
    # Extract key components using regex for all programs
    patterns = [
        # Generic patterns that work for all programs
        r'(FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1)',
        r'(FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2)',
        r'(SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1)',
        r'(SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2)',
        r'(THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1)',
        r'(THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2)',
        
        # BN-specific patterns with N- prefix
        r'(N[-_]?(?:FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1))',
        r'(N[-_]?(?:FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2))',
        r'(N[-_]?(?:SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1))',
        r'(N[-_]?(?:SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2))',
        r'(N[-_]?(?:THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1))',
        r'(N[-_]?(?:THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2))',
        
        # BN patterns with BN prefix
        r'(BN[-_]?(?:FIRST|1ST|YEAR.?1).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BN[-_]?(?:FIRST|1ST|YEAR.?1).*?(SECOND|2ND|SEMESTER.?2))',
        r'(BN[-_]?(?:SECOND|2ND|YEAR.?2).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BN[-_]?(?:SECOND|2ND|YEAR.?2).*?(SECOND|2ND|SEMESTER.?2))',
        r'(BN[-_]?(?:THIRD|3RD|YEAR.?3).*?(FIRST|1ST|SEMESTER.?1))',
        r'(BN[-_]?(?:THIRD|3RD|YEAR.?3).*?(SECOND|2ND|SEMESTER.?2))',
    ]
    
    for pattern_idx, pattern in enumerate(patterns):
        match = re.search(pattern, key_upper, re.IGNORECASE)
        if match:
            # Determine which pattern group matched
            matched_text = match.group(0)
            
            # Map pattern index to semester
            if pattern_idx in [0, 6, 12]:
                return f"{prefix}FIRST-YEAR-FIRST-SEMESTER"
            elif pattern_idx in [1, 7, 13]:
                return f"{prefix}FIRST-YEAR-SECOND-SEMESTER"
            elif pattern_idx in [2, 8, 14]:
                return f"{prefix}SECOND-YEAR-FIRST-SEMESTER"
            elif pattern_idx in [3, 9, 15]:
                return f"{prefix}SECOND-YEAR-SECOND-SEMESTER"
            elif pattern_idx in [4, 10, 16]:
                return f"{prefix}THIRD-YEAR-FIRST-SEMESTER"
            elif pattern_idx in [5, 11, 17]:
                return f"{prefix}THIRD-YEAR-SECOND-SEMESTER"
    
    # Check for direct matches in canonical mappings
    for key_components, canonical_key in canonical_mappings.items():
        if all(component in key_upper for component in key_components):
            return canonical_key
    
    # If no match but contains program prefix, return as-is
    if key_upper.startswith(("N-", "M-", "ND-")):
        return semester_key.upper()
    
    # If no match, try to construct from known patterns
    if "FIRST" in key_upper and "FIRST" in key_upper:
        return f"{prefix}FIRST-YEAR-FIRST-SEMESTER"
    elif "FIRST" in key_upper and "SECOND" in key_upper:
        return f"{prefix}FIRST-YEAR-SECOND-SEMESTER"
    elif "SECOND" in key_upper and "FIRST" in key_upper:
        return f"{prefix}SECOND-YEAR-FIRST-SEMESTER"
    elif "SECOND" in key_upper and "SECOND" in key_upper:
        return f"{prefix}SECOND-YEAR-SECOND-SEMESTER"
    elif "THIRD" in key_upper and "FIRST" in key_upper:
        return f"{prefix}THIRD-YEAR-FIRST-SEMESTER"
    elif "THIRD" in key_upper and "SECOND" in key_upper:
        return f"{prefix}THIRD-YEAR-SECOND-SEMESTER"
    
    # If no match, return original with proper prefix
    print(f"‚ö†Ô∏è Could not standardize semester key: {semester_key}, using prefix: {prefix}")
    return f"{prefix}{semester_key.replace('-', ' ').upper().replace(' ', '-')}"

def get_previous_semester(semester_key, program=None):
    """Get the previous semester key for carryover for all programs."""
    standardized = standardize_semester_key(semester_key, program)
    
    # Determine program from standardized key if not provided
    if not program:
        if standardized.startswith('N-'):
            program = "BN"
        elif standardized.startswith('M-'):
            program = "BM"
        else:
            program = "ND"
    
    # ND semesters
    if program == "ND":
        if standardized == "ND-FIRST-YEAR-SECOND-SEMESTER":
            return "ND-FIRST-YEAR-FIRST-SEMESTER"
        elif standardized == "ND-SECOND-YEAR-FIRST-SEMESTER":
            return "ND-FIRST-YEAR-SECOND-SEMESTER"
        elif standardized == "ND-SECOND-YEAR-SECOND-SEMESTER":
            return "ND-SECOND-YEAR-FIRST-SEMESTER"
    
    # BN semesters
    elif program == "BN":
        if standardized == "N-FIRST-YEAR-SECOND-SEMESTER":
            return "N-FIRST-YEAR-FIRST-SEMESTER"
        elif standardized == "N-SECOND-YEAR-FIRST-SEMESTER":
            return "N-FIRST-YEAR-SECOND-SEMESTER"
        elif standardized == "N-SECOND-YEAR-SECOND-SEMESTER":
            return "N-SECOND-YEAR-FIRST-SEMESTER"
        elif standardized == "N-THIRD-YEAR-FIRST-SEMESTER":
            return "N-SECOND-YEAR-SECOND-SEMESTER"
        elif standardized == "N-THIRD-YEAR-SECOND-SEMESTER":
            return "N-THIRD-YEAR-FIRST-SEMESTER"
    
    # BM semesters (same structure as BN)
    elif program == "BM":
        if standardized == "M-FIRST-YEAR-SECOND-SEMESTER":
            return "M-FIRST-YEAR-FIRST-SEMESTER"
        elif standardized == "M-SECOND-YEAR-FIRST-SEMESTER":
            return "M-FIRST-YEAR-SECOND-SEMESTER"
        elif standardized == "M-SECOND-YEAR-SECOND-SEMESTER":
            return "M-SECOND-YEAR-FIRST-SEMESTER"
        elif standardized == "M-THIRD-YEAR-FIRST-SEMESTER":
            return "M-SECOND-YEAR-SECOND-SEMESTER"
        elif standardized == "M-THIRD-YEAR-SECOND-SEMESTER":
            return "M-THIRD-YEAR-FIRST-SEMESTER"
    
    return None  # No previous for first semester

# ----------------------------
# Configuration
# ----------------------------
def get_base_directory():
    """Get base directory - ENHANCED VERSION."""
    # First try environment variable
    if os.getenv('BASE_DIR'):
        base_dir = os.getenv('BASE_DIR')
        if os.path.exists(base_dir):
            return base_dir
    
    # Try the user's home directory with student_result_cleaner
    home_dir = os.path.expanduser('~')
    default_dir = os.path.join(home_dir, 'student_result_cleaner')
    
    # Check if EXAMS_INTERNAL exists in the default directory
    if os.path.exists(os.path.join(default_dir, "EXAMS_INTERNAL")):
        return default_dir
    
    # If not, check if we're already in a directory that contains EXAMS_INTERNAL
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    if os.path.exists(os.path.join(current_script_dir, "EXAMS_INTERNAL")):
        return current_script_dir
    
    # Check parent directory
    parent_dir = os.path.dirname(current_script_dir)
    if os.path.exists(os.path.join(parent_dir, "EXAMS_INTERNAL")):
        return parent_dir
    
    # Final fallback
    return default_dir

BASE_DIR = get_base_directory()
TIMESTAMP_FMT = "%d-%m-%Y_%H%M%S"
DEFAULT_PASS_THRESHOLD = 50.0
DEFAULT_LOGO_PATH = os.path.join(os.path.dirname(__file__), "logo.png")

def sanitize_filename(filename):
    """Remove or replace characters that are not safe for filenames."""
    return re.sub(r'[^\w\-_.]', '_', filename)

def find_exam_number_column(df):
    """Find the exam number column in a DataFrame - ENHANCED ROBUST VERSION."""
    # Comprehensive list of possible column names for exam numbers
    possible_names = [
        # Primary variations
        'EXAM NUMBER', 'EXAMS NUMBER', 'EXAM NO', 'EXAMS NO', 
        'EXAM', 'EXAMS', 'EXAMINATION NUMBER', 'EXAMINATION NO',
        
        # Registration variations
        'REG. No', 'REG NO', 'REG NO.', 'REGISTRATION NUMBER', 
        'REGISTRATION NO', 'REGISTRATION', 'REG. NUMBER',
        
        # Student ID variations
        'MAT NO', 'MATRIC NO', 'MATRICULATION NUMBER', 'MATRIC',
        'STUDENT ID', 'STUDENT NO', 'STUDENT NUMBER', 'STUDENT',
        'ID', 'STUDENT ID NUMBER',
        
        # Common abbreviations
        'EXM NO', 'EXM NUMBER', 'EXAM NUM', 'EXAMS NUM',
        'REG NUM', 'REGISTRATION NUM',
        
        # With special characters and spaces
        'EXAM-NO', 'EXAM-NUMBER', 'EXAMS-NO', 'EXAMS-NUMBER',
        'REG-NO', 'REG-NUMBER', 'STUDENT-ID', 'STUDENT-NO',
        
        # Lowercase variations (we'll convert to upper for matching)
        'exam number', 'exams number', 'exam no', 'exams no',
        'reg no', 'registration number', 'student id'
    ]
    
    print(f"üîç Searching for exam number column among {len(df.columns)} columns: {list(df.columns)}")
    
    # First, check for exact matches (case-insensitive)
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if col_upper == possible_name.upper():
                print(f"‚úÖ Found exact exam column match: '{col}'")
                return col
    
    # Then check for partial matches (contains)
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if possible_name.upper() in col_upper:
                print(f"‚úÖ Found partial exam column match: '{col}' contains '{possible_name}'")
                return col
    
    # Then check for columns that might contain exam-like patterns with fuzzy matching
    for col in df.columns:
        col_str = str(col).upper().strip()
        
        # Look for patterns using regular expressions
        exam_patterns = [
            r'.*EXAM.*NO.*', r'.*EXAM.*NUM.*', r'.*REG.*NO.*', 
            r'.*REG.*NUM.*', r'.*STUDENT.*ID.*', r'.*MAT.*NO.*',
            r'.*EXAMS.*NO.*', r'.*EXAMS.*NUM.*'
        ]
        
        for pattern in exam_patterns:
            if re.match(pattern, col_str, re.IGNORECASE):
                print(f"‚úÖ Found exam column by pattern '{pattern}': '{col}'")
                return col
    
    # Then check for columns that might contain exam-like patterns with keywords
    for col in df.columns:
        col_str = str(col).upper().strip()
        # Look for patterns like exam numbers (mix of letters and numbers)
        exam_keywords = ['EXAM', 'REG', 'MAT', 'STUDENT', 'ID', 'NO', 'NUMBER']
        keyword_matches = sum(1 for keyword in exam_keywords if keyword in col_str)
        
        if keyword_matches >= 2:  # At least 2 keywords match
            print(f"‚úÖ Found potential exam column by keywords ({keyword_matches} matches): '{col}'")
            return col
    
    # If still not found, try to find the first column that looks like it contains exam numbers
    print("üîÑ Trying value-based detection for exam number column...")
    for col in df.columns:
        # Skip columns that are clearly not exam numbers
        col_str = str(col).upper().strip()
        if any(skip_word in col_str for skip_word in ['NAME', 'SCORE', 'MARK', 'GRADE', 'TOTAL', 'GPA', 'REMARK']):
            continue
            
        # Sample a few values to see if they look like exam numbers
        sample_values = df[col].dropna().head(10)
        if len(sample_values) > 0:
            exam_like_count = 0
            total_checked = min(10, len(sample_values))
            
            for val in sample_values:
                val_str = str(val).strip()
                # Exam numbers are typically alphanumeric and not too long
                if (re.match(r'^[A-Za-z0-9/-]+$', val_str) and 
                    3 <= len(val_str) <= 20 and 
                    not val_str.isalpha() and 
                    not val_str.isdigit() and
                    not re.match(r'^\d+$', val_str)):  # Not pure numbers
                    exam_like_count += 1
            
            if exam_like_count >= total_checked * 0.6:  # At least 60% look like exam numbers
                print(f"üîÑ Using column '{col}' as exam column based on value pattern ({exam_like_count}/{total_checked} values look like exam numbers)")
                return col
    
    # Last resort: check if there's a column that's mostly unique values (common for IDs)
    print("üîÑ Trying uniqueness-based detection...")
    for col in df.columns:
        unique_ratio = df[col].nunique() / len(df) if len(df) > 0 else 0
        if unique_ratio > 0.8:  # Mostly unique values (like IDs)
            print(f"üîÑ Using column '{col}' as exam column based on uniqueness ({unique_ratio:.1%} unique)")
            return col
    
    print(f"‚ùå No exam number column found. Available columns: {list(df.columns)}")
    print("üí° Please check if your data has one of these columns:")
    for name in possible_names[:10]:  # Show first 10 possible names
        print(f"   - {name}")
    
    return None

def find_student_name_column(df):
    """Find the student name column in a DataFrame - ENHANCED VERSION."""
    possible_names = [
        'NAME', 'STUDENT NAME', 'FULL NAME', 'NAMES', 'STUDENT',
        'CANDIDATE NAME', 'CANDIDATE', 'STUDENTNAMES', 'STUDENT_NAME',
        'name', 'student name', 'full name'
    ]
    
    # First, check for exact matches
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if col_upper == possible_name.upper():
                print(f"‚úÖ Found exact name column match: '{col}'")
                return col
    
    # Then check for partial matches
    for col in df.columns:
        col_upper = str(col).upper().strip()
        for possible_name in possible_names:
            if possible_name.upper() in col_upper:
                print(f"‚úÖ Found partial name column match: '{col}' contains '{possible_name}'")
                return col
    
    # If not found, return the second column (often the name column)
    if len(df.columns) > 1:
        print(f"üîÑ Using second column as name column: '{df.columns[1]}'")
        return df.columns[1]
    
    print(f"‚ùå No student name column found. Available columns: {list(df.columns)}")
    return 'NAME'

# Course Data Loading for different programs
def load_course_data(program):
    """Load course data for the specified program."""
    if program == "BN":
        return load_bn_course_data()
    else:  # ND, BM, etc.
        return load_nd_course_data()

def load_nd_course_data():
    """Load ND course data from course-code-creditUnit.xlsx."""
    possible_course_files = [
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "ND", "ND-COURSES", "course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "ND", "ND-COURSES", "course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "ND-COURSES", "course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "course-code-creditUnit.xlsx"),
    ]
    
    course_file = None
    for possible_file in possible_course_files:
        if os.path.exists(possible_file):
            course_file = possible_file
            print(f"‚úÖ Found ND course file: {course_file}")
            break
    
    if not course_file:
        print(f"‚ùå Main ND course file not found in standard locations")
        alternative_files = find_alternative_course_files("ND")
        if alternative_files:
            course_file = alternative_files[0]
            print(f"üîÑ Using alternative ND course file: {course_file}")
        else:
            print("‚ùå No ND course files found anywhere!")
            return {}, {}, {}, {}
    
    print(f"üìö Loading ND course data from: {course_file}")
    return _load_course_data_from_file(course_file)

def load_bn_course_data():
    """Load BN course data from N-course-code-creditUnit.xlsx."""
    possible_course_files = [
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BN", "BN-COURSES", "N-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "BN", "BN-COURSES", "N-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BN-COURSES", "N-course-code-creditUnit.xlsx"),
        os.path.join(BASE_DIR, "N-course-code-creditUnit.xlsx"),
    ]
    
    course_file = None
    for possible_file in possible_course_files:
        if os.path.exists(possible_file):
            course_file = possible_file
            print(f"‚úÖ Found BN course file: {course_file}")
            break
    
    if not course_file:
        print(f"‚ùå Main BN course file not found in standard locations")
        alternative_files = find_alternative_course_files("BN")
        if alternative_files:
            course_file = alternative_files[0]
            print(f"üîÑ Using alternative BN course file: {course_file}")
        else:
            print("‚ùå No BN course files found anywhere!")
            return {}, {}, {}, {}
    
    print(f"üìö Loading BN course data from: {course_file}")
    return _load_course_data_from_file(course_file)

def _load_course_data_from_file(course_file):
    """Generic function to load course data from Excel file - FIXED VERSION."""
    try:
        xl = pd.ExcelFile(course_file)
        semester_course_titles = {}
        semester_credit_units = {}
        course_code_to_title = {}
        course_code_to_unit = {}
        
        print(f"üìñ Available sheets: {xl.sheet_names}")
        
        for sheet in xl.sheet_names:
            sheet_standard = standardize_semester_key(sheet)
            print(f"üìñ Reading sheet: {sheet} (standardized: {sheet_standard})")
            try:
                df = pd.read_excel(course_file, sheet_name=sheet, engine='openpyxl', header=0)
                
                # Convert columns to string and clean
                df.columns = [str(c).strip().upper() for c in df.columns]
                
                # Look for course code, title, and credit unit columns with flexible matching
                code_col = None
                title_col = None
                unit_col = None
                
                for col in df.columns:
                    col_clean = str(col).upper()
                    if any(keyword in col_clean for keyword in ['COURSE CODE', 'CODE', 'COURSECODE']):
                        code_col = col
                    elif any(keyword in col_clean for keyword in ['COURSE TITLE', 'TITLE', 'COURSENAME']):
                        title_col = col
                    elif any(keyword in col_clean for keyword in ['CU', 'CREDIT', 'UNIT', 'CREDIT UNIT']):
                        unit_col = col
                
                print(f"üîç Detected columns - Code: {code_col}, Title: {title_col}, Unit: {unit_col}")
                
                if not all([code_col, title_col, unit_col]):
                    print(f"‚ö†Ô∏è Sheet '{sheet}' missing required columns - found: code={code_col}, title={title_col}, unit={unit_col}")
                    # Try to use first three columns as fallback
                    if len(df.columns) >= 3:
                        code_col, title_col, unit_col = df.columns[0], df.columns[1], df.columns[2]
                        print(f"üîÑ Using fallback columns: {code_col}, {title_col}, {unit_col}")
                    else:
                        print(f"‚ùå Sheet '{sheet}' doesn't have enough columns - skipped")
                        continue
                
                # Clean the data
                df_clean = df.dropna(subset=[code_col]).copy()
                if df_clean.empty:
                    print(f"‚ö†Ô∏è Sheet '{sheet}' has no data after cleaning - skipped")
                    continue
                
                # Convert credit units to numeric, handling errors
                df_clean[unit_col] = pd.to_numeric(df_clean[unit_col], errors='coerce')
                df_clean = df_clean.dropna(subset=[unit_col])
                
                # FIXED: Remove rows with "TOTAL" in course code
                df_clean = df_clean[~df_clean[code_col].astype(str).str.contains('TOTAL', case=False, na=False)]
                
                if df_clean.empty:
                    print(f"‚ö†Ô∏è Sheet '{sheet}' has no valid rows after cleaning - skipped")
                    continue
                
                codes = df_clean[code_col].astype(str).str.strip().tolist()
                titles = df_clean[title_col].astype(str).str.strip().tolist()
                units = df_clean[unit_col].astype(float).tolist()

                print(f"üìã Found {len(codes)} courses in {sheet}:")
                for i, (code, title, unit) in enumerate(zip(codes[:5], titles[:5], units[:5])):
                    print(f"   - '{code}': '{title}' (CU: {unit})")

                # Create mapping dictionaries with ENHANCED normalization strategies
                sheet_titles = {}
                sheet_units = {}
                
                for code, title, unit in zip(codes, titles, units):
                    if not code or code.upper() in ['NAN', 'NONE', '']:
                        continue
                    
                    # ENHANCED: Create comprehensive normalization variants for robust matching
                    variants = [
                        # Basic variants
                        code.upper().strip(),
                        code.strip(),
                        code.upper(),
                        code.lower(),
                        code.title(),
                        
                        # Space removal variants
                        code.upper().replace(' ', ''),
                        code.replace(' ', ''),
                        re.sub(r'\s+', '', code.upper()),
                        re.sub(r'\s+', '', code),
                        
                        # Special character removal (keep only alphanumeric)
                        re.sub(r'[^a-zA-Z0-9]', '', code.upper()),
                        re.sub(r'[^a-zA-Z0-9]', '', code),
                        
                        # Dash and underscore variants
                        code.upper().replace('-', ''),
                        code.upper().replace('_', ''),
                        code.replace('-', '').replace('_', ''),
                        code.upper().replace('-', '').replace('_', '').replace(' ', ''),
                        
                        # WITH common prefixes (for matching with prefix)
                        f"NUR{code.upper()}",
                        f"NUR{code.upper().replace(' ', '')}",
                        f"NUR{re.sub(r'[^a-zA-Z0-9]', '', code.upper())}",
                        f"NSC{code.upper()}",
                        f"NSC{code.upper().replace(' ', '')}",
                        f"NSC{re.sub(r'[^a-zA-Z0-9]', '', code.upper())}",
                        
                        # WITHOUT common prefixes (for matching without prefix)
                        code.upper().replace('NUR', '').strip(),
                        code.upper().replace('NSC', '').strip(),
                        re.sub(r'^(NUR|NSC)', '', code.upper()).strip(),
                        re.sub(r'^(NUR|NSC)', '', code.upper()).replace(' ', '').strip(),
                        
                        # Number-focused variants (for codes like "101", "201")
                        re.sub(r'[^0-9]', '', code),
                        
                        # Common variations with dots
                        code.upper().replace('.', ''),
                        code.replace('.', ''),
                    ]
                    
                    # Remove duplicates while preserving order
                    variants = list(dict.fromkeys([v for v in variants if v and v not in ['NAN', 'NONE', '']]))
                    
                    # Add all variants to mappings
                    for variant in variants:
                        sheet_titles[variant] = title
                        sheet_units[variant] = unit
                        course_code_to_title[variant] = title
                        course_code_to_unit[variant] = unit
                
                semester_course_titles[sheet_standard] = sheet_titles
                semester_credit_units[sheet_standard] = sheet_units
                
            except Exception as e:
                print(f"‚ùå Error processing sheet '{sheet}': {e}")
                traceback.print_exc()
                continue
        
        print(f"‚úÖ Loaded course data for sheets: {list(semester_course_titles.keys())}")
        print(f"üìä Total course mappings: {len(course_code_to_title)}")
        
        # Debug: Show some course mappings
        print("üîç Sample course mappings:")
        sample_items = list(course_code_to_title.items())[:15]
        for code, title in sample_items:
            unit = course_code_to_unit.get(code, 0)
            print(f"   '{code}' -> '{title}' (CU: {unit})")
            
        return semester_course_titles, semester_credit_units, course_code_to_title, course_code_to_unit
        
    except Exception as e:
        print(f"‚ùå Error loading course data: {e}")
        traceback.print_exc()
        return {}, {}, {}, {}

def find_alternative_course_files(program):
    """Look for alternative course files for the specified program."""
    if program == "BN":
        base_dirs = [
            os.path.join(BASE_DIR, "EXAMS_INTERNAL", "BN", "BN-COURSES"),
            os.path.join(BASE_DIR, "BN", "BN-COURSES"),
            os.path.join(BASE_DIR, "COURSES"),
            os.path.join(BASE_DIR, "EXAMS_INTERNAL"),
        ]
    else:  # ND, BM
        base_dirs = [
            os.path.join(BASE_DIR, "EXAMS_INTERNAL", "ND", "ND-COURSES"),
            os.path.join(BASE_DIR, "ND", "ND-COURSES"),
            os.path.join(BASE_DIR, "COURSES"),
            os.path.join(BASE_DIR, "EXAMS_INTERNAL"),
        ]
    
    course_files = []
    for base_dir in base_dirs:
        if os.path.exists(base_dir):
            for file in os.listdir(base_dir):
                if 'course' in file.lower() and file.endswith(('.xlsx', '.xls')):
                    full_path = os.path.join(base_dir, file)
                    course_files.append(full_path)
                    print(f"üìÅ Found {program} course file: {full_path}")
    
    return course_files

def debug_course_matching(resit_file_path, course_code_to_title, course_code_to_unit, program):
    """Debug function to check why course codes aren't matching - ENHANCED."""
    print(f"\nüîç DEBUGGING {program} COURSE MATCHING")
    print("=" * 50)
    
    # Read resit file to see what course codes we have
    resit_df = pd.read_excel(resit_file_path, header=0)
    resit_exam_col = find_exam_number_column(resit_df)
    
    # Get all course codes from resit file
    resit_courses = []
    for col in resit_df.columns:
        if col != resit_exam_col and col != 'NAME' and not 'Unnamed' in str(col):
            resit_courses.append(col)
    
    print(f"üìã {program} Course codes from resit file: {resit_courses}")
    print(f"üìä Total courses in {program} resit file: {len(resit_courses)}")
    
    # Check each resit course against course file
    for course in resit_courses:
        print(f"\nüîç Checking {program} course: '{course}'")
        original_code = str(course).strip()
        
        # Generate ENHANCED variants for matching
        variants = [
            original_code.upper().strip(),
            original_code.strip(),
            original_code.upper(),
            original_code,
            original_code.lower(),
            original_code.title(),
            original_code.upper().replace(' ', ''),
            original_code.replace(' ', ''),
            re.sub(r'\s+', '', original_code.upper()),
            re.sub(r'\s+', '', original_code),
            re.sub(r'[^a-zA-Z0-9]', '', original_code.upper()),
            re.sub(r'[^a-zA-Z0-9]', '', original_code),
            original_code.upper().replace('-', ''),
            original_code.upper().replace('_', ''),
            original_code.replace('-', '').replace('_', ''),
            original_code.upper().replace('-', '').replace('_', '').replace(' ', ''),
            f"NUR{original_code.upper()}",
            f"NUR{original_code.upper().replace(' ', '')}",
            f"NSC{original_code.upper()}",
            f"NSC{original_code.upper().replace(' ', '')}",
            original_code.upper().replace('NUR', '').strip(),
            original_code.upper().replace('NSC', '').strip(),
            re.sub(r'^(NUR|NSC)', '', original_code.upper()).strip(),
            re.sub(r'[^0-9]', '', original_code),
            original_code.upper().replace('.', ''),
            original_code.replace('.', ''),
        ]
        
        # Remove duplicates
        variants = list(dict.fromkeys([v for v in variants if v and v != 'NAN']))
        
        print(f"   Generated {len(variants)} variants to try")
        
        found = False
        for variant in variants:
            if variant in course_code_to_title:
                title = course_code_to_title[variant]
                unit = course_code_to_unit.get(variant, 0)
                print(f"   ‚úÖ FOUND: '{variant}' -> '{title}' (CU: {unit})")
                found = True
                break
        
        if not found:
            print(f"   ‚ùå NOT FOUND: No match for '{course}'")
            # Show some similar keys from course file
            similar_keys = []
            # Check for partial matches
            for key in list(course_code_to_title.keys())[:50]:  # Check first 50 keys
                if any(part in key.upper() for part in original_code.upper().split() if len(part) > 2):
                    similar_keys.append(key)
            
            if similar_keys:
                print(f"   üí° Similar keys found: {similar_keys[:5]}")
            else:
                print(f"   üí° Sample available keys: {list(course_code_to_title.keys())[:10]}")

def find_course_title(course_code, course_titles_dict, course_code_to_title):
    """Robust function to find course title with comprehensive matching strategies - ENHANCED."""
    if not course_code or str(course_code).upper() in ['NAN', 'NONE', '']:
        return str(course_code) if course_code else "Unknown Course"
    
    original_code = str(course_code).strip()
    
    # Generate ENHANCED comprehensive matching variants
    variants = [
        # Basic normalizations
        original_code.upper().strip(),
        original_code.strip(),
        original_code.upper(),
        original_code,
        original_code.lower(),
        original_code.title(),
        
        # Space handling variations
        original_code.upper().replace(' ', ''),
        original_code.replace(' ', ''),
        re.sub(r'\s+', '', original_code.upper()),
        re.sub(r'\s+', '', original_code),
        
        # Special character handling
        re.sub(r'[^a-zA-Z0-9]', '', original_code.upper()),
        re.sub(r'[^a-zA-Z0-9]', '', original_code),
        
        # Common formatting issues
        original_code.upper().replace('-', ''),
        original_code.upper().replace('_', ''),
        original_code.replace('-', '').replace('_', ''),
        original_code.upper().replace('-', '').replace('_', '').replace(' ', ''),
        
        # WITH common prefixes
        f"NUR{original_code.upper()}",
        f"NUR{original_code.upper().replace(' ', '')}",
        f"NUR{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        f"NSC{original_code.upper()}",
        f"NSC{original_code.upper().replace(' ', '')}",
        f"NSC{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        
        # WITHOUT common prefixes
        original_code.upper().replace('NUR', '').strip(),
        original_code.upper().replace('NSC', '').strip(),
        re.sub(r'^(NUR|NSC)', '', original_code.upper()).strip(),
        re.sub(r'^(NUR|NSC)', '', original_code.upper()).replace(' ', '').strip(),
        
        # Number-focused variants
        re.sub(r'[^0-9]', '', original_code),
        
        # Dot removal
        original_code.upper().replace('.', ''),
        original_code.replace('.', ''),
    ]
    
    # Remove duplicates
    variants = list(dict.fromkeys([v for v in variants if v and v != 'NAN']))
    
    # Try each strategy in order
    for variant in variants:
        # Try course_titles_dict first (semester-specific)
        if variant in course_titles_dict:
            title = course_titles_dict[variant]
            print(f"‚úÖ Found title for '{original_code}' using variant '{variant}': '{title}'")
            return title
        
        # Try global course_code_to_title
        if variant in course_code_to_title:
            title = course_code_to_title[variant]
            print(f"‚úÖ Found title for '{original_code}' using global variant '{variant}': '{title}'")
            return title
    
    # If no match found, log and return descriptive original code
    print(f"‚ö†Ô∏è Could not find course title for: '{original_code}'")
    print(f"   Tried {len(variants)} variants without success")
    return f"{original_code} (Title Not Found)"

def find_credit_unit(course_code, credit_units_dict, course_code_to_unit):
    """Robust function to find credit unit with comprehensive matching strategies - ENHANCED."""
    if not course_code or str(course_code).upper() in ['NAN', 'NONE', '']:
        return 0
    
    original_code = str(course_code).strip()
    
    # Generate the same ENHANCED variants as title matching
    variants = [
        original_code.upper().strip(),
        original_code.strip(),
        original_code.upper(),
        original_code,
        original_code.lower(),
        original_code.title(),
        original_code.upper().replace(' ', ''),
        original_code.replace(' ', ''),
        re.sub(r'\s+', '', original_code.upper()),
        re.sub(r'\s+', '', original_code),
        re.sub(r'[^a-zA-Z0-9]', '', original_code.upper()),
        re.sub(r'[^a-zA-Z0-9]', '', original_code),
        original_code.upper().replace('-', ''),
        original_code.upper().replace('_', ''),
        original_code.replace('-', '').replace('_', ''),
        original_code.upper().replace('-', '').replace('_', '').replace(' ', ''),
        f"NUR{original_code.upper()}",
        f"NUR{original_code.upper().replace(' ', '')}",
        f"NUR{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        f"NSC{original_code.upper()}",
        f"NSC{original_code.upper().replace(' ', '')}",
        f"NSC{re.sub(r'[^a-zA-Z0-9]', '', original_code.upper())}",
        original_code.upper().replace('NUR', '').strip(),
        original_code.upper().replace('NSC', '').strip(),
        re.sub(r'^(NUR|NSC)', '', original_code.upper()).strip(),
        re.sub(r'[^0-9]', '', original_code),
        original_code.upper().replace('.', ''),
        original_code.replace('.', ''),
    ]
    
    # Remove duplicates
    variants = list(dict.fromkeys([v for v in variants if v and v != 'NAN']))
    
    # Try each strategy
    for variant in variants:
        if variant in credit_units_dict:
            unit = credit_units_dict[variant]
            return unit
        
        if variant in course_code_to_unit:
            unit = course_code_to_unit[variant]
            return unit
    
    print(f"‚ö†Ô∏è Could not find credit unit for: '{original_code}', defaulting to 2")
    return 2  # Default credit unit

def get_semester_display_info(semester_key, program):
    """Get display information for a semester key based on program."""
    semester_lower = semester_key.lower()
    
    if program == "BN":
        if 'first-year-first-semester' in semester_lower:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "BN1", "Semester 1"
        elif 'first-year-second-semester' in semester_lower:
            return 1, 2, "YEAR ONE", "SECOND SEMESTER", "BN1", "Semester 2"
        elif 'second-year-first-semester' in semester_lower:
            return 2, 1, "YEAR TWO", "FIRST SEMESTER", "BN2", "Semester 3"
        elif 'second-year-second-semester' in semester_lower:
            return 2, 2, "YEAR TWO", "SECOND SEMESTER", "BN2", "Semester 4"
        elif 'third-year-first-semester' in semester_lower:
            return 3, 1, "YEAR THREE", "FIRST SEMESTER", "BN3", "Semester 5"
        elif 'third-year-second-semester' in semester_lower:
            return 3, 2, "YEAR THREE", "SECOND SEMESTER", "BN3", "Semester 6"
        else:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "BN1", "Semester 1"
    else:  # ND, BM
        if 'first-year-first-semester' in semester_lower:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "NDI", "Semester 1"
        elif 'first-year-second-semester' in semester_lower:
            return 1, 2, "YEAR ONE", "SECOND SEMESTER", "NDI", "Semester 2"
        elif 'second-year-first-semester' in semester_lower:
            return 2, 1, "YEAR TWO", "FIRST SEMESTER", "NDII", "Semester 3"
        elif 'second-year-second-semester' in semester_lower:
            return 2, 2, "YEAR TWO", "SECOND SEMESTER", "NDII", "Semester 4"
        else:
            return 1, 1, "YEAR ONE", "FIRST SEMESTER", "NDI", "Semester 1"

def get_grade_point(score):
    """Determine grade point based on score - NIGERIAN 5.0 SCALE."""
    try:
        score = float(score)
        if score >= 70: return 5.0
        elif score >= 60: return 4.0
        elif score >= 50: return 3.0
        elif score >= 45: return 2.0
        elif score >= 40: return 1.0
        else: return 0.0
    except (ValueError, TypeError):
        return 0.0

def extract_mastersheet_from_zip(zip_path, semester_key):
    """Extract mastersheet from ZIP file and return temporary file path."""
    try:
        print(f"üì¶ Looking for mastersheet in ZIP: {zip_path}")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            all_files = zip_ref.namelist()
            print(f"üìÅ Files in ZIP: {all_files}")
            
            mastersheet_files = [f for f in all_files if 'mastersheet' in f.lower() and f.endswith('.xlsx')]
            
            if not mastersheet_files:
                print(f"‚ùå No mastersheet found in ZIP")
                return None, None
            
            mastersheet_name = mastersheet_files[0]
            print(f"‚úÖ Found mastersheet: {mastersheet_name}")
            
            temp_dir = tempfile.mkdtemp()
            temp_mastersheet_path = os.path.join(temp_dir, f"mastersheet_{semester_key}.xlsx")
            
            with open(temp_mastersheet_path, 'wb') as f:
                f.write(zip_ref.read(mastersheet_name))
            
            print(f"‚úÖ Extracted mastersheet to: {temp_mastersheet_path}")
            return temp_mastersheet_path, temp_dir
            
    except Exception as e:
        print(f"‚ùå Error extracting mastersheet from ZIP: {e}")
        traceback.print_exc()
        return None, None

def find_latest_zip_file(clean_dir, program):
    """Find the latest ZIP file in clean results directory."""
    print(f"üîç Looking for {program} ZIP files in: {clean_dir}")
    
    if not os.path.exists(clean_dir):
        print(f"‚ùå {program} clean directory doesn't exist: {clean_dir}")
        return None
    
    all_files = os.listdir(clean_dir)
    
    zip_files = []
    for f in all_files:
        if f.lower().endswith('.zip'):
            if 'carryover' in f.lower():
                print(f"‚ö†Ô∏è Skipping {program} carryover ZIP: {f}")
                continue
            
            if any(pattern in f for pattern in ['_RESULT-', 'RESULT_', 'RESULT-']):
                zip_files.append(f)
                print(f"‚úÖ Found {program} regular results ZIP: {f}")
            else:
                print(f"‚ÑπÔ∏è Found other {program} ZIP (not a result file): {f}")
    
    if not zip_files:
        print(f"‚ùå No {program} regular results ZIP files found (excluding carryover files)")
        fallback_zips = [f for f in all_files if f.lower().endswith('.zip') and 'carryover' not in f.lower()]
        if fallback_zips:
            print(f"‚ö†Ô∏è Using fallback {program} ZIP files: {fallback_zips}")
            zip_files = fallback_zips
        else:
            print(f"‚ùå No {program} ZIP files found at all in {clean_dir}")
            return None
    
    print(f"‚úÖ Final {program} ZIP files to consider: {zip_files}")
    
    zip_files_with_path = [os.path.join(clean_dir, f) for f in zip_files]
    latest_zip = sorted(zip_files_with_path, key=os.path.getmtime, reverse=True)[0]
    
    print(f"üéØ Using latest {program} ZIP: {latest_zip}")
    return latest_zip

def find_latest_result_folder(clean_dir, set_name, program):
    """Find the latest result folder in clean results directory."""
    print(f"üîç Looking for {program} result folders in: {clean_dir}")
    
    if not os.path.exists(clean_dir):
        print(f"‚ùå {program} clean directory doesn't exist: {clean_dir}")
        return None
    
    all_items = os.listdir(clean_dir)
    
    result_folders = [f for f in all_items if os.path.isdir(os.path.join(clean_dir, f)) and f.startswith(f"{set_name}_RESULT-")]
    
    if not result_folders:
        print(f"‚ùå No {program} result folders found")
        return None
    
    print(f"‚úÖ Found {program} result folders: {result_folders}")
    
    folders_with_path = [os.path.join(clean_dir, f) for f in result_folders]
    latest_folder = sorted(folders_with_path, key=os.path.getmtime, reverse=True)[0]
    
    print(f"üéØ Using latest {program} result folder: {latest_folder}")
    return latest_folder

def find_latest_mastersheet_source(clean_dir, set_name, program):
    """Find the latest source for mastersheet: prefer ZIP, fallback to folder."""
    print(f"üîç Looking for {program} mastersheet source in: {clean_dir}")
    
    if not os.path.exists(clean_dir):
        print(f"‚ùå {program} clean directory doesn't exist: {clean_dir}")
        return None, None
    
    zip_path = find_latest_zip_file(clean_dir, program)
    if zip_path:
        print(f"‚úÖ Using {program} ZIP source: {zip_path}")
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_files = zip_ref.namelist()
                mastersheet_files = [f for f in zip_files if 'mastersheet' in f.lower() and f.endswith('.xlsx')]
                if mastersheet_files:
                    print(f"‚úÖ {program} ZIP contains mastersheet files: {mastersheet_files}")
                    return zip_path, 'zip'
                else:
                    print(f"‚ö†Ô∏è {program} ZIP found but no mastersheet inside: {zip_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error checking {program} ZIP contents: {e}")
    
    folder_path = find_latest_result_folder(clean_dir, set_name, program)
    if folder_path:
        print(f"‚úÖ Using {program} folder source: {folder_path}")
        return folder_path, 'folder'
    
    print(f"‚ùå No valid {program} ZIP files or result folders found in {clean_dir}")
    return None, None

def get_mastersheet_path(source_path, source_type, semester_key):
    """Get mastersheet path based on source type (zip or folder)."""
    temp_dir = None
    if source_type == 'zip':
        temp_mastersheet_path, temp_dir = extract_mastersheet_from_zip(source_path, semester_key)
        if not temp_mastersheet_path:
            print("‚ùå Failed to extract mastersheet from ZIP")
            return None, None
    elif source_type == 'folder':
        all_files = os.listdir(source_path)
        mastersheet_files = [f for f in all_files if 'mastersheet' in f.lower() and f.endswith('.xlsx')]
        
        if not mastersheet_files:
            print(f"‚ùå No mastersheet found in folder {source_path}")
            return None, None
        
        mastersheet_name = mastersheet_files[0]
        temp_mastersheet_path = os.path.join(source_path, mastersheet_name)
        print(f"‚úÖ Found mastersheet in folder: {temp_mastersheet_path}")
    else:
        return None, None
    
    return temp_mastersheet_path, temp_dir

def get_matching_sheet(xl, target_key):
    """Find matching sheet name with variants."""
    target_upper = target_key.upper().replace('-', ' ').replace('_', ' ').replace('.', ' ')
    target_upper = ' '.join(target_upper.split())
    
    possible_keys = [
        target_key,
        target_key.upper(),
        target_key.lower(),
        target_key.title(),
        target_key.replace('-', ' ').upper(),
        target_key.replace('-', ' ').lower(),
        target_key.replace('-', ' ').title(),
        target_key.replace('-', '_').upper(),
        target_key.replace('-', '_').lower(),
        target_key.replace('-', '_').title(),
        target_key.replace('First', '1st'),
        target_key.replace('Second', '2nd'),
        target_key.replace('Third', '3rd'),
        target_key.replace('YEAR', 'YR'),
        target_key.replace('SEMESTER', 'SEM'),
        target_upper,
        target_upper.replace('FIRST', '1ST'),
        target_upper.replace('SECOND', '2ND'),
        target_upper.replace('THIRD', '3RD'),
        target_upper.replace('YEAR', 'YR'),
        target_upper.replace('SEMESTER', 'SEM'),
    ]
    
    possible_keys = list(set([k for k in possible_keys if k]))
    
    print(f"üîç Trying sheet variants for '{target_key}': {possible_keys}")
    
    for sheet in xl.sheet_names:
        sheet_normalized = sheet.upper().replace('-', ' ').replace('_', ' ').replace('.', ' ')
        sheet_normalized = ' '.join(sheet_normalized.split())
        
        if any(p == sheet or p in sheet or p == sheet_normalized or p in sheet_normalized for p in possible_keys):
            print(f"‚úÖ Found matching sheet: '{sheet}' for '{target_key}'")
            return sheet
    
    print(f"‚ùå No matching sheet found for '{target_key}'")
    print(f"üìñ Available sheets: {xl.sheet_names}")
    return None

def load_previous_gpas(mastersheet_path, current_semester_key, program):
    """Load previous GPA data from mastersheet for CGPA calculation."""
    all_student_data = {}
    current_standard = standardize_semester_key(current_semester_key, program)
    
    if program == "BN":
        all_semesters = {
            "N-FIRST-YEAR-FIRST-SEMESTER": [],
            "N-FIRST-YEAR-SECOND-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER"],
            "N-SECOND-YEAR-FIRST-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER"],
            "N-SECOND-YEAR-SECOND-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER"],
            "N-THIRD-YEAR-FIRST-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER", "N-SECOND-YEAR-SECOND-SEMESTER"],
            "N-THIRD-YEAR-SECOND-SEMESTER": ["N-FIRST-YEAR-FIRST-SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER", "N-SECOND-YEAR-SECOND-SEMESTER", "N-THIRD-YEAR-FIRST-SEMESTER"]
        }
    else:
        all_semesters = {
            "ND-FIRST-YEAR-FIRST-SEMESTER": [],
            "ND-FIRST-YEAR-SECOND-SEMESTER": ["ND-FIRST-YEAR-FIRST-SEMESTER"],
            "ND-SECOND-YEAR-FIRST-SEMESTER": ["ND-FIRST-YEAR-FIRST-SEMESTER", "ND-FIRST-YEAR-SECOND-SEMESTER"],
            "ND-SECOND-YEAR-SECOND-SEMESTER": ["ND-FIRST-YEAR-FIRST-SEMESTER", "ND-FIRST-YEAR-SECOND-SEMESTER", "ND-SECOND-YEAR-FIRST-SEMESTER"]
        }
    
    semesters_to_load = all_semesters.get(current_standard, [])
    print(f"üìä Loading previous {program} GPAs for {current_standard}: {semesters_to_load}")

    if not os.path.exists(mastersheet_path):
        print(f"‚ùå {program} Mastersheet not found: {mastersheet_path}")
        return {}

    try:
        xl = pd.ExcelFile(mastersheet_path)
        print(f"üìñ Available sheets in {program} mastersheet: {xl.sheet_names}")
    except Exception as e:
        print(f"‚ùå Error opening {program} mastersheet: {e}")
        return {}

    for semester in semesters_to_load:
        try:
            sheet_name = get_matching_sheet(xl, semester)
            if not sheet_name:
                print(f"‚ö†Ô∏è Skipping {program} semester {semester} - no matching sheet found")
                continue
            
            print(f"üìñ Reading {program} sheet '{sheet_name}' for semester {semester}")
            df = pd.read_excel(mastersheet_path, sheet_name=sheet_name, header=5)
            
            if df.empty or len(df.columns) < 3:
                df = pd.read_excel(mastersheet_path, sheet_name=sheet_name, header=0)
                print(f"üîÑ Using header row 0 for {program} sheet '{sheet_name}'")
            
            exam_col = find_exam_number_column(df)
            gpa_col = None
            credit_col = None
            
            for col in df.columns:
                col_str = str(col).upper()
                if 'GPA' in col_str and 'CGPA' not in col_str:
                    gpa_col = col
                if 'CU PASSED' in col_str or 'CREDIT' in col_str or 'UNIT' in col_str:
                    credit_col = col
            
            print(f"üîç Columns found - Exam: {exam_col}, GPA: {gpa_col}, Credits: {credit_col}")
            
            if exam_col and gpa_col:
                for idx, row in df.iterrows():
                    try:
                        exam_no = str(row[exam_col]).strip()
                        if pd.isna(exam_no) or exam_no in ['', 'NAN', 'NONE']:
                            continue
                            
                        gpa_value = row[gpa_col]
                        if pd.isna(gpa_value):
                            continue
                            
                        credits = 30
                        if credit_col and credit_col in row and pd.notna(row[credit_col]):
                            try:
                                credits = int(float(row[credit_col]))
                            except (ValueError, TypeError):
                                credits = 30
                        
                        if exam_no not in all_student_data:
                            all_student_data[exam_no] = {'gpas': [], 'credits': [], 'semesters': []}
                        
                        all_student_data[exam_no]['gpas'].append(float(gpa_value))
                        all_student_data[exam_no]['credits'].append(credits)
                        all_student_data[exam_no]['semesters'].append(semester)
                        
                        if idx < 3:
                            print(f"üìä Loaded {program} GPA for {exam_no}: {gpa_value} with {credits} credits from {semester}")
                            
                    except (ValueError, TypeError) as e:
                        print(f"‚ö†Ô∏è Error processing row {idx} for {program} {semester}: {e}")
                        continue
            else:
                print(f"‚ö†Ô∏è Missing required columns in {program} {sheet_name}: exam_col={exam_col}, gpa_col={gpa_col}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load data from {program} {semester}: {e}")
            traceback.print_exc()
    
    print(f"üìä Loaded cumulative {program} data for {len(all_student_data)} students")
    return all_student_data

def calculate_cgpa(student_data, current_gpa, current_credits, program):
    """Calculate Cumulative GPA for all programs."""
    if not student_data or not student_data.get('gpas'):
        print(f"‚ö†Ô∏è No previous {program} GPA data, using current GPA: {current_gpa}")
        return current_gpa

    total_grade_points = 0.0
    total_credits = 0

    print(f"üî¢ Calculating {program} CGPA from {len(student_data['gpas'])} previous semesters")
    
    for prev_gpa, prev_credits in zip(student_data['gpas'], student_data['credits']):
        total_grade_points += prev_gpa * prev_credits
        total_credits += prev_credits
        print(f"   - GPA: {prev_gpa}, Credits: {prev_credits}, Running Total: {total_grade_points}/{total_credits}")

    total_grade_points += current_gpa * current_credits
    total_credits += current_credits

    print(f"üìä Final {program} calculation: {total_grade_points} / {total_credits}")

    if total_credits > 0:
        cgpa = round(total_grade_points / total_credits, 2)
        print(f"‚úÖ Calculated {program} CGPA: {cgpa}")
        return cgpa
    else:
        print(f"‚ö†Ô∏è No {program} credits, returning current GPA: {current_gpa}")
        return current_gpa

def get_previous_semesters_for_display(current_semester_key, program):
    """Get list of previous semesters for GPA display in mastersheet."""
    current_standard = standardize_semester_key(current_semester_key, program)
    
    if program == "BN":
        semester_mapping = {
            "N-FIRST-YEAR-FIRST-SEMESTER": [],
            "N-FIRST-YEAR-SECOND-SEMESTER": ["Semester 1"],
            "N-SECOND-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2"], 
            "N-SECOND-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3"],
            "N-THIRD-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2", "Semester 3", "Semester 4"],
            "N-THIRD-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3", "Semester 4", "Semester 5"]
        }
    else:
        semester_mapping = {
            "ND-FIRST-YEAR-FIRST-SEMESTER": [],
            "ND-FIRST-YEAR-SECOND-SEMESTER": ["Semester 1"],
            "ND-SECOND-YEAR-FIRST-SEMESTER": ["Semester 1", "Semester 2"], 
            "ND-SECOND-YEAR-SECOND-SEMESTER": ["Semester 1", "Semester 2", "Semester 3"]
        }
    
    return semester_mapping.get(current_standard, [])

def extract_semester_from_filename(filename):
    """Extract semester from filename using comprehensive pattern matching - FIXED."""
    filename_upper = filename.upper()
    
    # First try to extract any semester-like pattern from filename
    semester_pattern = r'((?:N|M|ND)[-_]?(?:FIRST|SECOND|THIRD|1ST|2ND|3RD)[-_]?YEAR[-_]?(?:FIRST|SECOND|1ST|2ND)[-_]?SEMESTER)'
    match = re.search(semester_pattern, filename_upper)
    
    if match:
        extracted = match.group(1)
        # Determine program from prefix
        if extracted.startswith(('N-', 'N_')):
            program = "BN"
        elif extracted.startswith(('M-', 'M_')):
            program = "BM"
        else:
            program = "ND"
        
        # Standardize the extracted pattern with program context
        standardized = standardize_semester_key(extracted, program)
        print(f"‚úÖ Extracted and standardized: '{filename}' ‚Üí '{standardized}'")
        return standardized
    
    # Fallback to comprehensive pattern mapping
    semester_patterns = {
        "N-FIRST-YEAR-FIRST-SEMESTER": [
            "N.FIRST.YEAR.FIRST.SEMESTER", "N-FIRST-YEAR-FIRST-SEMESTER", "N_FIRST_YEAR_FIRST_SEMESTER",
            "FIRST.YEAR.FIRST.SEMESTER", "FIRST-YEAR-FIRST-SEMESTER", "FIRST_YEAR_FIRST_SEMESTER",
            "1ST.YEAR.1ST.SEMESTER", "1ST-YEAR-1ST-SEMESTER", "1ST_YEAR_1ST_SEMESTER",
            "YEAR1.SEMESTER1", "YEAR-1-SEMESTER-1", "YEAR_1_SEMESTER_1"
        ],
        "N-FIRST-YEAR-SECOND-SEMESTER": [
            "N.FIRST.YEAR.SECOND.SEMESTER", "N-FIRST-YEAR-SECOND-SEMESTER", "N_FIRST_YEAR_SECOND_SEMESTER",
            "FIRST.YEAR.SECOND.SEMESTER", "FIRST-YEAR-SECOND-SEMESTER", "FIRST_YEAR_SECOND_SEMESTER",
            "1ST.YEAR.2ND.SEMESTER", "1ST-YEAR-2ND-SEMESTER", "1ST_YEAR_2ND_SEMESTER",
            "YEAR1.SEMESTER2", "YEAR-1-SEMESTER-2", "YEAR_1_SEMESTER_2"
        ],
        "N-SECOND-YEAR-FIRST-SEMESTER": [
            "N.SECOND.YEAR.FIRST.SEMESTER", "N-SECOND-YEAR-FIRST-SEMESTER", "N_SECOND_YEAR_FIRST_SEMESTER",
            "SECOND.YEAR.FIRST.SEMESTER", "SECOND-YEAR-FIRST-SEMESTER", "SECOND_YEAR_FIRST_SEMESTER",
            "2ND.YEAR.1ST.SEMESTER", "2ND-YEAR-1ST-SEMESTER", "2ND_YEAR_1ST_SEMESTER",
            "YEAR2.SEMESTER1", "YEAR-2-SEMESTER-1", "YEAR_2_SEMESTER_1"
        ],
        "N-SECOND-YEAR-SECOND-SEMESTER": [
            "N.SECOND.YEAR.SECOND.SEMESTER", "N-SECOND-YEAR-SECOND-SEMESTER", "N_SECOND_YEAR_SECOND_SEMESTER",
            "SECOND.YEAR.SECOND.SEMESTER", "SECOND-YEAR-SECOND-SEMESTER", "SECOND_YEAR_SECOND_SEMESTER",
            "2ND.YEAR.2ND.SEMESTER", "2ND-YEAR-2ND-SEMESTER", "2ND_YEAR_2ND_SEMESTER",
            "YEAR2.SEMESTER2", "YEAR-2-SEMESTER-2", "YEAR_2_SEMESTER_2"
        ],
        "N-THIRD-YEAR-FIRST-SEMESTER": [
            "N.THIRD.YEAR.FIRST.SEMESTER", "N-THIRD-YEAR-FIRST-SEMESTER", "N_THIRD_YEAR_FIRST_SEMESTER",
            "THIRD.YEAR.FIRST.SEMESTER", "THIRD-YEAR-FIRST-SEMESTER", "THIRD_YEAR_FIRST_SEMESTER",
            "3RD.YEAR.1ST.SEMESTER", "3RD-YEAR-1ST-SEMESTER", "3RD_YEAR_1ST_SEMESTER",
            "YEAR3.SEMESTER1", "YEAR-3-SEMESTER-1", "YEAR_3_SEMESTER_1"
        ],
        "N-THIRD-YEAR-SECOND-SEMESTER": [
            "N.THIRD.YEAR.SECOND.SEMESTER", "N-THIRD-YEAR-SECOND-SEMESTER", "N_THIRD_YEAR_SECOND_SEMESTER",
            "THIRD.YEAR.SECOND.SEMESTER", "THIRD-YEAR-SECOND-SEMESTER", "THIRD_YEAR_SECOND_SEMESTER",
            "3RD.YEAR.2ND.SEMESTER", "3RD-YEAR-2ND-SEMESTER", "3RD_YEAR_2ND_SEMESTER",
            "YEAR3.SEMESTER2", "YEAR-3-SEMESTER-2", "YEAR_3_SEMESTER_2"
        ]
    }
    
    for semester_key, patterns in semester_patterns.items():
        for pattern in patterns:
            flexible_pattern = pattern.replace('.', '[ ._ -]?')
            if re.search(flexible_pattern, filename_upper, re.IGNORECASE):
                print(f"‚úÖ Matched semester '{semester_key}' for filename: {filename}")
                return semester_key
    
    print(f"‚ùå Could not determine semester for filename: {filename}")
    return "UNKNOWN_SEMESTER"

def load_carryover_json_files(carryover_dir, semester_key=None, program=None):
    """Load carryover JSON files from directory."""
    carryover_files = []
    
    if semester_key:
        semester_key = standardize_semester_key(semester_key, program)
    
    previous_semester = get_previous_semester(semester_key, program)
    print(f"üîë Target {program} semester: {semester_key}")
    print(f"üîë Previous {program} semester for carryover: {previous_semester}")
    
    for file in os.listdir(carryover_dir):
        if file.startswith("co_student_") and file.endswith(".json"):
            file_semester = extract_semester_from_filename(file)
            file_semester_standardized = standardize_semester_key(file_semester, program)
            
            print(f"üìÑ Found {program} carryover file: {file}")
            print(f"   Original semester: {file_semester}")
            print(f"   Standardized: {file_semester_standardized}")
            print(f"   Target previous: {previous_semester}")
            
            if previous_semester and file_semester_standardized != previous_semester:
                print(f"   ‚è≠Ô∏è Skipping (doesn't match previous {program} semester)")
                continue
            
            file_path = os.path.join(carryover_dir, file)
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                    carryover_files.append({
                        'filename': file,
                        'semester': file_semester_standardized,
                        'data': data,
                        'count': len(data),
                        'file_path': file_path
                    })
                    print(f"   ‚úÖ Loaded: {len(data)} {program} records")
            except Exception as e:
                print(f"Error loading {program} {file}: {e}")
    
    print(f"üìä Total {program} carryover files loaded: {len(carryover_files)}")
    return carryover_files

def get_carryover_records_from_zip(zip_path, set_name, semester_key, program):
    """Get carryover records from ZIP file."""
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            temp_dir = tempfile.mkdtemp()
            carryover_dir = os.path.join(temp_dir, "CARRYOVER_RECORDS")
            os.makedirs(carryover_dir, exist_ok=True)
            for member in zip_ref.namelist():
                if member.startswith("CARRYOVER_RECORDS/"):
                    zip_ref.extract(member, temp_dir)
            records = load_carryover_json_files(carryover_dir, semester_key, program)
            shutil.rmtree(temp_dir)
            print(f"‚úÖ Loaded {len(records)} {program} carryover records from ZIP")
            return records
    except Exception as e:
        print(f"‚ùå Error loading from {program} ZIP: {e}")
        return []

def get_carryover_records(program, set_name, semester_key=None):
    """Get carryover records for a specific program, set, and semester."""
    try:
        if semester_key:
            semester_key = standardize_semester_key(semester_key, program)
            print(f"üîë Using standardized {program} semester key: {semester_key}")
        
        clean_dir = os.path.join(BASE_DIR, program, set_name, "CLEAN_RESULTS")
        if not os.path.exists(clean_dir):
            print(f"‚ùå {program} clean directory not found: {clean_dir}")
            return []
        
        timestamp_items = []
        
        for item in os.listdir(clean_dir):
            item_path = os.path.join(clean_dir, item)
            
            if item.startswith(f"{set_name}_RESULT-") and "CARRYOVER" not in item.upper():
                if os.path.isdir(item_path) or item.endswith('.zip'):
                    timestamp_items.append(item)
                    print(f"Found {program} regular result: {item}")
        
        if not timestamp_items:
            print(f"‚ùå No {program} regular result files found in: {clean_dir}")
            return []
        
        latest_item = sorted(timestamp_items)[-1]
        latest_path = os.path.join(clean_dir, latest_item)
        print(f"‚úÖ Using latest {program} result: {latest_item}")
        
        if latest_item.endswith('.zip'):
            return get_carryover_records_from_zip(latest_path, set_name, semester_key, program)
        else:
            carryover_dir = os.path.join(latest_path, "CARRYOVER_RECORDS")
            if not os.path.exists(carryover_dir):
                print(f"‚ùå No {program} CARRYOVER_RECORDS folder in: {latest_path}")
                return []
            return load_carryover_json_files(carryover_dir, semester_key, program)
            
    except Exception as e:
        print(f"Error getting {program} carryover records: {e}")
        return []

def process_carryover_results(resit_file_path, source_path, source_type, semester_key, set_name, pass_threshold, output_dir, program):
    """
    Process carryover results and generate CARRYOVER_mastersheet for all programs.
    """
    print(f"\nüîÑ PROCESSING {program} CARRYOVER RESULTS FOR {semester_key}")
    print("=" * 60)
    
    # Standardize semester key with program context
    semester_key = standardize_semester_key(semester_key, program)
    print(f"üîë Processing {program} semester: {semester_key}")
    
    # Get previous semester for carryover
    previous_semester = get_previous_semester(semester_key, program)
    print(f"üîë Previous {program} semester for carryover: {previous_semester}")
    
    semester_course_titles, semester_credit_units, course_code_to_title, course_code_to_unit = load_course_data(program)
    
    debug_course_matching(resit_file_path, course_code_to_title, course_code_to_unit, program)
    
    year, sem_num, level, sem_display, set_code, sem_name = get_semester_display_info(semester_key, program)
    
    possible_sheet_keys = []
    if program == "BN":
        possible_sheet_keys = [
            f"{set_code} {sem_display}",
            f"{set_code.replace('BN2', 'BN 2').replace('BN1', 'BN 1').replace('BN3', 'BN 3')} {sem_display}",
            semester_key,
            semester_key.replace('-', ' ').upper(),
            f"{set_code} {sem_name}",
            f"{level} {sem_display}",
        ]
    else:
        possible_sheet_keys = [
            f"{set_code} {sem_display}",
            f"{set_code.replace('NDII', 'ND II').replace('NDI', 'ND I')} {sem_display}",
            semester_key,
            semester_key.replace('-', ' ').upper(),
            f"{set_code} {sem_name}",
            f"{level} {sem_display}",
        ]
    
    course_titles_dict = {}
    credit_units_dict = {}
    
    for sheet_key in possible_sheet_keys:
        sheet_standard = standardize_semester_key(sheet_key, program)
        if sheet_standard in semester_course_titles:
            course_titles_dict = semester_course_titles[sheet_standard]
            credit_units_dict = semester_credit_units[sheet_standard]
            print(f"‚úÖ Using {program} sheet key: '{sheet_key}' with {len(course_titles_dict)} courses")
            break
        else:
            print(f"‚ùå {program} sheet key not found: '{sheet_key}'")
    
    if not course_titles_dict:
        print(f"‚ö†Ô∏è No {program} semester-specific course data found, using global course mappings")
        course_titles_dict = course_code_to_title
        credit_units_dict = course_code_to_unit
    
    print(f"üìä Final {program} course mappings: {len(course_titles_dict)} titles, {len(credit_units_dict)} units")
    
    timestamp = datetime.now().strftime(TIMESTAMP_FMT)
    carryover_output_dir = os.path.join(output_dir, f"CARRYOVER_{set_name}_{semester_key}_{timestamp}")
    os.makedirs(carryover_output_dir, exist_ok=True)
    
    if not os.path.exists(resit_file_path):
        print(f"‚ùå {program} resit file not found: {resit_file_path}")
        return False
    
    temp_mastersheet_path = None
    temp_dir = None
    
    try:
        temp_mastersheet_path, temp_dir = get_mastersheet_path(source_path, source_type, semester_key)
        
        if not temp_mastersheet_path:
            print(f"‚ùå Failed to get {program} mastersheet")
            return False
        
        print(f"üìñ Reading {program} files...")
        resit_df = pd.read_excel(resit_file_path, header=0)
        
        xl = pd.ExcelFile(temp_mastersheet_path)
        sheet_name = get_matching_sheet(xl, semester_key)
        if not sheet_name:
            print(f"‚ùå No matching {program} sheet found for {semester_key}")
            return False
        
        print(f"üìñ Using {program} sheet '{sheet_name}' for current semester {semester_key}")
        
        # Try multiple header options for mastersheet
        mastersheet_df = None
        for header_row in [5, 4, 3, 2, 1, 0]:
            try:
                mastersheet_df = pd.read_excel(temp_mastersheet_path, sheet_name=sheet_name, header=header_row)
                print(f"‚úÖ Successfully read {program} mastersheet with header row {header_row}")
                break
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to read {program} mastersheet with header row {header_row}: {e}")
                continue
        
        if mastersheet_df is None:
            print(f"‚ùå Could not read {program} mastersheet with any header row")
            return False
        
        print(f"‚úÖ {program} files loaded - Resit: {len(resit_df)} rows, Mastersheet: {len(mastersheet_df)} students")
        
        resit_exam_col = find_exam_number_column(resit_df)
        mastersheet_exam_col = find_exam_number_column(mastersheet_df)
        
        if not resit_exam_col:
            print(f"‚ùå Cannot find exam number column in {program} resit file")
            print(f"üìä Resit file columns: {list(resit_df.columns)}")
            return False
        
        if not mastersheet_exam_col:
            print(f"‚ùå Cannot find exam number column in {program} mastersheet")
            print(f"üìä Mastersheet columns: {list(mastersheet_df.columns)}")
            return False
        
        print(f"üìù {program} Exam columns - Resit: '{resit_exam_col}', Mastersheet: '{mastersheet_exam_col}'")
        
        cgpa_data = load_previous_gpas(temp_mastersheet_path, semester_key, program)
        
        carryover_data = []
        updated_students = set()
        
        print(f"\nüéØ PROCESSING {program} RESIT SCORES...")
        
        for idx, resit_row in resit_df.iterrows():
            exam_no = str(resit_row[resit_exam_col]).strip().upper()
            if not exam_no or exam_no in ['NAN', 'NONE', '']:
                continue
            
            # Find student in mastersheet with enhanced matching
            student_mask = mastersheet_df[mastersheet_exam_col].astype(str).str.strip().str.upper() == exam_no
            if not student_mask.any():
                print(f"‚ö†Ô∏è {program} Student {exam_no} not found in mastersheet - skipping")
                continue
            
            student_data = mastersheet_df[student_mask].iloc[0]
            student_name_col = find_student_name_column(mastersheet_df)
            student_name = student_data.get(student_name_col, 'Unknown')
            
            # Find current credits
            current_credits = 0
            for col in mastersheet_df.columns:
                if 'CU PASSED' in str(col).upper() or 'CREDIT' in str(col).upper():
                    current_credits = student_data.get(col, 0)
                    break
            
            # Find current GPA
            current_gpa = 0
            for col in mastersheet_df.columns:
                if 'GPA' in str(col).upper() and 'CGPA' not in str(col).upper():
                    current_gpa = student_data.get(col, 0)
                    break
            
            student_record = {
                'EXAM NUMBER': exam_no,
                'NAME': student_name,
                'RESIT_COURSES': {},
                'CURRENT_GPA': current_gpa,
                'CURRENT_CREDITS': current_credits
            }
            
            if exam_no in cgpa_data:
                student_record['CURRENT_CGPA'] = calculate_cgpa(
                    cgpa_data[exam_no], 
                    student_record['CURRENT_GPA'], 
                    current_credits,
                    program
                )
            else:
                student_record['CURRENT_CGPA'] = student_record['CURRENT_GPA']
            
            if exam_no in cgpa_data:
                student_gpa_data = cgpa_data[exam_no]
                for i, prev_semester in enumerate(student_gpa_data['semesters']):
                    sem_display_name = get_semester_display_info(prev_semester, program)[5]
                    student_record[f'GPA_{sem_display_name}'] = student_gpa_data['gpas'][i]
                    print(f"üìä Stored {program} GPA for {exam_no}: {sem_display_name} = {student_gpa_data['gpas'][i]}")
            
            for col in resit_df.columns:
                if col == resit_exam_col or col == 'NAME' or 'Unnamed' in str(col):
                    continue
                    
                resit_score = resit_row.get(col)
                if pd.isna(resit_score) or resit_score == '':
                    continue
                
                try:
                    resit_score_val = float(resit_score)
                except (ValueError, TypeError):
                    continue
                
                if col in mastersheet_df.columns:
                    original_score = student_data.get(col)
                    if pd.isna(original_score):
                        continue
                    
                    try:
                        original_score_val = float(original_score) if not pd.isna(original_score) else 0.0
                    except (ValueError, TypeError):
                        original_score_val = 0.0
                    
                    if original_score_val < pass_threshold:
                        course_title = find_course_title(col, course_titles_dict, course_code_to_title)
                        credit_unit = find_credit_unit(col, credit_units_dict, course_code_to_unit)
                        
                        student_record['RESIT_COURSES'][col] = {
                            'original_score': original_score_val,
                            'resit_score': resit_score_val,
                            'updated': resit_score_val >= pass_threshold,
                            'course_title': course_title,
                            'credit_unit': credit_unit
                        }
            
            if student_record['RESIT_COURSES']:
                carryover_data.append(student_record)
                updated_students.add(exam_no)
                print(f"‚úÖ {program} {exam_no}: {len(student_record['RESIT_COURSES'])} resit courses, CGPA: {student_record['CURRENT_CGPA']}")
        
        if carryover_data:
            print(f"\nüìä GENERATING {program} CARRYOVER MASTERSHEET...")
            carryover_mastersheet_path = generate_carryover_mastersheet(
                carryover_data, carryover_output_dir, semester_key, set_name, timestamp, 
                cgpa_data, course_titles_dict, credit_units_dict, course_code_to_title, course_code_to_unit, program
            )
            
            print(f"\nüìÑ GENERATING {program} INDIVIDUAL STUDENT REPORTS...")
            generate_individual_reports(
                carryover_data, carryover_output_dir, semester_key, set_name, timestamp, cgpa_data, program
            )
            
            zip_path = os.path.join(output_dir, f"CARRYOVER_{set_name}_{semester_key}_{timestamp}.zip")
            if create_carryover_zip(carryover_output_dir, zip_path, program):
                print(f"‚úÖ Final {program} carryover ZIP created: {zip_path}")
            
            print(f"\nüéâ {program} CARRYOVER PROCESSING COMPLETED!")
            print(f"üìÅ Output directory: {carryover_output_dir}")
            print(f"üì¶ ZIP file: {zip_path}")
            print(f"üë®‚Äçüéì {program} Students processed: {len(carryover_data)}")
            
            return True
        else:
            print(f"‚ùå No {program} carryover data found to process")
            return False
            
    except Exception as e:
        print(f"‚ùå Error processing {program} carryover results: {e}")
        traceback.print_exc()
        return False
    finally:
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            print(f"‚úÖ Cleaned up {program} temporary files")

def generate_remarks(resit_courses, program):
    """Generate remarks based on resit performance."""
    passed_count = sum(1 for course_data in resit_courses.values() 
                      if course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD)
    total_count = len(resit_courses)
    
    if passed_count == total_count:
        return f"All {program} courses passed in resit"
    elif passed_count > 0:
        return f"{passed_count}/{total_count} {program} courses passed in resit"
    else:
        return f"No improvement in {program} resit"

def generate_carryover_mastersheet(carryover_data, output_dir, semester_key, set_name, timestamp, cgpa_data, course_titles, course_units, course_code_to_title, course_code_to_unit, program):
    """Generate the CARRYOVER_mastersheet with enhanced GPA tracking for all programs."""
    
    wb = Workbook()
    ws = wb.active
    
    if program == "BN":
        ws.title = "BN_CARRYOVER_RESULTS"
        program_name = "BASIC NURSING"
        program_abbr = "BN"
    else:
        ws.title = "CARRYOVER_RESULTS"
        program_name = "NATIONAL DIPLOMA"
        program_abbr = "ND"
    
    if os.path.exists(DEFAULT_LOGO_PATH):
        try:
            from openpyxl.drawing.image import Image
            img = Image(DEFAULT_LOGO_PATH)
            img.width = 80
            img.height = 80
            ws.add_image(img, 'A1')
        except Exception as e:
            print(f"‚ö†Ô∏è Could not add logo: {e}")
    
    current_year = 2025
    next_year = 2026
    year, sem_num, level, sem_display, set_code, current_semester_name = get_semester_display_info(semester_key, program)
    
    all_courses = set()
    for student in carryover_data:
        all_courses.update(student['RESIT_COURSES'].keys())
    
    previous_semesters = get_previous_semesters_for_display(semester_key, program)
    
    headers = ['S/N', 'EXAM NUMBER', 'NAME']
    
    for prev_sem in previous_semesters:
        headers.append(f'GPA {prev_sem}')
    
    course_headers = []
    for course in sorted(all_courses):
        course_headers.extend([f'{course}', f'{course}_RESIT'])
    
    headers.extend(course_headers)
    headers.extend([f'GPA {current_semester_name}', 'CGPA', 'REMARKS'])
    
    total_columns = len(headers)
    last_column = get_column_letter(total_columns)
    
    ws.merge_cells(f'A3:{last_column}3')
    title_cell = ws['A3']
    title_cell.value = "FCT COLLEGE OF NURSING SCIENCES, GWAGWALADA-ABUJA"
    title_cell.font = Font(bold=True, size=14)
    title_cell.alignment = Alignment(horizontal='center', vertical='center')
    
    ws.merge_cells(f'A4:{last_column}4')
    subtitle_cell = ws['A4']
    
    if program == "BN":
        subtitle_cell.value = f"{program_name} RESIT - {current_year}/{next_year} SESSION {level} {sem_display} EXAMINATIONS RESULT ‚Äî {datetime.now().strftime('%B %d, %Y')}"
    else:
        subtitle_cell.value = f"RESIT - {current_year}/{next_year} SESSION {program_name} {level} {sem_display} EXAMINATIONS RESULT ‚Äî {datetime.now().strftime('%B %d, %Y')}"
    
    subtitle_cell.font = Font(bold=True, size=12)
    subtitle_cell.alignment = Alignment(horizontal='center', vertical='center')
    
    print(f"üîç {program} Courses found in resit data: {sorted(all_courses)}")
    print(f"üìä {program} GPA columns for {semester_key}: Previous={previous_semesters}, Current={current_semester_name}")
    
    headers = ['S/N', 'EXAM NUMBER', 'NAME']
    
    for prev_sem in previous_semesters:
        headers.append(f'GPA {prev_sem}')
    
    course_headers = []
    course_title_mapping = {}
    course_unit_mapping = {}
    
    for course in sorted(all_courses):
        course_title = find_course_title(course, course_titles, course_code_to_title)
        course_title_mapping[course] = course_title
        
        credit_unit = find_credit_unit(course, course_units, course_code_to_unit)
        course_unit_mapping[course] = credit_unit
        
        if len(course_title) > 30:
            course_title = course_title[:27] + "..."
        course_headers.extend([f'{course}', f'{course}_RESIT'])
    
    headers.extend(course_headers)
    headers.extend([f'GPA {current_semester_name}', 'CGPA', 'REMARKS'])
    
    title_row = [''] * 3
    
    for prev_sem in previous_semesters:
        title_row.extend([''])
    
    for course in sorted(all_courses):
        course_title = course_title_mapping[course]
        if len(course_title) > 30:
            course_title = course_title[:27] + "..."
        title_row.extend([course_title, course_title])
    
    title_row.extend(['', '', ''])
    
    ws.append(title_row)
    
    credit_row = [''] * 3
    
    for prev_sem in previous_semesters:
        credit_row.extend([''])
    
    for course in sorted(all_courses):
        credit_unit = course_unit_mapping[course]
        credit_row.extend([f'CU: {credit_unit}', f'CU: {credit_unit}'])
    
    credit_row.extend(['', '', ''])
    
    ws.append(credit_row)
    
    code_row = ['S/N', 'EXAM NUMBER', 'NAME']
    
    for prev_sem in previous_semesters:
        code_row.append(f'GPA {prev_sem}')
    
    for course in sorted(all_courses):
        code_row.extend([f'{course}', f'{course}_RESIT'])
    
    code_row.extend([f'GPA {current_semester_name}', 'CGPA', 'REMARKS'])
    
    ws.append(code_row)
    
    course_colors = [
        "E6F3FF", "FFF0E6", "E6FFE6", "FFF6E6", "F0E6FF",
        "E6FFFF", "FFE6F2", "F5F5DC", "E6F7FF", "FFF5E6",
    ]
    
    start_col = 4
    if previous_semesters:
        start_col += len(previous_semesters)
    
    color_index = 0
    for course in sorted(all_courses):
        for row in [5, 6, 7]:
            for offset in [0, 1]:
                cell = ws.cell(row=row, column=start_col + offset)
                cell.fill = PatternFill(start_color=course_colors[color_index % len(course_colors)], 
                                      end_color=course_colors[color_index % len(course_colors)], 
                                      fill_type="solid")
                cell.font = Font(bold=True)
                cell.alignment = Alignment(horizontal='center', vertical='center')
                cell.border = Border(
                    left=Side(style='thin'), right=Side(style='thin'),
                    top=Side(style='thin'), bottom=Side(style='thin')
                )
        
        for offset in [0, 1]:
            cell = ws.cell(row=5, column=start_col + offset)
            cell.alignment = Alignment(text_rotation=90, horizontal='center', vertical='center')
            cell.font = Font(bold=True, size=9)
        
        color_index += 1
        start_col += 2
    
    for row in [5, 6, 7]:
        for col in range(1, 4):
            cell = ws.cell(row=row, column=col)
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center")
            cell.border = Border(
                left=Side(style='thin'), right=Side(style='thin'),
                top=Side(style='thin'), bottom=Side(style='thin')
            )
        
        gpa_col = 4
        for prev_sem in previous_semesters:
            cell = ws.cell(row=row, column=gpa_col)
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = Border(
                left=Side(style='thin'), right=Side(style='thin'),
                top=Side(style='thin'), bottom=Side(style='thin')
            )
            gpa_col += 1
        
        for col in range(len(headers)-2, len(headers)+1):
            cell = ws.cell(row=row, column=col)
            cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = Border(
                left=Side(style='thin'), right=Side(style='thin'),
                top=Side(style='thin'), bottom=Side(style='thin')
            )
    
    row_idx = 8
    failed_counts = {course: 0 for course in all_courses}
    
    start_col = 4
    if previous_semesters:
        start_col += len(previous_semesters)
    
    for student in carryover_data:
        exam_no = student['EXAM NUMBER']
        
        ws.cell(row=row_idx, column=1, value=row_idx-7)
        ws.cell(row=row_idx, column=2, value=student['EXAM NUMBER'])
        ws.cell(row=row_idx, column=3, value=student['NAME'])
        
        gpa_col = 4
        for prev_sem in previous_semesters:
            gpa_value = student.get(f'GPA_{prev_sem}', '')
            ws.cell(row=row_idx, column=gpa_col, value=gpa_value)
            gpa_col += 1
        
        course_col = gpa_col
        color_index = 0
        for course in sorted(all_courses):
            for offset in [0, 1]:
                cell = ws.cell(row=row_idx, column=course_col + offset)
                cell.fill = PatternFill(start_color=course_colors[color_index % len(course_colors)], 
                                      end_color=course_colors[color_index % len(course_colors)], 
                                      fill_type="solid")
            
            if course in student['RESIT_COURSES']:
                course_data = student['RESIT_COURSES'][course]
                
                orig_cell = ws.cell(row=row_idx, column=course_col, value=course_data['original_score'])
                if course_data['original_score'] < DEFAULT_PASS_THRESHOLD:
                    orig_cell.fill = PatternFill(start_color="FFB6C1", end_color="FFB6C1", fill_type="solid")
                
                resit_cell = ws.cell(row=row_idx, column=course_col+1, value=course_data['resit_score'])
                if course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD:
                    resit_cell.fill = PatternFill(start_color="90EE90", end_color="90EE90", fill_type="solid")
                else:
                    resit_cell.fill = PatternFill(start_color="FFB6C1", end_color="FFB6C1", fill_type="solid")
                    failed_counts[course] += 1
            else:
                ws.cell(row=row_idx, column=course_col, value='')
                ws.cell(row=row_idx, column=course_col+1, value='')
            
            color_index += 1
            course_col += 2
        
        ws.cell(row=row_idx, column=course_col, value=student['CURRENT_GPA'])
        ws.cell(row=row_idx, column=course_col+1, value=student['CURRENT_CGPA'])
        
        remarks = generate_remarks(student['RESIT_COURSES'], program)
        ws.cell(row=row_idx, column=course_col+2, value=remarks)
        
        row_idx += 1
    
    failed_row_idx = row_idx
    ws.cell(row=failed_row_idx, column=1, value=f"{program} FAILED COUNT BY COURSE:").font = Font(bold=True)
    
    for col in range(1, len(headers) + 1):
        cell = ws.cell(row=failed_row_idx, column=col)
        cell.fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")
    
    course_col = gpa_col
    for course in sorted(all_courses):
        count_cell = ws.cell(row=failed_row_idx, column=course_col+1, value=failed_counts[course])
        count_cell.font = Font(bold=True)
        count_cell.fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")
        course_col += 2
    
    summary_start_row = failed_row_idx + 2
    
    total_students = len(carryover_data)
    passed_all = sum(1 for student in carryover_data 
                    if all(course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD 
                          for course_data in student['RESIT_COURSES'].values()))
    
    carryover_count = total_students - passed_all
    total_failed_attempts = sum(failed_counts.values())
    
    summary_data = [
        [f"{program} CARRYOVER SUMMARY"],
        [f"A total of {total_students} {program} students registered and sat for the Carryover Examination"],
        [f"A total of {passed_all} {program} students passed all carryover courses"],
        [f"A total of {carryover_count} {program} students failed one or more carryover courses and must repeat them"],
        [f"Total failed {program} resit attempts: {total_failed_attempts} across all courses"],
        [f"{program} Carryover processing completed on {datetime.now().strftime('%B %d, %Y at %H:%M:%S')}"],
        [""],
        [""],
        ["", ""],
        ["________________________", "________________________"],
        ["Mrs. Abini Hauwa", "Mrs. Olukemi Ogunleye"],
        ["Head of Exams", f"Chairman, {program} Program C'tee"]
    ]
    
    for i, row_data in enumerate(summary_data):
        row_num = summary_start_row + i
        if len(row_data) == 1:
            if row_data[0]:
                ws.merge_cells(start_row=row_num, start_column=1, end_row=row_num, end_column=10)
                cell = ws.cell(row=row_num, column=1, value=row_data[0])
                if i == 0:
                    cell.font = Font(bold=True, size=12, underline='single')
                else:
                    cell.font = Font(bold=False, size=11)
                cell.alignment = Alignment(horizontal='left', vertical='center')
        elif len(row_data) == 2:
            left_cell = ws.cell(row=row_num, column=1, value=row_data[0])
            right_cell = ws.cell(row=row_num, column=4, value=row_data[1])
            
            if i >= len(summary_data) - 3:
                left_cell.alignment = Alignment(horizontal='left')
                right_cell.alignment = Alignment(horizontal='left')
                left_cell.font = Font(bold=True, size=11)
                right_cell.font = Font(bold=True, size=11)
    
    thin_border = Border(
        left=Side(style='thin'), right=Side(style='thin'),
        top=Side(style='thin'), bottom=Side(style='thin')
    )
    
    for row in ws.iter_rows(min_row=7, max_row=row_idx-1, min_col=1, max_col=len(headers)):
        for cell in row:
            cell.border = thin_border
    
    ws.freeze_panes = 'D8'
    
    for row in ws.iter_rows():
        for cell in row:
            if cell.font is None or not cell.font.bold:
                cell.font = Font(name='Calibri', size=11)
    
    for col_idx, column in enumerate(ws.columns, 1):
        max_length = 0
        column_letter = get_column_letter(col_idx)
        
        for cell in column:
            try:
                if cell.value is not None:
                    cell_value = str(cell.value)
                    cell_length = len(cell_value)
                    
                    if cell.row == 5 and cell.alignment.text_rotation == 90:
                        cell_length = max(cell_length, 10)
                    
                    if isinstance(cell.value, (int, float)) and not isinstance(cell.value, bool):
                        cell_length = max(cell_length, 8)
                    
                    if cell_length > max_length:
                        max_length = cell_length
            except:
                pass
        
        adjusted_width = min(max_length + 2, 50)
        
        if col_idx == 1:
            adjusted_width = 8
        elif col_idx == 2:
            adjusted_width = 18
        elif col_idx == 3:
            adjusted_width = 35
        elif col_idx >= 4 and col_idx <= (4 + len(previous_semesters) - 1):
            adjusted_width = 15
        elif col_idx >= len(headers) - 2:
            adjusted_width = 15
        else:
            adjusted_width = min(max(adjusted_width, 12), 25)
        
        ws.column_dimensions[column_letter].width = adjusted_width
    
    for row_idx in range(8, row_idx):
        if row_idx % 2 == 0:
            for cell in ws[row_idx]:
                if (cell.fill.start_color.index == '00000000' or 
                    cell.fill.start_color.index == '00FFFFFF'):
                    cell.fill = PatternFill(start_color="F8F8F8", end_color="F8F8F8", fill_type="solid")
    
    gpa_fill = PatternFill(start_color="E6E6FA", end_color="E6E6FA", fill_type="solid")
    if previous_semesters:
        for row in range(8, row_idx):
            for col in range(4, 4 + len(previous_semesters)):
                cell = ws.cell(row=row, column=col)
                if cell.fill.start_color.index == '00000000':
                    cell.fill = gpa_fill
    
    final_gpa_fill = PatternFill(start_color="E0FFFF", end_color="E0FFFF", fill_type="solid")
    for row in range(8, row_idx):
        for col in range(len(headers)-2, len(headers)+1):
            cell = ws.cell(row=row, column=col)
            if cell.fill.start_color.index == '00000000':
                cell.fill = final_gpa_fill
    
    if program == "BN":
        filename = f"BN_CARRYOVER_mastersheet_{timestamp}.xlsx"
    else:
        filename = f"CARRYOVER_mastersheet_{timestamp}.xlsx"
        
    filepath = os.path.join(output_dir, filename)
    wb.save(filepath)
    
    print(f"‚úÖ {program} CARRYOVER mastersheet generated: {filepath}")
    return filepath

def generate_individual_reports(carryover_data, output_dir, semester_key, set_name, timestamp, cgpa_data, program):
    """Generate individual student reports in CSV format."""
    if program == "BN":
        reports_dir = os.path.join(output_dir, "BN_INDIVIDUAL_REPORTS")
    else:
        reports_dir = os.path.join(output_dir, "INDIVIDUAL_REPORTS")
        
    os.makedirs(reports_dir, exist_ok=True)
    
    for student in carryover_data:
        exam_no = student['EXAM NUMBER']
        safe_exam_no = sanitize_filename(exam_no)
        
        if program == "BN":
            filename = f"bn_carryover_report_{safe_exam_no}_{timestamp}.csv"
        else:
            filename = f"carryover_report_{safe_exam_no}_{timestamp}.csv"
            
        filepath = os.path.join(reports_dir, filename)
        
        report_data = []
        report_data.append([f"{program} CARRYOVER RESULT REPORT"])
        report_data.append(["FCT COLLEGE OF NURSING SCIENCES"])
        report_data.append([f"{program} Set: {set_name}"])
        report_data.append([f"{program} Semester: {semester_key}"])
        report_data.append([])
        report_data.append([f"{program} STUDENT INFORMATION"])
        report_data.append(["Exam Number:", student['EXAM NUMBER']])
        report_data.append(["Name:", student['NAME']])
        report_data.append([])
        
        report_data.append([f"{program} PREVIOUS GPAs"])
        for key in sorted([k for k in student.keys() if k.startswith('GPA_')]):
            semester = key.replace('GPA_', '')
            report_data.append([f"{semester}:", student[key]])
        report_data.append([])
        
        report_data.append([f"{program} CURRENT ACADEMIC RECORD"])
        report_data.append(["Current GPA:", student['CURRENT_GPA']])
        report_data.append(["Current CGPA:", student['CURRENT_CGPA']])
        report_data.append([])
        
        report_data.append([f"{program} RESIT COURSES"])
        report_data.append(["Course Code", "Course Title", "Credit Unit", "Original Score", "Resit Score", "Status"])
        
        for course_code, course_data in student['RESIT_COURSES'].items():
            status = "PASSED" if course_data['resit_score'] >= DEFAULT_PASS_THRESHOLD else "FAILED"
            course_title = course_data.get('course_title', course_code)
            credit_unit = course_data.get('credit_unit', 0)
            report_data.append([
                course_code, 
                course_title,
                credit_unit,
                course_data['original_score'], 
                course_data['resit_score'], 
                status
            ])
        
        try:
            df = pd.DataFrame(report_data)
            df.to_csv(filepath, index=False, header=False)
            print(f"‚úÖ Generated {program} report for: {exam_no}")
        except Exception as e:
            print(f"‚ùå Error generating {program} report for {exam_no}: {e}")
    
    print(f"‚úÖ Generated {len(carryover_data)} {program} individual student reports in {reports_dir}")

def create_carryover_zip(source_dir, zip_path, program):
    """Create ZIP file of carryover results."""
    try:
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(source_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, source_dir)
                    zipf.write(file_path, arcname)
        print(f"‚úÖ {program} ZIP file created: {zip_path}")
        return True
    except Exception as e:
        print(f"‚ùå Error creating {program} ZIP: {e}")
        return False

def main():
    """Main function to process carryover results for all programs."""
    print("üéØ UNIFIED CARRYOVER RESULT PROCESSOR - ALL PROGRAMS")
    print("=" * 50)
    
    set_name = os.getenv("SELECTED_SET", "ND-2025")
    semester_key = os.getenv("SELECTED_SEMESTERS", "ND-FIRST-YEAR-SECOND-SEMESTER")
    resit_file_path = os.getenv("RESIT_FILE_PATH", "")
    pass_threshold = float(os.getenv("PASS_THRESHOLD", str(DEFAULT_PASS_THRESHOLD)))
    
    print(f"üéØ Processing: Set={set_name}, Semester={semester_key}")
    
    if set_name.startswith("SET4"):
        program = "BN" 
    elif set_name.startswith("ND-"):
        program = "ND"
    elif set_name.startswith("BM") or set_name.startswith("SET"):
        program = "BM"
    else:
        program = "ND"
        print(f"‚ö†Ô∏è Could not determine program from set name '{set_name}', defaulting to ND")
    
    possible_base_dirs = [
        BASE_DIR,
        os.path.join(BASE_DIR, "EXAMS_INTERNAL"),
        os.path.join(os.path.expanduser('~'), 'student_result_cleaner', 'EXAMS_INTERNAL'),
    ]
    
    raw_dir = None
    clean_dir = None
    output_dir = None
    
    for base in possible_base_dirs:
        test_raw_dir = os.path.join(base, program, set_name, "RAW_RESULTS")
        test_clean_dir = os.path.join(base, program, set_name, "CLEAN_RESULTS")
        
        print(f"üîç Checking {program} directory: {test_clean_dir}")
        
        if os.path.exists(test_clean_dir):
            raw_dir = test_raw_dir
            clean_dir = test_clean_dir
            output_dir = test_clean_dir
            print(f"‚úÖ Found {program} clean directory: {clean_dir}")
            break
    
    if not clean_dir:
        print(f"üîç Trying alternative {program} directory structures...")
        alt_clean_dir = os.path.join(BASE_DIR, "EXAMS_INTERNAL", program, set_name, "CLEAN_RESULTS")
        print(f"üîç Checking alternative {program} directory: {alt_clean_dir}")
        
        if os.path.exists(alt_clean_dir):
            raw_dir = os.path.join(BASE_DIR, "EXAMS_INTERNAL", program, set_name, "RAW_RESULTS")
            clean_dir = alt_clean_dir
            output_dir = alt_clean_dir
            print(f"‚úÖ Found alternative {program} clean directory: {clean_dir}")
    
    if not clean_dir:
        print(f"‚ùå {program} clean directory not found for {program}/{set_name}")
        print("üí° Please check:")
        print(f"   - {program} Set name: {set_name}")
        print(f"   - {program} Program: {program}") 
        print(f"   - Base directory: {BASE_DIR}")
        return
    
    print(f"üìÅ {program} Base directory: {BASE_DIR}")
    print(f"üìÅ {program} Raw directory: {raw_dir}")
    print(f"üìÅ {program} Clean directory: {clean_dir}")
    print(f"üìÅ {program} Output directory: {output_dir}")
    print(f"üìÅ {program} Resit file path: {resit_file_path}")
    
    if not resit_file_path or not os.path.exists(resit_file_path):
        print(f"‚ùå {program} resit file not provided or doesn't exist: {resit_file_path}")
        print(f"üí° Please set the RESIT_FILE_PATH environment variable to a valid {program} resit file")
        return

    if not os.path.exists(raw_dir):
        print(f"‚ö†Ô∏è {program} raw directory doesn't exist: {raw_dir}")
        print(f"üí° The {program} set might not be properly set up")
    
    print(f"üîç Looking for {program} mastersheet in: {clean_dir}")
    source_path, source_type = find_latest_mastersheet_source(clean_dir, set_name, program)
    if not source_path:
        print(f"‚ùå No {program} ZIP files or result folders found in {clean_dir}")
        print(f"üí° Please run the {program} regular result processor first to generate clean results")
        return
    
    success = process_carryover_results(
        resit_file_path, source_path, source_type, semester_key, set_name, pass_threshold, output_dir, program
    )
    
    if success:
        print(f"\n‚úÖ {program} Carryover processing completed successfully!")
        print(f"üìÅ Check the {program} CLEAN_RESULTS directory for the CARRYOVER output")
    else:
        print(f"\n‚ùå {program} Carryover processing failed!")

if __name__ == "__main__":
    main()